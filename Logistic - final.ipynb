{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from LogisticRegression import LogisticClassifier as mylogit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_(coefs,degree):\n",
    "    theta = np.array([[w]for w in coefs])\n",
    "    X=dt.iloc[:,:-1].values\n",
    "    y=dt.iloc[:,-1].values\n",
    "    pos , neg = (y==1).reshape(118,1) , (y==0).reshape(118,1)\n",
    "    plt.scatter(X[pos[:,0],0],X[pos[:,0],1],c=\"r\",marker=\"+\",label=\"Admitted\")\n",
    "    plt.scatter(X[neg[:,0],0],X[neg[:,0],1],c=\"b\",marker=\"x\",label=\"Not admitted\")\n",
    "    # Plotting decision boundary\n",
    "\n",
    "    u_vals = np.linspace(-1,1.5,50)\n",
    "    v_vals= np.linspace(-1,1.5,50)\n",
    "    z=np.zeros((len(u_vals),len(v_vals)))\n",
    "    for i in range(len(u_vals)):\n",
    "        for j in range(len(v_vals)):\n",
    "            z[i,j] =mapFeaturePlot(u_vals[i],v_vals[j],degree) @ theta\n",
    "    plt.contour(u_vals,v_vals,z.T,0)\n",
    "    plt.xlabel(\"F1\")\n",
    "    plt.ylabel(\"F2\")\n",
    "    plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('microchip_data.txt',header = None)\n",
    "X = dt.iloc[:,:2]\n",
    "y = dt.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25079954648>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3iUVfq/7zN9MumNFiA06T2AiKioK8oq2EVXV1bXtpbVLa5ucV33u/5su9ZdV1zr2nUt2LBhR2mCKChFCBACpLeZZOr5/XHSJplAMplkZjLnvq5cyXveMieTyfu85ymfR0gp0Wg0Go2mqxiiPQGNRqPRxCfagGg0Go0mLLQB0Wg0Gk1YaAOi0Wg0mrDQBkSj0Wg0YWGK9gR6k+zsbJmfnx/taWg0Gk1csW7dujIpZU7b8YQyIPn5+axduzba09BoNJq4QgixK9S4dmFpNBqNJiy0AdFoNBpNWGgDotFoNJqwSKgYiEaj0bTG6/VSVFREQ0NDtKcSE9hsNvLy8jCbzZ06XhsQjUaTsBQVFZGSkkJ+fj5CiGhPJ6pIKSkvL6eoqIhhw4Z16hztwtJoNAlLQ0MDWVlZCW88AIQQZGVldWk1pg2IJuFxuX1UOj0EAlqZOhHRxqOFrr4X2oWlSViklBRV1vOP97awq9zFGdPzWDBhABkOS7SnptHEBXoFoklYSmvdnPavz3llfTFf7a7iD698y4vrivD5A9GemkYTkscff5zi4uKwzy8sLOSZZ56J2Hy0AdEkLHur6imr8wSNPbNqF5Uub5Rm1HPUNXjZXlLHvz/+gRXfH6C8zh3tKWnCQBsQjSZGSLW1T1XMTrZiMvQtn7iUklU7Kzj+Hx9z29vfc9Hja7n2+Q1UOLURiQX+8Y9/MGHCBCZMmMA999xDYWEhEyZMaN5/1113cfPNN/PSSy+xdu1afvKTnzBlyhTq6+vJz8/nd7/7HTNnzmTmzJls374dgCVLlvDSSy81XyM5ORmAG264gU8//ZQpU6Zw9913d3vu2oBoEpZMh4UTx/dv3rYYDfzplHF9LgZS7vRw29vfB419uq2Mqj640oo31q1bx2OPPcaqVav48ssvefjhh6msrAx57JlnnklBQQFPP/00GzZswG63A5Camsrq1au56qqruPbaaw/6erfddhtz585lw4YNXHfddd2evw6iaxKWDIeFW0+fyC/mjaC4qp7JeelkJvct4wFqBVLv9bcb9/p11lm0+eyzzzjttNNwOBwAnH766Xz66addusa5557b/D0SRqEr6BWIJqHJdFiYlJfOiRMGMCDdjtVkjPaUIk6Gw8Ilc4cHjY3IcZDVx1Za8YiU7Y14VVUVgUBLIseh6jJap942/WwymZqvIaXE4/GEPLe7aAOi0fRxTAYDC6cM5JELC5g/vj/XHT+KZy85nOwUa7SnlvAcddRRvPrqq7hcLpxOJ6+88gonnXQSJSUllJeX43a7eeONN5qPT0lJoba2Nugazz//fPP32bNnA6p1xbp16wB47bXX8Hq9HZ7fHbQLS6NJADKSLBw3th9zRmZjNgqMBv3sGAtMmzaNJUuWMHPmTAB+/vOfM2PGDG666SZmzZrFsGHDGDNmTPPxS5Ys4fLLL8dut/PFF18A4Ha7mTVrFoFAgGeffRaASy65hEWLFjFz5kyOO+64ZhfZpEmTMJlMTJ48mSVLlnTb5SVCLaH6KgUFBVI3lNJoNE189913jB07NtrTCJumJnnZ2dkRu2ao90QIsU5KWdD2WP0YotFoNJqwiKoBEUI8KoQoEUJ828F+IYS4TwixXQixUQgxrdW+C4UQ2xq/Luy9WfctKp0eNhVX8+r6veyucOF0+6I9pV6hwesPS/uqrM7NFz+U8fa3+zhQ04BfV61rokhhYWFEVx9dJdoxkMeBB4AnO9h/EjCq8WsW8CAwSwiRCfwZKAAksE4IsUxKGTqBWhOS6novd7+3lSe/VO2OhYCHLyjg2DG5GPpYMV0TFU4PX/xQxrKv9zF1SDpnTsvrdDC5rM7NhY+uZlNxDQApVhNvXHMkQ7McPTlljSZmieoKREr5CVBxkEMWAU9KxZdAuhBiADAfeE9KWdFoNN4DTuz5GfctnG5fs/EAkBJufn0T5X20Qtnt9fPEykKufGY972zaz21vf88l/13b6d93c3FNs/EAqHX7uO+DbTSEqLHQaBKBWI+BDAL2tNouahzraLwdQohLhRBrhRBrS0tLe2yi8Yg3hPulwukhqmkVgQAEeuaGXNPg5dHPdgaNrd9dhcvdudcrC6EfVVbnCfk+ajSJQKwbkFB+FHmQ8faDUi6VUhZIKQtycnIiOrl4x2E1MTI3OWjsnBmDSbF2rp1lRPF7oXIXvPdHePPXULoVPPURfxmbuX2hoLGT7rrZw7Owtzn/oiOHkRJCU0ujSQRi3YAUAYNbbecBxQcZ13SB7GQrT/98FkuOyGf60AxuOnkcVx07ErslCtXYdQfgwSPgi3/CusfgwdlQvTuiL5GeZOH6E0cHjZ08aQBJnfx9s1MsvHH1kSyY0J/ZI7J4dMkMpuSlR3SOmsRj+fLljB49mpEjR3LbbbdFezpdItpB9EOxDLhKCPEcKoheLaXcJ4R4B7hVCJHReNwJwI3RmmQ80y/Vxo0njcHl9ZNqNWE0RumZYvMy8NS1bAd8sPIBOPkfYIzME77ZaOCEcf2Z8Ms0VnxfwqS8NMYNSCU9qXOSHmajkRG5ydx51mR8AUmavfdXHlJK3UGvD+H3+7nyyit57733yMvLY8aMGSxcuJBx48ZFe2qdIqoGRAjxLHAMkC2EKEJlVpkBpJT/Bt4CFgDbARfws8Z9FUKIvwJrGi91i5TyYMF4zUGwmo1YQ7h2ehVTiEwos1WlhkWQtCQzaUlmxg5IDfsaDmvv/9uU1rpZ9nUx2w7UsnjGYIbnJJMaBQOW6Ly6fi93vrOF4qp6Bqbb+e380Zw6NWT4tVOsXr2akSNHMny40ipbvHgxr732mjYgnUFKee4h9kvgyg72PQo82hPz0nSNSqeHeq8fo0GQZjdhM4fxsRq9AD66FZxlatucBLOvAkOsL5JDU+/1U13vJRCQ2C1GMjq5yglFWa2bxUu/5IdStUJ7bs0e/n3+NOaP769XI73Iq+v3cuPL3zQrG++tqufGl78BCNuI7N27l8GDW7zxeXl5rFq1qvuT7SXi879TEzOU1jZw7fMb+Hx7OXazkRsXjOHUKYO6/nSc3A8u+wy+ex28LphwBqT0P/R5MUhNvZf/fVXEHcu3UO/1M3dUNnefPSVs8cJ91fXNxqOJ+z7Yzoz8TLKStSBib3HnO1vayeLXe/3c+c6WsA1IKCmpeHooiPUguibC1DR4+aaompuXbeLZ1bsprQ2/5sPt87P0kx18vr0cUP9MN722iXJnGNLRBgOkDoBZl8KR10L64IjFPnqbsjo3f3l9c/PN5tNtZTzy2Q68vvDSfQ0hbihaC7H3Ka4KnRXY0XhnyMvLY8+eloqEoqIiBg4cGPb1ehu9AkkgpJSs3F7G5U991Tz23wG7ePLimWSH8SRb1+Djix3l7ca/31/DsOzErc5uXWzYxBc7Kqhz+8gwdd2V1S/NxtgBKXy3r0WG+9c/Gq1XH63w+wOUuzz4/BKrydAj783AdDt7QxiLgen2sK85Y8YMtm3bxs6dOxk0aBDPPfdcRHuW9zTagCQQ5U4Pd7+3LWhs874aSmvdYRmQZJuJOSOy+XZv8A1zbP/wA9R9gfED2//+c0ZmhR18z0628t+LZrFiSwnbDtRy+rQ88jLCv2n1NTw+P+t3V3H1s+spqXUzfmAqD10wnbyMpIi+zm/njw6KgQDYzUZ+O3/0Qc46OCaTiQceeID58+fj9/u56KKLGD9+fCSm2ytoA6IJu/LcajLy87nD+X5/DR9vLcNhMfKHH48lM8E73WUnW/nrovHc9vb3OD1+5o3O4WdzhmExhe93yk6xcnbB4EMfmIBUurxc9PganB51Y99UXMNvX9zIg+dP63SKdmdoinNEMgsLYMGCBSxYsCASU+x1tAFJILIcFq49fhRXPN3iwhrdL4XcbnSmy0mxcu/iqdR7/RiEIN1ujn5KcJRJtZs5q2AwJ4zvT0BK7GZjRG9kmmCcbl+z8WhiTWEFnh6QmDl16qBuG4y+hDYgCYQQgjkjs3ntyjm8sHYPY/qncOKEAWG5r1qTnmRB12MHYzMbQ8qmaCKPw2rCbjYGuZamDE7HrDMNehxtQBKMVLuZyYPTmTxY3/I1fYP0JDMPXTCda55bT5XLy4gcB38/ezIZCe5K7Q20AdFoNHGN1WRk9ohM3r32KDz+ADaTMeyaG03X0AZEo9F0mgqnm5oGH4GAJNVu7rb7M1KYjUZyU7XLsLfRBkSjaYvHqdSBv38LsobDoBmQrFsBlNW5ufqZr/hih5KdmzgojUeXzCBHP+0nLDrKpOlbOMuh9gC42hc4dpp9G+H+6fDuH+DZc+G5c8Gpm5Gt2lHRbDwAvtlbzZsb90VxRn2Diy66iNzcXCZMmBDtqXQZbUA0fYeKHfDs2fD3w+CZc6Bi56HPaYurHN6/CWSrFNCiNVCjb5Tf7q1uN/Z1URX+gO7I2B2WLFnC8uXLoz2NsNAGRBM9/H5oqFHfu0tdCTxzNhStVdtFa8JbOQQC4HG1H/c1dH+OrfD7A9Q2ePEHut9AWEpJbYMXT5haW51lwaQB7cbOnJ6HMZHSZTe+AHdPgJvT1feNL3T7kkcddRSZmZkRmFzvk0B/eU1M4SyFL/8JL1ygvnfXReRzQ1mwTAsl36nxrpCUBUdcEzyWlgcZQ7s3v1aU1blZ+ulOrnjqKx77fCflIXqtd5YKp4eXv9rLL57+in+8t4WSmsgautYMzUzi7nMmk5dhp3+qjVsWjg8p29Jn2fgCvH4NVO8BpPr++jURMSLxig6ia3qf+ip4/Vr4/g21veMj2LMaFj0A9jDrU4xmcOQEG6KU/mDooqKvwQCHnQDnv6xa62aOhFmXKbn5CFDl8vC7lzbywfclAHy2vYwNe6q49bSJXZbAd/v8PLGykHs/UIbz021lvP9dCc9deniPZEel2s0snDyII0fmAJIMhwVTIq0+PrgFvG3EFL31anzS2dGZU5RJoL++JmbwOGHLm8FjW95Q4+GSlA1nPQ7WxidiWxqc+Zga7yr2DBh5HJz+MBz7RyUzHyFcHn+z8WjirW/24fL4unytapeXJ78oDBrbXlJHbUPXr9VZjAZBToqVnBRb2MajwulhY1EVL6zdw84yJ7UN3gjPsoeoLuraeAIQ7Za2JwL3AkbgP1LK29rsvxuY17iZBORKKdMb9/mBbxr37ZZSLuydWWu6jTCA0RocVzBa1Xi4GE2QNwOuWqMMkSUJ7Flg7EZtgDnyircGIbAYDUE6TVaTMawmQkIIUmxmKl3BN2BLtPrad4Lqeg9/f3cLT6/aDaiOxf/6yTROGNcfoyHGGyml5TW6r0KMJyhR+6QJIYzAP4GTgHHAuUKIoEbAUsrrpJRTpJRTgPuBl1vtrm/ap41HnGFLhaOuDx47+ndq1dAdTFbltsoaASkDIIzeGz1Nis3ElfNGBI1d96PDwupvnuWw8KeTxwW1jV84eSAOa+wW1Dnd/mbjASAl3PL6Ziqc4ceBeo3jbmr/UGG2q/FucO655zJ79my2bNlCXl4ejzzySLeu15tEcwUyE9gupdwBIIR4DlgEbO7g+HOBP/fS3DQ9icUBBRfBqB9B0WoYPAtS89SqoY/jsJq48Ih8jh/Xj692VVKQn8mANBv2MIQXDQbB4cMzWfHrY/h8exmj+6cwIscR08q/3hAKuVWurruwGrx+KpwevtpdSV5GEkMy7WQ6erigsSnO8cEtym2VlqeMRzfjH88++2wEJhcdomlABgGt14NFwKxQBwohhgLDgBWthm1CiLWAD7hNSvlqB+deClwKMGTIkAhMWxMRkjLU14BJ0Z5Jr5OeZCE9ycL4gd1ccQEpNjMpNnPcdIB0WE3tuiueN3MwydaurcC+31fDWQ99gdev0qDnj+/P/zt9Ys/3opl0dsIGzEMRTQMSyuHZUVL8YuAlKWXrgoEhUspiIcRwYIUQ4hsp5Q/tLijlUmApQEFBQfeT7uOEBq+f6novbl8Au9kYUbmJOreXugYf/oDEbjElfAMpTefJTrbyxM9m8shnO/m6qIoFEwZw8uSB2C2dX4FVOj3c8sbmZuMB8M6m/Vw/f7T+LPYy0TQgRUDrFmt5QHEHxy4Grmw9IKUsbvy+QwjxETAVaGdAEhGX28cH35fwu/9txOXxk5+VxJMXzWJIVvddRFUuD498tpMHP/oBX0AyIz+Df/1kGjkptgjMvBNICQG/Cpo34amH+nLY9zVk5Kv4R1IUC7Oc5VCzV30NmKxqS0wxrBcVCAABMPTO7SA31cZvThiNy+snxWrC0MXguS8QoNzpaTde6w4v+0xKGVYSQ19Eyq49Y0czXWMNMEoIMUwIYUEZiWVtDxJCjAYygC9ajWUIIayNP2cDc+g4dhKz1Ht8lNQ2UFMf2TTGmgYfv3phA67GLm2F5S5ufGUjVa72/3RdZV91A/ev2I6vsYJ6TWElj68s7PEqaEAJHH5+H7z2Cyj8XNWTAOxbD/dOhufOgwePgA/+CvWVh75eQ43SzepO+nBbnOXw5q/gobnw7GK4byqUfh+560cSKaGmGD76f/D6L5UBbqg99HkRwGwykGY3d9l4AGQkWTj/8ODCzpxkK4PSu541Z7PZKC8v7/KNsy8ipaS8vBybrfMPg1FbgUgpfUKIq4B3UGm8j0opNwkhbgHWSimbjMm5wHMy+C88FnhICBFAGcHbpJRxZUBKa938470tfPh9KeMHpnLzwvEMzoxMELmq3hO0vAf4pqg6Ijf5zcU17cbWFFZS7/F3q+f3Iakrgcd/3FJtvvF5Vacx/Bh489cQaPX0ue5RmHudqufoiKo9sPxGKF4Hw46B4/+sMri6i6scNrcKx/kaYPkNsPiZg88nGtSVwNKj1XeA9U/Bz5bD0NnRndchMBkNnDktj1SbiRfXFpGf7eDa40eRndx191VeXh5FRUWUlmqxTFAGNS+v82nJUa0DkVK+BbzVZuymNts3hzhvJTCxRyfXg9Q0eLlp2be8/c1+APbXNLC1pJaXr5gTkVhFRpKlXYvP2SOyuuRn7ogpQ9pXih87JrfnU0dr97WXKvn07zD0CLUyaUvbiuHW1JXA02e2rAy+fgbq9sOZj3b/Jt9QFeL1DoA/Bovlir9qMR5NfHIHnPWESrXuKvWVSgmgajfkjgN7Jph7xrWZ4bBwdmPfeZvJGPZn22w2M2zYsAjPLnGI3YqjPkyD18+7m4Jvensq6nGG6cNtS7rdzOM/m8HANPXPe/jwTP6ycDwptq7XGrQlJ9nKHWdMItVuwmgQnDZ1IGdNz8PU08VrofzzRjOYbDD1/ODxtMEHl0Txutq7lX5YAd4I6EilD2kff5l2obqZxhrGEJ8HgxnCiQfUV8HHd8IDM+CpM5RLcd+G7s/xIAgh1MNSBB6MwqHS6eHjLSVc/9LXvPxVUbc0zeIVrYUVBQSCQel2dle0qL6ajQJbGLUAobCajczIz+S1q+YQCIDFbCAjQrUBqXYzp04dxDGjc5CAw2Ii2dYLH6PkXBg4TT01N3HsH8GRDXOuhbELlU9fGCB14MG1q4xWVQDWepWS0r97lfBNOHLh5yvgg79A5S6Y8hOYcFpw0D9W6D8RMoZBZaPsvcEE834P1pSuX8tTq0Qxm/B7VCzogtf6ZDOuBq+fJ74o5J731ar4hbVFHD82l7vOmhzTdTiRJgY/1X2f7GQLd501iQseWY3bF0AI+P2CsaRE8EZsMIgey4yymAzkpvZS1lUTjhw473nY8TGUfgcTzlArDVBB8Deug/0b1dP/aQ+BLR0sHQRV7Wmw4E5Ydo3q+2E0w8J/hqeb1RaDATKHwcIHVPzDngGGGK0MT+4HF70DW5erfieTzgpf9yuUBH5NMcgISPWHiZSS0jo3eyrqSbaqVPZIFRvW1HtZ+smOoLH3vyvB6fGT3vfrYZvRBiQKCCGYlJfOJ9fPY29VPf1SbKTaTTisUfpz1JXA1nfgwGaYfI66AXZXVqQnSM5VN7nW1FepJ939G9W2qwKePx+u+bpjA2JOgnGnwvB56iaXlqcMTnd0s9piTVZfsU5KP5h+YfevY09XK7+aVpn4kxZH9XNUXN3AqQ98Tmmja2nuqGzuOWcKWRFSKg7l6Eu0ZGBtQKKEzWzEZjbSr7ef5NtSV6oCyvu+Vtur/gVnP6lcQvGQG+9rgN1fthlzQ33FwZ+mrSnqKwGF8Mpq3Xj8AcxGA9nJlsjUQDhyVQbXe3+Gsu9h7Kkw8+c9IkjZGRq8fh5Ysa3ZeICSu/+h1BkRA5JmN/OLeSO5850tzWMnTehPUpTiMdFCG5BEx1naYjya+PBWGHJEfPiuTTYYcjhse7fVmDU2g9YxwLaSWi7/7zp+KHWSn5XEv8+fzmH9UsKqxwhCCNV0a9H9KrZkS4+qmKXHF2BXeXu3WlGli5nDuv/ZsJqNnDdzCNOHZrD82/3MHJbJrGGZCRX/AJ2FFb+4a1XRWrcLoELVhsRRUZU9HX78D+jfqKmVlAnnPKVuYJogymrdXPakMh6gCkwvfmIt5ZFUwrWmKFdjDxuPSqeHmoP0EUm1m1k8Y3DQmNkomBUB49FEhsPC4cOzuHnheBZMHBAx11g8oVcg8Ybfp7Jm3v+zqo0ouBhGLwhfusPRD/qNhwObWsaO+p2S34gX0gfDBa+Ar16loSZlhU5RTXA8/gA7yoKr7vdW1ePuDRWBCFFd72HVzgoe+ngHDouR608cw8jc5JAZjHMPy+Fvp07g8ZWFpCeZ+eOPxyXkTb4n0QYk3nCVwsPz1AoEYO9XsOifKl00HF92cg5c8Cpsfg32fwvTzoesUSqbKJ5wRCCDqo9jNgoGZ9rZU9GSvtwv1YoFn3qAcGRHrHVvT/Ht3houfXJd8/YXOz7nw98cQ15G+9SnjCQLi2cOYf4E1awqUqnsmhbi7C6hYd83LcajiTWPqOyjcEnOhZmXwMJ7VVe/cPuSa8LH74PqvbBqKax9VK0uA5FdGWQnW3no/On0b0zcyE2xsvScMWS92qgh9vCxMd2etd7j44mVhUFjXr/kg+9KQp+AasGbnWzVxqOH0CuQeMMRIrCd0h+M+h8krqndp27i7katsQ//Bpd9FtF+7EIIRvdP5fWr5+D2BrDIBrKW/RTjrk/VAdVF8PEdcNLtUcueOhgmg4GBIQQTQ41pege9Aok30ger+oUmLMlw/M1gC6N6OJHxOFXxXMlmqN0P3ijKUAQCauXhbiVU6SxTbsUIY2wsMM3LTCK3+IMW49FE2ZbgXvUxhNlk4NKjhpPVqufH+IGpTB2sV8zRQq9Aepk6txeDECRZwnzrHdlwxn+UmqyzRGUfaf9/aOpKYNdKlap82ImN2UFWpXm17T14+RIluWFOgvP/p1rrRqtq3BtCUt7rAr9fyYRYkiMvhzJ4lpIvaa1kPOkcsMZgEWkj/VNtvH3tXL7fV0uS1Uh+poPsCDZL03QNkUg6+AUFBXLt2rVRee26Bh9bS2p5YMV2rCYDvzx+FPlZjojpX2naUHcAHlsA5dvVtskGl30KOYeplccDBeCpazk+LU9pWKVEKYhcthX+NbvlZm62wy++hM3LYNs7kD9X9ZFPzo3ca3pcSlts+Q1Khn7aElX8F08ZeJpeQQixTkpZ0HZcr0B6iV0VTs54cGVz2cb73x3gg18dzZCs+OhlHXcUb2gxHqDcMh/dBoseAL872HiA8v9HUbeJ1MFwxUpYeb+KZ82+Er75H6y4Re0v/Az2rFarz9Yp234fuMpUYoXFoVYP1k5+pixJkH+kSoEOBJRuVxSL/zTxhzYgvYDPH+Cxz3cG1fx5/ZLXNxZz5bxR0ZtYX6atgQDw1CgjYU6CzOFQ0UoMb+gctUqJFhY75IyGk+9W265y+PCvwcf88EH7Pifl2+CJk1XMxGCCBXfBxLO6psMVKjFDo+kEOojeCxiEIDeEMm6fKmpy16n2sHUx0tltyBHtq9HnXNdSKX3+yzDsKLV92Entn+yjhdHcUgRpbrOSMFmDJedd5fDalcp4gHJ/vfXr4GC8JmwqXR5KahuojkAr6L5KVA2IEOJEIcQWIcR2IcQNIfYvEUKUCiE2NH79vNW+C4UQ2xq/IiAn2nMYDIILDh9KZqvskbwMO8eN6Z4/u8rlYW+li6JKFxXOKH7I60rg7d/CfVPgyVOgaI0SNIwmjhy47BOYcQmMWwQXv6v6XzSROUyJRl61Fk5/SCnJxhK2dDj2T8FjR10f3CnQ74XSLcHHBPzt64Q0XUJKSWG5k0ueWMvc2z/k6ufWU1x1kA6XCUzUguhCCCOwFfgRUASsAc5t3dtcCLEEKJBSXtXm3ExgLVCAEm5aB0yXUlYe7DWjGUQPBCRldW7W7qrEYjQweXB6t9rXlte5+cOr37D8W9XZcO7ILO5ZPLX3VzXeenj3T7Dm4ZYxsx2uWQ8pkathCBufp9FtFYe1AvVVKsW4aA0MmgopgyCpVcvdhlp4/WrY9ErLmC0drlwVmf7uvY23QcVzCj9XSQ3Zh0VF0LO01s2Z/14ZJMY4bUg6/7mwIGL9ROKNWAyizwS2Syl3AAghngMWAZsPepZiPvCelLKi8dz3gBOBZ3tort3GYBDkptpYMDEyN9W1uyqbjQfAp9vLeW/zARbPHBKR63eahhrY+nbwmLdepRl31oA4yyHgVe4kS4STCuI5KGxPV1+5Y0Lvt6XAiberAPi25ZA9WsnaRKIxVjQo2wKP/Khl9Zp/pOrP3stp6g1efzsl3692V+HxJU7GameJpgtrELCn1XZR41hbzhBCbBRCvCSEaJLX7Oy5CCEuFUKsFUKsLS2NEf98BFhX2H6xtbqwgkDgEB9yZ6lqtVpTHBlXh8kGOSFucJ15Avb74MC38MxZ8K/D4a3rlTtM03lS+qnMsl9+o7KpBkyKzfa5h6K+Sq1kW7s+Cz+Dmr29PhWLyUBKm+ZuA9NsGHXEuB3RfEtCKf+1vfu9DuRLKScB7wNPdOFcNSjlUillgWmqS9QAACAASURBVJSyICen72SbzJ/Q/gZ9yuSBB+/rULsPnjoD7p0E90yElQ9A/UG9foemqT1s02pDGODYmzrXic5VBo/9GPauU/PY8BR8cEvo9qiajrGlKkMSzwWlAW/oz2JDda9PJd1u5h/nTMFqUrdHh8XIPYunkJWg7quDEc1HlSKgtWB/HlDc+gApZXmrzYeB21ude0ybcz+K+AxjmBE5Dm46eRz3frANf0By2VHDmZJ3EEkHbwN88veW5lEBH3x8G0w4XeX/d4eMYXDpx2pFY7YrV1TrYG9HOMugoSp4bMubcOwfVY2CJnGwZ8Gsy1RWWRNJWSoO0pNI2ZjFJtUcjEasZiNHjszik9/Oo87tI9lmIiPJ3P2mW32QaBqQNcAoIcQwYC+wGDiv9QFCiAFSyn2NmwuB7xp/fge4VQjRdOc7Abix56ccO6QnWTj/8KGcPFk9+afZzFgPVtXucaon/baUfK/qD7qDEOoJuKtV3PZ0dW7rRI6sUbqXRyJiMMDoH8NZDqVGnD4UjvqtapXbUzTUwK7PVW8dnxuO+CWMPw2SMrBbTNgtJmJb3D76RM2ASCl9QoirUMbACDwqpdwkhLgFWCulXAZcI4RYCPiACmBJ47kVQoi/oowQwC1NAfVEwmIyhKwvCYktFQ47QUlXNCEEDJzcM5PrDNZUOO4v8MHNIBsroU+5V0tpJCpJGeoGPuJYVY3f05lzNXvh2cUt229ep8RKR/2oZ1+3D6G1sBIJZyks/wNsekn1DF9wF4w8TrmcokVDjXJ9uavVnJJywKj1wTS9wMd3wof/Fzw2/jQ47SFVtKlpJhbTeDW9jSMHfvx3OOEWQDS2fo3yR8CW2hgvCZlEp9H0HP3GhRibqNoiazqFNiCJhi1F9w7pDs4y5fpw10LWSNUCNpxWwprokzdT1ZoUfqa2c0arls7x1s45imgDotF0lrpSePFCFXgFlTZ7yYeQ3svFm5rIkJyjChXrK1UacVJOVCrf4xltajWazlK6ucV4gFqNfPp3lSKtiU8c2ZA9CnLHaeMRBtqAaDSdpaooxNhu1V9Eo0lAtAtLE380VCslWntm7/qrhx2l0kv9rZSPp/+sc1X3Gk0bfP4AJbVuXv6qiICUnDFtMLmpVsxxpJmiDYgmfvB7VZfBd/+oUpILLoaxp/ReHw9HjpKFf/dPqoJ+1hUwbG7vvLamz1FS62b+3Z9Q61ZtjP/98Q7eu+5oBmXEj3K0NiCa+MFZCg8fC95GrazXr1Fd+Kac1zuZUGYbDJwK5/xXScHYs3TGjiZs/vdVUbPxAHB5/Dy9ahfXn9iB+nIMoj/98YCrAnZ/qYQGt69o6UCXaOz9qsV4NLHuse4LQnYVe4ZajWjjoekG/hDK2b5DqWnHGPo/INbx1ittoEfnq4yfp05ThiQKKqVRJ1R/kdRBKi6h0cQZZ00fTJKlRXXBajJw/uFDozijrqNdWJ3A4/NT6fJSXucmw2EhxWom2dZLb11DtTIcrVn/Xzj6d7EXvPU2qNhAXYlKj7SlRbZBVMZQGHEc/PCB2ralwXE3gTU5cq+h0fQSuakW3r32KJ5atQt/AC6YPZT+qfEloaINSCfYVFzDT/6zCpfHj0HA/506gVOnDCLJ2ktvX8AXvC0DdND+JHr4/bDnS3jmHPA1qNjE6Q/DmAWq6VQkcGTD6UtVJbirAnLHquIvjSYOMRuN5GUmccNJY6M9lbDRLqxDUFbn5tcvfI3L4wcgIOHmZZupafAd9LzyOjclNQ1UOLtZI2BNgRk/Dx4bczKYI9z6tbu4yuCVy5TxAGX0ll2tOs1FEkc2DJgMI+aprodaeFGjiRp6BXIIpITCcmfQmMcfoMHr7+B4yc4yJ1c/u55NxTVMHZzOvYunMCQrzBu+xQFH/QYGz4TvXofhx8DoBUr6OpaQfqjdHzzmqQuumdBoNH0KvQI5BFaTgePGBje1GZhmw2EN/eRbVudmyWNr2FRcA8D6PVVc9tQ6yuu6sRJJymqRmZ7209hsXWqywdAjgsdyRkfOfaVJXHxutZKNsdYT1S4v3++v4ZHPdrKmsKL73oY4RK9ADkGq3czfTp1IsvU7PtpSypgBqdx62kSyk0MHu9y+ALsrglNNv9tXi9sX6P5kYrlTX1ImnPEILL8Rdn4MA6fBKfdAcg92lNP0fWr2wcr74cC3MOlsGH1STDQc8/gCvPXtPm58+ZvmsZ/MGsLvThxDqj2G/08jjDYgnSA31cZfT52Iy+3DYjKQntRx2qjFaCDTYaHC2eK6GZRux2xMAMnv1IGw8H5Vq2GyqZa1Gk241JXAEz+G8h/U9s6P4Zgb4cjrot7wqarew+3Lvw8ae2b1bq6aNzKhDEhUXVhCiBOFEFuEENuFEDeE2P8rIcRmIcRGIcQHQoihrfb5hRAbGr+W9fRck60mclNtBzUeABkOC/88byopjRla6UlmHjhvKlmO+ErPCxtbqgpua+Oh6S71VS3Go4k1/4l8YkY4SKj3BMdBpQR/jLnZepqorUCEEEbgn8CPgCJgjRBimZRyc6vD1gMFUkqXEOIK4A7gnMZ99VLKKb066U5gNhqYPjSD9399NPUeP0kWIxkOCwZDAqxANJpIEmqVYU8HEf3QbbLVxHkzh/DYysLmsRn5GUGFgYlANF1YM4HtUsodAEKI54BFQLMBkVJ+2Or4L4Hze3WGYWIxGemXmlgfJI0m4lhTYMIZ8O3/1LYwwPz/FxNJJElWE1cfN4qxA1N5+5v9FORncE7BYDITxdPQSDQNyCBgT6vtImDWQY6/GHi71bZNCLEW8AG3SSlfDXWSEOJS4FKAIUMSvHOczw0IMHVS+sPtVPUdu79U7VszhsbEP68mQUjKhJPugFmXQ+n3kD9XaZDFSAvhTIeFs6bn8eOJA7CZDBjjSIY9UkTTgIT6FIR0IAohzgcKgKNbDQ+RUhYLIYYDK4QQ30gpf2h7rpRyKbAUoKCgILEclE146qF6N3x+LyDgyGshffChU2z3rlXaW4FGX++EM2HBnb0nn67ROLLV1+CZ0Z5JSIQQOHpLkSIGiabJLAIGt9rOA4rbHiSEOB74A7BQStmcaC2lLG78vgP4CJjak5ONa2r3woNHwIanYcNT6ueafQc/p64Ulv+uxXgAfPsSuGt6dq4ajSZuiKYBWQOMEkIME0JYgMVAUDaVEGIq8BDKeJS0Gs8QQlgbf84G5tAqdqJpw+r/BOtp+T2w/umDnyMDSm+qLd76yM5No9HELVEzIFJKH3AV8A7wHfCClHKTEOIWIcTCxsPuBJKBF9uk644F1gohvgY+RMVAtAHpCGtK+zFb6sHPsWdAwUXBYxn5seG+cpZB7QHwaZkUjSaaCJlAecsFBQVy7dq10Z5G71O9F/49p6XxkiMbLvtUFf4dDFc5bH4dvnkecsfBkb+CtEE9P9+O8NbD/m/g7etVd8KpP1VCk47oVyZrNH0ZIcQ6KWVBu3FtQBKAgB/qDsDWd1UXvVE/Ake/znXUk1L1+DDZVUvXaFJdBPdNUb3RmzjpTphxMRh02nRC4q5VrtaSzZB9GCRlgz3G+uT0AToyIB3eQYQQE4UQXwoh9gghlgohMlrtW91TE9X0AAajWm0ULFFijCkDOt+OVQjlzoq28QAo/irYeABsfE4ZOE3i4ffCtnfhvsnw7GK4f5pqtuZxHvpcTUQ42F3kQeBmYCKwFfhMCDGicV/iiL1oYof0EO0+s0ep1ZEm8XCVw1u/CVbpXXELNOhMwd7iYAYkRUq5XEpZJaW8CxXwXi6EOJyYa4enSQjS8mDi2S3bKf1h3h/AkhS9OWmih5Qtcb0mfG4IeEMfr4k4B6uAkUKINCllNShZESHEGcD/gBhIxdEkHElZcNLtMO9GcNdBcj8tF5/ImO1w2ALY8mbL2KBpYNYPFL3FwQzIRGCsEGKWlPJeACnlRiHEccCfemV2Gk1bkjJjI5VYE33s6arnTNZI+OF9GDwLjr5ey+30Ih1mYQkhNgMnoYr7jqGN9IiUMkSVWWyTsFlYGk1fxudWcQ9rslqVaJBSUlbnoajSRbLVRFaypVtCjx1lYR1sBfIgsBwYDqwj2IDIxnGNRqOJLiYrJOdEexYRpcHrx+n24bCasJm7nqJeXNXAqf/6nNJapf40b3QOd501mawOOqmGS4cGREp5P3C/EOJBKeUVEX1VjUaj0YSkpKaBBz7czqodFcwekcWV80aQk9L5NPp6r5/7VmxrNh4AH24pZWe5s/cMSBPaeGg0Gk3vUOn0cM1z6/lyh4oQbDlQy7aSWh44bxoZh+iG2oTHG2BXeftamD0VLgqGRjZ+mHgC9hqNRhOj1Hv9zcajic+3l9PQpn3uwUi1mzi7YHDQmNkomJkf+eQTbUA0Go0mRjAaRLu2uMlWU5daYgshmDc6l5tPGc/wbAfThmTwwmWzI+6+gug2lEpoPD4/lS4v5XVuMhwWUmxmkhO4MY1Go4E0u5k/nTyOG1/+pnnsTyePJT2pa+IfGQ4LFxw+hJMnDcBoEGQ4OtmFtIvoO1YUkFKyqbiGn/xnFS6PH6NB8H+nTmDRlIEkWeLgTyKlEmfc/gF4XTB6gSroM3bhQ+73q+ZUliSVRaPRaLCZjZw8aQBzRmSxtaSOw/qlkJFkxmrqeiaW0WggO6Vn/7fi4G7V9yiv8/CrF77G1ejX9AckNy/bxLzRufFhQOoOwNJjoLaxq+H7N8MVK1XP9M7gLIMNz6gK4rwZMPtqSOnXU7PVaOKKFJuZFJuZIVmOaE/lkMTB3arvEUC2y5Jw+wI0eDsfKIsqW99pMR4Anjr44l9w4t/AcIiPlLsO3v8LrH9Sbe/+Ego/g5+8CI6+lcuf0LgqlNS69KuGZvpve1BKa93Uub1YjEYcViPpncy4ijZRDaILIU4UQmwRQmwXQtwQYr9VCPF84/5VQoj8VvtubBzfIoSY35vz7i42k5FjxwRrOA1Ms+GwdmGZKiXU7oeNL6qn+Zp9wf3LexJPXYix2mBV1IOdu/HZ4LHi9VqCuy/hLIXXroJ7J8F9U+GpM9SqVROS/dUNnPPQF8y762Pm3L6CW9/6jgpnfHTbjJoBEUIYgX+i5FLGAecKIca1OexioFJKORK4G7i98dxxqB7q44ETgX81Xi8uSLWbufW0iSycPID0JDOzh2fx9CWHk92VLIm6/bD0aHj55/DqFfDgbGVQeoNxC4MF64QBZl/VyRiIAFubhj/CAAbdIaDPsO/rYIHDfV/D+md67wEnjnB7/Tz40XZ2lLU8QL2wtoiiSlcUZ9V5orkCmQlsl1LukFJ6gOeARW2OWQQ80fjzS8BxQgjROP6clNItpdwJbG+8XtyQm2rj1tMn8u61R/Hg+dMYlu1A/WqdZNNrwQajvhLWPtq5VUB3Se6vYh7TL4JJ56j2uJ2NfyRlwom3B4/Nvjp03/bWeJxQUwxl29XvrW9Gscu+je3HiteBPz6eqnuTBq+f7/bXthvfXhJilR+DRDMGMgjY02q7CJjV0TFSSp8QohrIahz/ss25UWzWHR7JVjPJ1jCfvNv2QWgak1J1EexJjGbIHAYn3QEEupZFZTTDqBPg6q9gzxroP0F1S7SldnyOxwmbX4PXf6luQo5suPANyB3b7V9F0wMcdiJ88JfgsUnn9KjQYb3XT73HT6rNhMkYP+VtKTYzJ08cwOqdLcWDBgEFPVD01xNE850OdZdr+/jc0TGdOVddQIhLhRBrhRBrS0tLuzjFGGbyYjC2CrQZjDDr0s63qo0EJnN4Kbi2VMgaAVMWKwNyKHn2hmp4/ZqWJ1hnGbz6C/VdE3ukDYIzHoG0wcrYH3czDJ3TYy+3v7qe/3tjM0seW82/P/6B8jr3oU+KEQwGwcmTB3LF0SNIs5vJz0rikQtnkNVDdRuRJporkCKgdb19HlDcwTFFQggTkAZUdPJcAKSUS4GloOTcIzLzWCBlAFz+GXxyFwR8MPfX6h+2L+Jxtu+FXrJJ/d6a2MOWBuNOg2Fz1WOdPQNMPXNDLKtz89NHV7P1gHL5bCyqZk9lPTedPA5HnBTmZjos/PL4UfzsyHwEguxkS9fc2VEkmiuQNcAoIcQwIYQFFRRf1uaYZcCFjT+fCayQqoHJMmBxY5bWMGAUsLqX5h0bmG2QMxoW3g+L/qWe5C2xnzfelkBAUn8onR9riroJtWbE8br3QyxjNKqOkSn9esx4ALjcvmbj0cQrX+3F6Ymvhwub2Uhuio2cFGvcGA+I4gqkMaZxFfAOYAQelVJuEkLcAqyVUi4DHgH+K4TYjlp5LG48d5MQ4gVgM+ADrpRSJkxUtcLpwecPkGIzY7d0XuY51iirc/Pq+r2sKaxgwcQBzB2VQ2aopXtSNlz4OrxyOZR+DyN/BCf/vX02lybhMBsNGAQEWvkWMh2WkD5uTeTpsCNhXyTeOxJ6/X62HXDy+1e+YXeFi5MnDuCa40d1Lf03RqhwevjF0+uClEcvO2o41x5/GHZLBxnZzjKVfWWygV0bDw3U1Ht58KPtPPjxDkDljyy9oIBjx+Ri7IIAoebghNORUBNBSmsb2FZSh88vGTMghdwuNIhpotLp5eyHvqDOrZbnT365C5NRcP2JY8LqWhZNXB5fO9nqJ74o5OK5wzo2ILrXtaYNqXYzlx09gtOm5fFDSR0TBqWR6TBH3XiU1DawZX8tRiEY1S+FnB7WpIoW2oD0AqW1DZz17y8oLFfFQf1Tbbx21Rz6pXbNiOyrbmg2Hk289c1+Lj9mRNwZEEMIP284gnEaTXqShfQkC4f1O0QtUS9xoKaB0/75OcXVDQAMzUripctnd6mrYLwQPwnTccwH35U0Gw+A/TUNvLBmz0HOCE2o1L5hOQ4scZT33oTDYuTM6XlBY7854TDS7fGRvqjRdMRL64qajQfArnIX727qm1IuegXSC+ytqm83VlTpIhCQXWoUk2o3c/WxI7l/xXYAMpLM/HXR+LgRXmtNWpKF3y8Yw+nTBrF+dxVHH5bD4IwkLKb4M4YaTRNSypAyJEUh7gF9AW1AeoFTpw7inx9uD8oUuWB2fpeMBygDcsnc4SyeMYSaBi9ZDkuPdBnrLTIdVo4YYeWIETq2oekbCCG44PChPLu6xcNgEHDmtLyDnBW/aAPSCwxIs/G/K47g7+9uxRcIcM1xoxialXToE0OQajeTajcziMjXQLjcPmrdPgJSkmQ2kdbFLmgajQaGZCXx3KWHc+/72zAY4NcnjGZAWt+Lf4BO4+1Vauq9SElM3pirXB6eWFnIPz/8AW8gwPxx/fjbaRPjeoWjSTBcFeAqU2KbWaMgKatHixgPRbXLixDqoS/e0Wm8MUAsf5D2VLi4+/1tzdvLNx2gID+Tn80ZFvWUSI3mkLgq4YNbYN1jatucBBe/C/0nRm1KsfigGGl0xFIDwNpd7dV9P91WRr03viQhYgqPS3VurNkHDTXRnk3fpqGyxXgAeF3w1m/UqkTTY+gViAaAmSHko48+LAe7WX9EwsJVofqzfHKnUhGeeBbMv1UXQ/YU9VXtx6r3thfh1EQUvQLRADAow87180djNRkQAn48cQCLpgxMPPdVfaVyh3SXykJY8VfwNYAMwMbn4btlEAh0/9rxiN+vpGjc7ZsnRYTUQe0FNycvbj92MFzlUF8d2Xn1cfTjpQZQ1bw/mzOMM6bnIaUkyWLquZiNq0LdWIVRPZEbYqAC3V2nWq9++Dd1wz/m9zBo6qE7JXZE4Wftx7a+A5MWgyW8DLy4xVUOG1+Er5+B9Hz40c3qeyR71ziy4eL34Z3fQ+UOmHg2FFzUuSB6fRXs/ARW3guWFDj+ZqV0rdWeD4k2IJpm7BZjxzpUkaKmGP53MexaqXqanLYUhsxUAonRpHoPPPHjlpbAT56i+q2EG4QdMrv92Ihjo/979jZ+L3z1JLx/s9re9zXs+hSu+AJS+kfudQxGyB4JZzwMPrdaeRg7+QBUvB5euKBl+5HPVMfM9CGRm18fRbuwYpDaBi/Vrj7ou22ogbd+q4wHqADzs2eH9l834feBsxy8PVzJu/6p9v3k1z4W+tjOkDUC5v5K3cSEgDGnwITTe7djZCxQX6EMSGtcFVDVdSmfTmFLg+TczhsPjwtWLw0e83th27sRn1qF083n28u45/2tfLWrkkpX/PeI1yuQGKLB6+eHkjrufHcLbm+AX8wbweTB6aTa+kg6oNfV3rXjrVe+8VBPo84ydWP/bhn0nwxH/1b1T+8JMvLbj2UOD/96SZlw5K9hxqXKJWZxgD09/OvFKwazaixVsSN4PFbeC4Mp9EojNbKV47UNXv7x3lae+nI3APe8v43fzh/NxUcOizsh1NYk2ONQbFNS6+bUf33OR1tK+WJHORc8sprtbbqtxTUmKwycEjxmNIfuie5xwsd3wPt/hr3rYN2j8OQiqCvpmbmNWxhsMDLyYeKZ3bumNRlSB6ge4bFww/R5VJHdgU3Klejuhc9WUiacdHuw6278GaH/5tHAZIEjrgZHTsvYgCkwaHpEX8bp9vHMqt1BYw+s2E51fXx7GvQKJIZ4Z9N+vP5gN8pjn+9k/MBUrHH8lNKMPQNOuReePhPKtoElGRY9ELqzoLsO1v83eKxsqzIsPUFyP7joHSjfrlxZ2aOUK6QvsX+jMsKeOhUzOPkemHBGz7dCzhkD16yH/d+obKnUAapKPNL43GqVa03tWmJG6iAV7yr5Tn0mM/ODDUoECMjgrokA/rYDcUhUDIgQIhN4HsgHCoGzpZSVbY6ZAjwIpAJ+4G9Syucb9z0OHA005dwtkVJu6I259yT9Q/QHGZBux2jsQ6m0Gfmw5C3lujJZlFEJFVgWqH/iql2txgQYe1CaIjm37xmNJupK4dXLlfEA1dnxzV+r9sA9bUBMVuV67Cn3I6hizZX3wb4NMPZUmHhG52tuhFAu1EgG9duQZDFywrh+vLu5RdZ98czBJFvj+xk+WrO/AfhASnmbEOKGxu3ftTnGBfxUSrlNCDEQWCeEeEdK2RRx/a2U8qVenHOXqWvwUuv24fL4SbGZyHZYD6rAe/jwLEbmJrO9RP2TZzks/OyIfEwxGngtd7pxNvgRAhxWU+h+5qHozE06KQcW3AXPnqNiCAAzL+/5m11fRQag/IfgMb9HPbHHO3Ul8NRpagUBKkmjehfM+2PMpEynJ1n4f6dP5JjROXy+vZwTxvdj7qhsHNqAhMUi4JjGn58APqKNAZFSbm31c7EQogTIAQ6SshM71NR7eWb1bu5Y/j0BCTkpVp6/9HCG5yR3eE5OipXnLjmcbSW11HsDTBiUSk4siRn6feqGY0mmzOXlF0+vY/VOtXCcOyqbu8+ZErn+7AYDDD0Cfvm1ioFkH6bSfrsaS/DWq6dta8fve0JgssGo+bD17Zax1IF9433xOFuMRxPrHocjfhkzBgQgK9nKebOGcub0wX2m7020fot+Usp9AI3fD/pIKoSYCViA1o9QfxNCbBRC3C2EiKG7rKKmwcvtjcYDoLTWzU2vfUv1IVL3slOszB6RzbFjcslNsSFCtH6NCnUH4JM74IWfwtblvLdpX7PxAKWb9cUP5ZF9TWuyypAZfxr0G9+1wKvfBxU74Y1fwf8uUoViDQlcZWxPg1PugQlngi0dhs6Bn76uVnrxTqiUXXumcoPGIH3FeEAPrkCEEO8DoZyKf+jidQYA/wUulLLJl8GNwH6UUVmKWr3c0sH5lwKXAgwZ0nuFQeV1nnZlBVsP1OH2xaGUhbMMnvsJFK0BQKYM5Ctfe3/2+t2VnDK5B/3cXcFZAg/NbZHO2PoO/PQ1GH5MNGcVXVL6KyPicapYUqxkQnUXSzJMv0hl6oGKaZx4OyRp3bGepscMiJTy+I72CSEOCCEGSCn3NRqIkLmZQohU4E3gj1LKL1tde1/jj24hxGPAbw4yj6UoI0NBQUGvpT30T7ORZDHi8vibx44f14+UGKvp8Ackbp8fu9nY8WrH42w2HgCieC2nzr2GF9cFHxYzxgOg8PP2uksr74OB08EWpjxJX8CaEr48S6xiT4fj/gjTL4SSzUoFIFYkcvo40VpLLQMubPz5QuC1tgcIISzAK8CTUsoX2+wb0PhdAKcC3/bobMMgI8nMs5cczpj+KdjNRk6fOohfHX9Yz0uFdIGyOjePfb6TK59ez9OrdlPhdIc+0GgC0eqjUrqF8f4t3HTyWLKTLeSmWLn1tAkMy46hAHdSCBE9eyYYY+f910SQpCxVYzTlPMgc1veMZIwSlY6EQogs4AVgCLAbOEtKWSGEKAAul1L+XAhxPvAYsKnVqUuklBuEECtQAXUBbGg855BVUdHoSFhW5yYgJQ6LKaYyLqpcHn71wtes+L5l8XdWQR5/PnkcyW1XSQ3VsOJWWP3vlrFF/8Q74RyqGvyAICPJjMkYQ77duhJ4cmFLcNWcBJd9ouo7NBpNl+ioI6FuaZugFFfVc8RtK4LGjAbByhuOpV+IehRc5VBRqPLs849U/vRQBYCxRF2JEspzlcGwY7qmkaTRaJrRLW01QRgEmAwCX6tqWOvBskOSstRXXmQlHnqU5Fw4bH60Z6HR9FliyOeg6U2SrSYumjMsaOza4w8jLYb7tms0mthCr0ASlGSbmSuOGcFJE/uzblclhw/PIi/DHtfKoBqNpnfRBiSByXBYyHBYmDqkC20/44RqlwePP0CKzayNoqZXqXC68QeIvcSSHkAbEE2fwh+QFJY5+eNr31JY5mTBhP78Yt5IsmJJEkbTJ3F5fGwqruGW1zdTXe/lgtlDOXNaHhmd1YiLQ7QB0fQpyuvcnPnvlVQ2dnR85PNCfAG44aQxMVWDo+l7VDg9nLv0y+bElL+9+R1ZDgunTR0UO5JEEaZvr680CUeZ09NsPJp4Y2MxtW4vBHwqtfdgLXQ1mjBZtaMiKKsR4MW1RdQ0+KI0o55Hr0A0fYo0W/uP9JDMJMzSC1/+B756XDWPOvE2pfBr6qZry1Wh91pYqwAAFn1JREFUFIoNRiVSaLZ373qauGVodnvl3+E5Dmx9SDyxLX33N9P0CJVOD9tL6li1s5ySmgZ8/tgSh0y2mbly3oiWbauJv502gYxd78K7f1CdEAs/g0d+pIoju0PdAXhxCdw9Hu4vgK+fh4aa7l0zHDxOqN6rFIcrd0VnDhqGZTk4fmyLsPiANBtXzhvZN7qJdoBegcQhUkpKat28tmEvlS4vZxcMpn+qFbulZ/+cFU4Pt7y+iVc3FAOQajPx8i/mMDI3dnpKpNnNXHrUCBbPGEJZnZuB6XYyjW544/7gA731sO/r8LvkeRvg07th58dq21MHb/wShh8NttTu/RJdwe9XBvG5c1XfE4CT7oCp50e1+ZbH76e0xsOL6/ZgEHDm9MHkplj7dFZSVrKVO86cRJXLi8vjp1+qlZyUEKoOfQhtQOKQ0lo3J9//GaW1Svzw4U928OY1RzK6f8/euMrq3M3GA6Cmwcf/vbmZ+xZPJTWGChDT7GbS7GYGZza6FNw+SB+qZE1a050Wq+5aKPy0/XjJd0rMr7dwlcGyq1uMB8B7f4Kxp0TVgJTUuDnh7k+a1aiXfrKTd647ikHpfdvFl+mwkulInIy/vvs40If5Ykd5s/EA8AUk96/YTn0r6fieoKy2vVrv3sp6PLHe48SaDCfdHmwwxi6E1LxuXDMF8ue2H88dG/41w0Kq3iet8blVu9oo8uyq3UGtDOrcPl5auyeKM9L0BHoFEo+E0L/sDVHMEbnJOCxGnK1uDGdOzyPdETurj9YEAsrV99Y3+2jw+lm0ZA05nj1YjAIcOUrbK1zMNjjyOtV/YufHqqnR/L/1fpMmkw0OOwm2vNUyljsOzNGV1g+E+Dwmjmxr4qANSBxy+IgsshwWyp3qKdNoEFx17Kger3PIdFh45co53PL6ZvZV13Pm9DzOKsjDZIjNhWxpnZsF931KReP7dP+K7bxz3VEMyYxQn+yUfnDW4yqeYjCALUMZlt7Enq66DKYOgh8+gIHT4Ee3QHJ0W9WeN2soj60spMGrVqdJFiNnTR8c1TlpIo+Wc49Dmp6sX1y3hwqnh/NnDWVAuo2kHg6iN1Fd78Xr85OeZInpoOiTKwu5admmoLELZw/lT6eMi1mjFzbeehWXMScpl12U8fj8HKhx8/SqXRiE4LxZQ+iXasWsG3rFJVrOvQ9hMAj6p9m4+tjoNEdSir2x6bZqjTfQPjbj8Qf6pi/FbI+pGhSLycjgzCRuOKm3Y0Ka3qSPPYZpNC0smDCA5FZdIM1GwSVzh8f0qkmjiSeisgIRQmQCzwP5QCFwtpSyMsRxfuCbxs3dUsqFjePDgOeATOAr4AIpZXTTTjQxR06KleXXzuXJlbuo9/r52Zx8BvbxNFKNpjeJVk/0O4AKKeVtQogbgAwp5e9CHFcnpWzn0BVCvAC8LKV8Tgjxb+BrKeWDh3rdvhID0XSNQKM+kcEQ44J2HifIgEoR1mhiiI5iINFayy8Cnmj8+Qng1M6eKJSs5bHAS+Gcr0k8DAYR28bDWw8HvoWXL4OXLoI9q8FdF+1Z9R4+D9QeUNIwvva1RrFOpdNDSW0Dlc7Ec4JEK4jeT0q5D0BKuU8IkdvBcTYhxFrAB9wmpXwVyAKqpJRNEpdFwKCOXkgIcSlwKcCQIUMiNX+NJnLU7oelx4C/UUV4+3tw2afQf2JUp9Ur1FcqDbGPb1PV9EdcAzMu7v16mjDZVe7kuuc3sH5PFVMHZ3D3OZMZmhXdGpzepMdWIEKI94UQ34b4WtSFywxpXDadB9wjhPj/7d15dFzVfcDx708aabRvaLG8Y9fYGBxscMC1wdgECBAW0wowCVQ0NtQsTU5bCHCAJicHGkOakhBawEkAs4TNFBAFQ4wXnLQ2YIxBBuMFG6/yIkto12g0c/vHe7KfpJE0fppN1u9zzpyZue+90W/ujOb37nv33TsWCLUr2eNxOGPMImPMVGPM1KKi+PaNVyqkyleOJg8AY+CDJ6zh5wcqY6zEWLkEKl+1Hoc6XF69Bd6500okvnpYeT/s/TgyMbS3Qd0e+OQ52LzUGso/gqobfMxfvI71u77BGFi/q5Ybn1lHdePAa0W5FbUWiDHm/J6WicgBESm1Wx+lQMhP1hizz77fLiKrgCnAq0CeiHjsVshwYF+o7ZUaELJCNMCzShjQnSQbquCJc6Cp2nqeVQI3vQ85pZ3X2/Rm9203LoGx37EuzuyPb3bCEzOt4fYBiiZA+Zuh69sFXyDI1oOdDzVuOdCIzx/dIYUSSby+oRVAuf24HHij6woiki8iXvtxITAD+MJYZ/1XAmW9ba/UgHHSxdZgjx0yC2HqD/v/AxpPnzx/NHmAdX5j45Lu642Y1r1s5PT+v/e2Zlj5i6PJA+DQl7D/M9cvWdvcxt7aFvbUNlPb1EZqslDUZarkomwvKYOom3i8zoEsBF4WkXnALuAqABGZCiwwxswHTgaeEJEgVqJbaIz5wt7+TuBFEbkf+AT4Q6zfgFIRk10C85fB3vXWIIgjzoLMyOwlR0zTITj4pdWyGDXdGkust8m4Qs214kwoHUZOgwmXwZd2S2TMLJhwSf/jDbaDL8TMk611rl7ucKOPu16tZNmmAwDMPKmI/7jqNH77/SnMX7yORl872V4Pj147hYLjeA70rnQoE6VCaGkL0NDqJzlJOCErtsNzt/oD1Lf6SRKhMMZ/G0K896ZD8NL1sGuNtYInDW5cASWn9Pwih7bAY9OODjOf5IFbP4QTxnZft7nGmk8FrEEgM/sxyKXT9lXwjOOUqzfHiqHrYbQwvF1ZxS3Pr+9U9suybzFnylBqmvw0t7WTkeohPyOFVM/xN1yLDmWiVJgON/p4ZPk2Xt+wl2F56Txw5alMLM2JycxyNU0+Hlv5FUvW76E4O43755zKpOG5pMVoVrvDjT5+/d4WKj6tYnh+Ov925SRO9taR2pE8ANpbYdm/QtlTPU+elTsMbloNq38JIjDzDsju4Yc7oyA6va6GToHyt2DNb60W0zm3W/curPu6plvZBztqKDtjOCU5x/ekUb0ZPAfrlApDW3uQP/xlB4vXfE1di58vquqZu2gttc3+Prftr/ZAkD9+sIvf/WUHtc1+Nh9o4Pu/X0ttc4jrCwLt1i2CfP4Ai1Zv59m1u6hr8fP5vnquWbSG2uRCKwk4tdR07jnWVWomDDkVrnwM5jxmtVZSO4+CfLjRx8c7a3hnYxX761rwByJ88jktF048G8qehEv+HQpGQ7K7feaLJ3VPfpefNhTpWi+DjLZAlHKoa2lj6cb9ncp87UF2VDcyJDe6e5p1LX7eqqzqVOYPGDbtq6c01x6Cxd8K9Xvg/x61nk+/zZoYKwLDyNe3+nl7Y+e/3+oPsrPOT8kJ46wutx3Oujm8VkNK6KHzDzf6uPWP61m73dqzT09JpuK2GYwricJV+BGYmXFccRb3XXoyv1m+FROEBbPGMml4bgSCG9g0gSjlkJaSzNiiTHZUN3UqH5Ib/TG00lKSGVecxaaqhk7lI5zzlzRUwX/99dEZBzc8bx3Xj8A0ul5PMn9VnMXumpZO5SW5GfCDJfD+g1C/F749H0af3b1Vcgz21LYcSR4ALf4AC9/5kl9fM5nstMQb6TkvI5Xrp43mstOsWS1z01PwHofnOo6VHsJSyiE7LYX7Lp1IcfbRk9f/MHMM+RnR/1HL9Hr4yUUTGOpo6ZRPH02hIxY+Xtx5utpAm1UWATnpKfz00lOOdE0VgVtmjSUvPQXyR8H3fgVXP2PNt56e36+/FeqwXHWDD38gcTv1pHqSKM5Oozg7TZOHTVsgKqG1tAVo8PnxepLteUiib2RBBv/zo7Opa/aT6fWQ5fWQE6O/PTw/gzduO5u65jbSUz1keZPJzXB0Cw0150cE5wEZWZDBWz/u4b1HcM6Rk0tzyEnzUN969DxO+fTRMUnUKnK0G69KWIcafDyyfCvLNx1g/JBsfnb5KYwsyBjcJy7r9sLjM6yhP8BqCSz4X6vX0wASCATZXdvCr/60mf31rVw3bRQzTyoiP2PwXEMxkPTUjVcTiEpIjT4/972+kdc+OTpKTWluGhW3zaAoe/B2myQYsK7q/vItwMCES61hQpIG5iGVJl87bYGgJo4Ep9eBqAGluS3A25Wde0NV1bXS6AtQNJiny0hKhpyhcOaN8Y4kIjK9HgbP2LXHHz2JrhJSkgjD8zt3AU1OEtJT9CurVKLQ/0aVkAqzvDxUNgmv5+hX9PYLx3ea41wpFV/636gS1qlDc1n9k9nsqW2hJMdLTnoKWQl4jYBSg5UmEJWwvCnJlKQkD+qxhpRKZHoISymllCuaQJRSSrmiCUQppZQreg5EKTUg1DS1UdfiJxAIkpeR2nmMMBUXcUkgIlIAvASMBr4GrjbG1HZZZzbwsKNoAjDXGPO6iDwNnAt0zE95gzFmQ5TDVqpfjDHUtVjjeqWnDswrx+OlutHHP720gT9vtabFPakki+fmnUWxdrCIq3gdwroLWG6MGQcst593YoxZaYyZbIyZDJwHNAN/cqxyR8dyTR4q0dU2tfHf6/dy4zPruPf1jeyuaSYYHDzDCPXXht3fHEkeAFsONPLKx7sJaB3GVbwOYV0BzLIfLwZWAXf2sn4ZsNQY0xzdsJSKvEAgSMWn+/hpxecAfPR1Las2H2Tpj8+J2R50IGg43OijrsVPVpo1ym4izrvRk837G7qVfb6vnvZgkOQBOg7Y8SBeLZASY0wVgH1f3Mf6c4EXupQ9ICKficjDItLjwVARuUlE1onIukOHDvUvaqVcqG3x8+zanZ3KDje1sasmdvtDO6qbuPg3f+aCh1czY+EKnlu7k/qW6E/TGykXTCzpVlZ2xgidlyPOopZAROQ9EdkY4nbFMb5OKTAJeNdRfDfWOZFvAwX00noxxiwyxkw1xkwtKipy8U6U6h9PklCQ2X202ZwYtQBqm9u49/VKDjdZkzgFDTz07mYafJGdUz2aSnPTWHT9GYwtymRYXjo/u+wUpozIi3dYg17UDmEZY87vaZmIHBCRUmNMlZ0gDvbyUlcDrxljjuwudbReAJ+IPAXcHpGglYqCvIxU7v3eyZQ9toa2QBCA2eOLKMyOzRDm/vYgXx3sPEWvMVavpmF50Z+qNxKy01K4YGIJp4/KxxjIz0zBk6RXIcRbvM6BVADlwEL7/o1e1r0Wq8VxhCP5CDAH2BitQJWKhPFDsll1xyw+3lnLsPx0RhVkUJAZm26o2Wkezp9YzAsf7j5SluX1UDLAusGKCIVZAyvm4128EshC4GURmQfsAq4CEJGpwAJjzHz7+WhgBPB+l+2fF5EiQIANwILYhK2UO15PMkPz0hkahz3+9FQP/3LheNqDhncq9zOqMIMH/+Zb5GcOnJPoKjHpjIRKDRJNvnaafO0kJwkn6J68OgY6I6FSg1ym10OmzqeiIkjPQimllHJFE4hSSilXNIEopZRyRROIUkopVzSBKKWUckUTiFJKKVc0gSillHJlUF1IKCKHgJ19rhhZhUB1n2vFj8bnXiLHBokdXyLHBhpfV6OMMd1Gox1UCSQeRGRdqCs4E4XG514ixwaJHV8ixwYaX7j0EJZSSilXNIEopZRyRRNI9C2KdwB90PjcS+TYILHjS+TYQOMLi54DUUop5Yq2QJRSSrmiCUQppZQrmkAiQEQKRGSZiGy17/NDrDNbRDY4bq0iMsde9rSI7HAsmxzr+Oz1Ao4YKhzlJ4rIB/b2L4lIxCbzDrPuJovIGhH5XEQ+E5FrHMuiUncicpGIbBaRbSJyV4jlXrsuttl1M9qx7G67fLOIfDcS8RxjbP8sIl/YdbVcREY5loX8jGMc3w0icsgRx3zHsnL7u7BVRMrjENvDjri2iMg3jmWxqLsnReSgiIScplssj9jxfyYipzuWRbXuQjLG6K2fN+Ah4C778V3Ag32sXwDUABn286eBsnjHBzT2UP4yMNd+/DhwcyxjA04CxtmPhwJVQF606g5IBr4CxgCpwKfAxC7r3AI8bj+eC7xkP55or+8FTrRfJznGsc12fLdu7oitt884xvHdADwaYtsCYLt9n28/zo9lbF3W/0fgyVjVnf03ZgKnAxt7WH4JsBRrOu9pwAexqLuebtoCiYwrgMX248XAnD7WLwOWGmOaoxrVUcca3xEiIsB5wBI320ciNmPMFmPMVvvxPuAg0O2q2Ag6E9hmjNlujGkDXrTjdHLGvQT4jl1XVwAvGmN8xpgdwDb79WIWmzFmpeO7tRYYHsG/3+/4evFdYJkxpsYYUwssAy6KY2zXAi9E8O/3yRizGmvnsidXAM8Yy1ogT0RKiX7dhaQJJDJKjDFVAPZ9cR/rz6X7F/MBu0n6sIhEesLqcONLE5F1IrK24/AacALwjTGm3X6+BxgWh9gAEJEzsfYev3IUR7ruhgG7Hc9Dvecj69h1U4dVV+FsG+3YnOZh7bF2CPUZR1K48f2t/ZktEZERx7httGPDPux3IrDCURztugtHT+8h2nUXkk6QHCYReQ8YEmLRPcf4OqXAJOBdR/HdwH6sH8ZFwJ3Az+MQ30hjzD4RGQOsEJFKoD7EesfU9zvCdfcsUG6MCdrF/a67UH8qRFnX99zTOuFs2x9hv76IXAdMBc51FHf7jI0xX4XaPorxvQm8YIzxicgCrJbceWFuG+3YOswFlhhjAo6yaNddOOL1vQtJE0iYjDHn97RMRA6ISKkxpsr+kTvYy0tdDbxmjPE7XrvKfugTkaeA2+MRn314CGPMdhFZBUwBXsVqJnvsPe3hwL5YxyYiOcBbwL12073jtftddyHsAUY4nod6zx3r7BERD5CLdeghnG2jHRsicj5Wgj7XGOPrKO/hM47kj2Cf8RljDjue/g540LHtrC7broplbA5zgVudBTGou3D09B6iXXch6SGsyKgAOno9lANv9LJut+Oq9g9nx/mGOUDIHhjRjE9E8jsO/4hIITAD+MJYZ+hWYp236XH7KMeWCryGdez3lS7LolF3HwHjxOp9lor1Y9K1140z7jJghV1XFcBcsXppnQiMAz6MQExhxyYiU4AngMuNMQcd5SE/4wjGFm58pY6nlwOb7MfvAhfaceYDF9K5pR712Oz4xmOdiF7jKItF3YWjAvg7uzfWNKDO3omKdt2FFu2z9IPhhnXsezmw1b4vsMunAr93rDca2Askddl+BVCJ9eP3HJAV6/iA6XYMn9r38xzbj8H6EdwGvAJ4YxzbdYAf2OC4TY5m3WH1dtmCtYd5j132c6wfZYA0uy622XUzxrHtPfZ2m4GLo/B96yu294ADjrqq6OszjnF8vwA+t+NYCUxwbPtDu063AX8f69js5z8DFnbZLlZ19wJWL0M/VqtiHrAAWGAvF+A/7fgrgamxqrtQNx3KRCmllCt6CEsppZQrmkCUUkq5oglEKaWUK5pAlFJKuaIJRCmllCuaQJSKAxH5kYhsEpFXxRpp2CcikbgIUqmY0SvRlYqPW4CLgSZgFJEdoFKpmNAWiFIxJiKPY12cWQH8wBjzEdaFY0oNKNoCUSrGjDELROQiYLYxpjre8SjllrZAlFJKuaIJRCmllCuaQJRSSrmigykqFQci8jXWiMMeYB2QAwSBRqx5ukNN5KVUQtEEopRSyhU9hKWUUsoVTSBKKaVc0QSilFLKFU0gSimlXNEEopRSyhVNIEoppVzRBKKUUsqV/wfS3kQCrJTg8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt.columns = ['f1','f2','output']\n",
    "sns.scatterplot(x='f1', y='f2',hue='output', data=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapFeaturePlot(x1,x2,degree):\n",
    "    \"\"\"\n",
    "    take in numpy array of x1 and x2, return all polynomial terms up to the given degree\n",
    "    \"\"\"\n",
    "    \n",
    "    out = np.ones(1)\n",
    "    for i in range(1,degree+1):\n",
    "        for j in range(i+1):\n",
    "            terms= (x1**(i-j) * x2**j)\n",
    "            out= np.hstack((out,terms))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36666666666666664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "poly_features = PolynomialFeatures(degree = 1) #To ensure no intercept is added\n",
    "X_train=poly_features.fit_transform(X_train)\n",
    "X_test = poly_features.transform(X_test)\n",
    "print(X_train.shape)\n",
    "no_reg = linear_model.LogisticRegression(penalty = 'none', solver = 'newton-cg', fit_intercept=True)\n",
    "no_reg.fit(X_train,y_train)\n",
    "accuracy_score(y_test, no_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_(no_reg.coef_[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "poly_features = PolynomialFeatures(degree = 6) #To ensure no intercept is added\n",
    "X_train=poly_features.fit_transform(X_train)\n",
    "X_test = poly_features.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 28) (59, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6610169491525424"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_reg = linear_model.LogisticRegression(penalty = 'none', solver = 'newton-cg') #\n",
    "no_reg.fit(X_train,y_train)\n",
    "accuracy_score(y_test, no_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_(no_reg.coef_[0],6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek Kapoor\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 303 out of 303 | elapsed:    0.2s finished\n",
      "C:\\Users\\Abhishek Kapoor\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#penalty = [ 'l2']\n",
    "C = np.arange(0.01,5,0.05) #Remeber, lower is greater regularization\n",
    "C = np.append(0.001,C)\n",
    "hyperparameters = dict(C=C)\n",
    "sk_logistic = linear_model.LogisticRegression(solver = 'liblinear') #Supports both regularization types \n",
    "clf = GridSearchCV(sk_logistic, hyperparameters, verbose=1)\n",
    "best_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.66}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847457627118644"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, best_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_(best_model.best_estimator_.coef_[0],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847457627118644"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mylogit(tol=1e-5, max_iter=10000, intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_(model.beta,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout : 0.0, test accuracy: 0.8475, convergence: True, rounds : 3998\n",
      "Dropout : 0.05, test accuracy: 0.8475, convergence: True, rounds : 7170\n",
      "Dropout : 0.1, test accuracy: 0.8475, convergence: True, rounds : 7598\n",
      "Dropout : 0.15, test accuracy: 0.8475, convergence: True, rounds : 7887\n",
      "Dropout : 0.2, test accuracy: 0.8475, convergence: True, rounds : 8184\n",
      "Dropout : 0.25, test accuracy: 0.8305, convergence: True, rounds : 8868\n",
      "Dropout : 0.3, test accuracy: 0.8305, convergence: True, rounds : 8881\n",
      "Dropout : 0.35, test accuracy: 0.8305, convergence: True, rounds : 8857\n",
      "Dropout : 0.4, test accuracy: 0.8136, convergence: True, rounds : 11970\n",
      "Dropout : 0.45, test accuracy: 0.8136, convergence: True, rounds : 12617\n",
      "Dropout : 0.5, test accuracy: 0.8475, convergence: True, rounds : 9852\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = np.arange(0.00,0.55,0.05)\n",
    "acc = []\n",
    "for c in dropout_rates:\n",
    "    model = mylogit(tol=1e-5, max_iter=20000,dropout_rate=c, intercept=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    acc.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "    print(f'Dropout : {round(c,2)}, test accuracy: {round(acc[-1],4)}, convergence: {model.converged}, rounds : {model.iterations}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847457627118644"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mylogit(tol=1e-5, max_iter=10000, intercept=False,dropout_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_(model.beta,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0, train_loss: 0.6825810620436247, val_loss: 0.6925886990876448 \n",
      "round 1, train_loss: 0.6818727222338438, val_loss: 0.6921661500181676 \n",
      "round 2, train_loss: 0.6811830742225082, val_loss: 0.6917482726095926 \n",
      "round 3, train_loss: 0.6805109237323764, val_loss: 0.6913343609410385 \n",
      "round 4, train_loss: 0.679855158689652, val_loss: 0.6909237752626188 \n",
      "round 5, train_loss: 0.6792147435249271, val_loss: 0.6905159367878009 \n",
      "round 6, train_loss: 0.6785887138638239, val_loss: 0.6901103228623601 \n",
      "round 7, train_loss: 0.6779761715821243, val_loss: 0.6897064624851228 \n",
      "round 8, train_loss: 0.6773762802015484, val_loss: 0.6893039321570021 \n",
      "round 9, train_loss: 0.6767882606036746, val_loss: 0.6889023520361163 \n",
      "round 10, train_loss: 0.67621138704079, val_loss: 0.6885013823780498 \n",
      "round 11, train_loss: 0.6756449834237204, val_loss: 0.6881007202415332 \n",
      "round 12, train_loss: 0.6750884198679062, val_loss: 0.6877000964410313 \n",
      "round 13, train_loss: 0.6745411094801381, val_loss: 0.6872992727288603 \n",
      "round 14, train_loss: 0.6740025053694911, val_loss: 0.6868980391905599 \n",
      "round 15, train_loss: 0.67347209786703, val_loss: 0.6864962118382967 \n",
      "round 16, train_loss: 0.6729494119398848, val_loss: 0.6860936303880715 \n",
      "round 17, train_loss: 0.6724340047862126, val_loss: 0.6856901562074467 \n",
      "round 18, train_loss: 0.6719254635984847, val_loss: 0.685285670421416 \n",
      "round 19, train_loss: 0.6714234034833553, val_loss: 0.6848800721648629 \n",
      "round 20, train_loss: 0.6709274655271809, val_loss: 0.6844732769708718 \n",
      "round 21, train_loss: 0.6704373149969897, val_loss: 0.6840652152848852 \n",
      "round 22, train_loss: 0.6699526396674039, val_loss: 0.6836558310954103 \n",
      "round 23, train_loss: 0.6694731482646703, val_loss: 0.6832450806726289 \n",
      "round 24, train_loss: 0.6689985690195734, val_loss: 0.6828329314068893 \n",
      "round 25, train_loss: 0.6685286483215597, val_loss: 0.682419360739613 \n",
      "round 26, train_loss: 0.6680631494669587, val_loss: 0.6820043551797083 \n",
      "round 27, train_loss: 0.6676018514946671, val_loss: 0.6815879093990626 \n",
      "round 28, train_loss: 0.6671445481031327, val_loss: 0.6811700254011669 \n",
      "round 29, train_loss: 0.6666910466429153, val_loss: 0.6807507117573397 \n",
      "round 30, train_loss: 0.6662411671794932, val_loss: 0.6803299829054457 \n",
      "round 31, train_loss: 0.6657947416213685, val_loss: 0.6799078585063569 \n",
      "round 32, train_loss: 0.6653516129088712, val_loss: 0.6794843628537647 \n",
      "round 33, train_loss: 0.66491163425939, val_loss: 0.6790595243332749 \n",
      "round 34, train_loss: 0.6644746684650529, val_loss: 0.6786333749270103 \n",
      "round 35, train_loss: 0.6640405872391762, val_loss: 0.6782059497602351 \n",
      "round 36, train_loss: 0.6636092706080449, val_loss: 0.6777772866867635 \n",
      "round 37, train_loss: 0.6631806063448441, val_loss: 0.6773474259101674 \n",
      "round 38, train_loss: 0.6627544894427856, val_loss: 0.676916409638006 \n",
      "round 39, train_loss: 0.6623308216246666, val_loss: 0.6764842817665203 \n",
      "round 40, train_loss: 0.6619095108863272, val_loss: 0.6760510875934206 \n",
      "round 41, train_loss: 0.6614904710716129, val_loss: 0.6756168735565655 \n",
      "round 42, train_loss: 0.6610736214766509, val_loss: 0.6751816869965135 \n",
      "round 43, train_loss: 0.6606588864813863, val_loss: 0.6747455759410593 \n",
      "round 44, train_loss: 0.6602461952064697, val_loss: 0.6743085889100277 \n",
      "round 45, train_loss: 0.6598354811937386, val_loss: 0.6738707747387057 \n",
      "round 46, train_loss: 0.6594266821086378, val_loss: 0.6734321824184446 \n",
      "round 47, train_loss: 0.659019739463055, val_loss: 0.6729928609530419 \n",
      "round 48, train_loss: 0.6586145983571529, val_loss: 0.6725528592296416 \n",
      "round 49, train_loss: 0.6582112072388752, val_loss: 0.672112225902987 \n",
      "round 50, train_loss: 0.6578095176799005, val_loss: 0.6716710092919199 \n",
      "round 51, train_loss: 0.6574094841669059, val_loss: 0.6712292572871448 \n",
      "round 52, train_loss: 0.6570110639070733, val_loss: 0.6707870172693231 \n",
      "round 53, train_loss: 0.6566142166468615, val_loss: 0.6703443360366358 \n",
      "round 54, train_loss: 0.656218904503119, val_loss: 0.6699012597410371 \n",
      "round 55, train_loss: 0.6558250918056933, val_loss: 0.6694578338324559 \n",
      "round 56, train_loss: 0.6554327449507328, val_loss: 0.6690141030102785 \n",
      "round 57, train_loss: 0.6550418322639572, val_loss: 0.6685701111814901 \n",
      "round 58, train_loss: 0.6546523238731997, val_loss: 0.6681259014248909 \n",
      "round 59, train_loss: 0.6542641915895901, val_loss: 0.6676815159608733 \n",
      "round 60, train_loss: 0.6538774087967794, val_loss: 0.6672369961262519 \n",
      "round 61, train_loss: 0.653491950347659, val_loss: 0.6667923823537091 \n",
      "round 62, train_loss: 0.6531077924680606, val_loss: 0.6663477141554348 \n",
      "round 63, train_loss: 0.6527249126669505, val_loss: 0.6659030301105738 \n",
      "round 64, train_loss: 0.6523432896526887, val_loss: 0.6654583678561306 \n",
      "round 65, train_loss: 0.6519629032549193, val_loss: 0.6650137640810068 \n",
      "round 66, train_loss: 0.6515837343517286, val_loss: 0.6645692545228652 \n",
      "round 67, train_loss: 0.6512057648016918, val_loss: 0.6641248739675517 \n",
      "round 68, train_loss: 0.6508289773804881, val_loss: 0.6636806562508115 \n",
      "round 69, train_loss: 0.6504533557217698, val_loss: 0.6632366342620774 \n",
      "round 70, train_loss: 0.6500788842619899, val_loss: 0.6627928399501026 \n",
      "round 71, train_loss: 0.6497055481889301, val_loss: 0.6623493043302469 \n",
      "round 72, train_loss: 0.6493333333936679, val_loss: 0.6619060574932366 \n",
      "round 73, train_loss: 0.648962226425755, val_loss: 0.6614631286152263 \n",
      "round 74, train_loss: 0.6485922144513864, val_loss: 0.6610205459690104 \n",
      "round 75, train_loss: 0.6482232852143593, val_loss: 0.6605783369362468 \n",
      "round 76, train_loss: 0.6478554269996347, val_loss: 0.6601365280205626 \n",
      "round 77, train_loss: 0.647488628599317, val_loss: 0.6596951448614231 \n",
      "round 78, train_loss: 0.6471228792809041, val_loss: 0.6592542122486597 \n",
      "round 79, train_loss: 0.646758168757635, val_loss: 0.6588137541375533 \n",
      "round 80, train_loss: 0.6463944871608112, val_loss: 0.658373793664387 \n",
      "round 81, train_loss: 0.6460318250139471, val_loss: 0.6579343531623881 \n",
      "round 82, train_loss: 0.645670173208633, val_loss: 0.6574954541779787 \n",
      "round 83, train_loss: 0.6453095229819884, val_loss: 0.6570571174872699 \n",
      "round 84, train_loss: 0.6449498658956094, val_loss: 0.6566193631127453 \n",
      "round 85, train_loss: 0.6445911938158958, val_loss: 0.6561822103400582 \n",
      "round 86, train_loss: 0.6442334988956807, val_loss: 0.6557456777349202 \n",
      "round 87, train_loss: 0.6438767735570595, val_loss: 0.6553097831600069 \n",
      "round 88, train_loss: 0.6435210104753527, val_loss: 0.6548745437918577 \n",
      "round 89, train_loss: 0.6431662025641143, val_loss: 0.6544399761377295 \n",
      "round 90, train_loss: 0.642812342961123, val_loss: 0.6540060960523627 \n",
      "round 91, train_loss: 0.642459425015291, val_loss: 0.6535729187546389 \n",
      "round 92, train_loss: 0.6421074422744211, val_loss: 0.6531404588441001 \n",
      "round 93, train_loss: 0.6417563884737657, val_loss: 0.652708730317306 \n",
      "round 94, train_loss: 0.6414062575253278, val_loss: 0.6522777465840046 \n",
      "round 95, train_loss: 0.6410570435078545, val_loss: 0.6518475204831058 \n",
      "round 96, train_loss: 0.6407087406574825, val_loss: 0.6514180642984341 \n",
      "round 97, train_loss: 0.6403613433589823, val_loss: 0.6509893897742488 \n",
      "round 98, train_loss: 0.6400148461375742, val_loss: 0.6505615081305217 \n",
      "round 99, train_loss: 0.6396692436512647, val_loss: 0.6501344300779587 \n",
      "round 100, train_loss: 0.6393245306836781, val_loss: 0.6497081658327568 \n",
      "round 101, train_loss: 0.6389807021373476, val_loss: 0.6492827251310931 \n",
      "round 102, train_loss: 0.6386377530274355, val_loss: 0.6488581172433312 \n",
      "round 103, train_loss: 0.6382956784758508, val_loss: 0.64843435098795 \n",
      "round 104, train_loss: 0.6379544737057438, val_loss: 0.648011434745186 \n",
      "round 105, train_loss: 0.6376141340363501, val_loss: 0.6475893764703836 \n",
      "round 106, train_loss: 0.6372746548781592, val_loss: 0.647168183707059 \n",
      "round 107, train_loss: 0.6369360317283869, val_loss: 0.6467478635996713 \n",
      "round 108, train_loss: 0.6365982601667357, val_loss: 0.6463284229060987 \n",
      "round 109, train_loss: 0.6362613358514166, val_loss: 0.6459098680098284 \n",
      "round 110, train_loss: 0.6359252545154236, val_loss: 0.6454922049318536 \n",
      "round 111, train_loss: 0.6355900119630357, val_loss: 0.6450754393422794 \n",
      "round 112, train_loss: 0.6352556040665394, val_loss: 0.6446595765716481 \n",
      "round 113, train_loss: 0.634922026763151, val_loss: 0.6442446216219732 \n",
      "round 114, train_loss: 0.6345892760521304, val_loss: 0.6438305791774978 \n",
      "round 115, train_loss: 0.634257347992069, val_loss: 0.6434174536151706 \n",
      "round 116, train_loss: 0.6339262386983452, val_loss: 0.6430052490148499 \n",
      "round 117, train_loss: 0.6335959443407334, val_loss: 0.6425939691692376 \n",
      "round 118, train_loss: 0.6332664611411576, val_loss: 0.6421836175935403 \n",
      "round 119, train_loss: 0.6329377853715789, val_loss: 0.6417741975348775 \n",
      "round 120, train_loss: 0.6326099133520118, val_loss: 0.6413657119814227 \n",
      "round 121, train_loss: 0.6322828414486538, val_loss: 0.6409581636712953 \n",
      "round 122, train_loss: 0.6319565660721327, val_loss: 0.640551555101204 \n",
      "round 123, train_loss: 0.6316310836758484, val_loss: 0.6401458885348403 \n",
      "round 124, train_loss: 0.6313063907544171, val_loss: 0.6397411660110423 \n",
      "round 125, train_loss: 0.6309824838422057, val_loss: 0.6393373893517138 \n",
      "round 126, train_loss: 0.6306593595119457, val_loss: 0.6389345601695193 \n",
      "round 127, train_loss: 0.6303370143734326, val_loss: 0.638532679875354 \n",
      "round 128, train_loss: 0.6300154450722937, val_loss: 0.6381317496855913 \n",
      "round 129, train_loss: 0.629694648288829, val_loss: 0.6377317706291196 \n",
      "round 130, train_loss: 0.629374620736915, val_loss: 0.6373327435541641 \n",
      "round 131, train_loss: 0.6290553591629696, val_loss: 0.636934669134909 \n",
      "round 132, train_loss: 0.6287368603449719, val_loss: 0.636537547877916 \n",
      "round 133, train_loss: 0.62841912109154, val_loss: 0.6361413801283481 \n",
      "round 134, train_loss: 0.628102138241052, val_loss: 0.6357461660760062 \n",
      "round 135, train_loss: 0.6277859086608204, val_loss: 0.6353519057611757 \n",
      "round 136, train_loss: 0.6274704292463033, val_loss: 0.6349585990802948 \n",
      "round 137, train_loss: 0.6271556969203631, val_loss: 0.6345662457914483 \n",
      "round 138, train_loss: 0.6268417086325591, val_loss: 0.6341748455196844 \n",
      "round 139, train_loss: 0.6265284613584773, val_loss: 0.6337843977621722 \n",
      "round 140, train_loss: 0.6262159520990956, val_loss: 0.633394901893189 \n",
      "round 141, train_loss: 0.6259041778801763, val_loss: 0.6330063571689558 \n",
      "round 142, train_loss: 0.6255931357516944, val_loss: 0.6326187627323134 \n",
      "round 143, train_loss: 0.6252828227872882, val_loss: 0.6322321176172543 \n",
      "round 144, train_loss: 0.624973236083739, val_loss: 0.6318464207533051 \n",
      "round 145, train_loss: 0.6246643727604749, val_loss: 0.631461670969769 \n",
      "round 146, train_loss: 0.6243562299590957, val_loss: 0.6310778669998315 \n",
      "round 147, train_loss: 0.6240488048429231, val_loss: 0.6306950074845319 \n",
      "round 148, train_loss: 0.6237420945965686, val_loss: 0.630313090976604 \n",
      "round 149, train_loss: 0.6234360964255192, val_loss: 0.6299321159441946 \n",
      "round 150, train_loss: 0.6231308075557452, val_loss: 0.6295520807744556 \n",
      "round 151, train_loss: 0.6228262252333212, val_loss: 0.6291729837770172 \n",
      "round 152, train_loss: 0.6225223467240653, val_loss: 0.6287948231873526 \n",
      "round 153, train_loss: 0.6222191693131909, val_loss: 0.6284175971700209 \n",
      "round 154, train_loss: 0.6219166903049748, val_loss: 0.6280413038218102 \n",
      "round 155, train_loss: 0.6216149070224374, val_loss: 0.6276659411747693 \n",
      "round 156, train_loss: 0.6213138168070369, val_loss: 0.6272915071991416 \n",
      "round 157, train_loss: 0.6210134170183707, val_loss: 0.6269179998061972 \n",
      "round 158, train_loss: 0.6207137050338947, val_loss: 0.626545416850971 \n",
      "round 159, train_loss: 0.6204146782486482, val_loss: 0.6261737561349046 \n",
      "round 160, train_loss: 0.6201163340749898, val_loss: 0.6258030154084013 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 161, train_loss: 0.6198186699423422, val_loss: 0.6254331923732939 \n",
      "round 162, train_loss: 0.6195216832969483, val_loss: 0.6250642846852221 \n",
      "round 163, train_loss: 0.6192253716016327, val_loss: 0.6246962899559358 \n",
      "round 164, train_loss: 0.6189297323355709, val_loss: 0.6243292057555112 \n",
      "round 165, train_loss: 0.6186347629940706, val_loss: 0.6239630296144957 \n",
      "round 166, train_loss: 0.6183404610883518, val_loss: 0.6235977590259748 \n",
      "round 167, train_loss: 0.6180468241453421, val_loss: 0.623233391447566 \n",
      "round 168, train_loss: 0.6177538497074752, val_loss: 0.6228699243033459 \n",
      "round 169, train_loss: 0.6174615353324902, val_loss: 0.6225073549857066 \n",
      "round 170, train_loss: 0.6171698785932463, val_loss: 0.6221456808571472 \n",
      "round 171, train_loss: 0.6168788770775345, val_loss: 0.6217848992520008 \n",
      "round 172, train_loss: 0.6165885283878996, val_loss: 0.6214250074781028 \n",
      "round 173, train_loss: 0.6162988301414641, val_loss: 0.6210660028183949 \n",
      "round 174, train_loss: 0.616009779969758, val_loss: 0.6207078825324746 \n",
      "round 175, train_loss: 0.6157213755185535, val_loss: 0.6203506438580906 \n",
      "round 176, train_loss: 0.6154336144477025, val_loss: 0.619994284012577 \n",
      "round 177, train_loss: 0.6151464944309798, val_loss: 0.6196388001942433 \n",
      "round 178, train_loss: 0.6148600131559283, val_loss: 0.6192841895837087 \n",
      "round 179, train_loss: 0.6145741683237079, val_loss: 0.618930449345189 \n",
      "round 180, train_loss: 0.6142889576489526, val_loss: 0.6185775766277365 \n",
      "round 181, train_loss: 0.614004378859622, val_loss: 0.6182255685664315 \n",
      "round 182, train_loss: 0.6137204296968641, val_loss: 0.6178744222835346 \n",
      "round 183, train_loss: 0.613437107914878, val_loss: 0.6175241348895903 \n",
      "round 184, train_loss: 0.6131544112807785, val_loss: 0.6171747034844915 \n",
      "round 185, train_loss: 0.6128723375744654, val_loss: 0.6168261251585081 \n",
      "round 186, train_loss: 0.6125908845884941, val_loss: 0.6164783969932659 \n",
      "round 187, train_loss: 0.6123100501279504, val_loss: 0.6161315160627018 \n",
      "round 188, train_loss: 0.6120298320103256, val_loss: 0.6157854794339704 \n",
      "round 189, train_loss: 0.6117502280653958, val_loss: 0.6154402841683247 \n",
      "round 190, train_loss: 0.6114712361351032, val_loss: 0.615095927321957 \n",
      "round 191, train_loss: 0.6111928540734383, val_loss: 0.6147524059468086 \n",
      "round 192, train_loss: 0.6109150797463259, val_loss: 0.6144097170913508 \n",
      "round 193, train_loss: 0.6106379110315115, val_loss: 0.6140678578013311 \n",
      "round 194, train_loss: 0.6103613458184527, val_loss: 0.6137268251204916 \n",
      "round 195, train_loss: 0.6100853820082076, val_loss: 0.6133866160912592 \n",
      "round 196, train_loss: 0.6098100175133299, val_loss: 0.6130472277554075 \n",
      "round 197, train_loss: 0.6095352502577632, val_loss: 0.6127086571546931 \n",
      "round 198, train_loss: 0.6092610781767374, val_loss: 0.6123709013314644 \n",
      "round 199, train_loss: 0.6089874992166666, val_loss: 0.6120339573292466 \n",
      "round 200, train_loss: 0.6087145113350501, val_loss: 0.6116978221933026 \n",
      "round 201, train_loss: 0.6084421125003725, val_loss: 0.6113624929711708 \n",
      "round 202, train_loss: 0.6081703006920074, val_loss: 0.6110279667131805 \n",
      "round 203, train_loss: 0.6078990739001225, val_loss: 0.6106942404729439 \n",
      "round 204, train_loss: 0.6076284301255837, val_loss: 0.6103613113078299 \n",
      "round 205, train_loss: 0.6073583673798637, val_loss: 0.6100291762794168 \n",
      "round 206, train_loss: 0.6070888836849507, val_loss: 0.609697832453924 \n",
      "round 207, train_loss: 0.6068199770732576, val_loss: 0.6093672769026269 \n",
      "round 208, train_loss: 0.6065516455875335, val_loss: 0.6090375067022522 \n",
      "round 209, train_loss: 0.6062838872807768, val_loss: 0.6087085189353562 \n",
      "round 210, train_loss: 0.6060167002161476, val_loss: 0.6083803106906874 \n",
      "round 211, train_loss: 0.6057500824668853, val_loss: 0.6080528790635292 \n",
      "round 212, train_loss: 0.6054840321162205, val_loss: 0.6077262211560315 \n",
      "round 213, train_loss: 0.6052185472572953, val_loss: 0.6074003340775247 \n",
      "round 214, train_loss: 0.6049536259930817, val_loss: 0.6070752149448165 \n",
      "round 215, train_loss: 0.604689266436299, val_loss: 0.6067508608824803 \n",
      "round 216, train_loss: 0.6044254667093364, val_loss: 0.6064272690231252 \n",
      "round 217, train_loss: 0.6041622249441724, val_loss: 0.6061044365076551 \n",
      "round 218, train_loss: 0.6038995392822994, val_loss: 0.605782360485513 \n",
      "round 219, train_loss: 0.6036374078746456, val_loss: 0.6054610381149171 \n",
      "round 220, train_loss: 0.6033758288814993, val_loss: 0.6051404665630802 \n",
      "round 221, train_loss: 0.6031148004724363, val_loss: 0.6048206430064212 \n",
      "round 222, train_loss: 0.6028543208262448, val_loss: 0.6045015646307638 \n",
      "round 223, train_loss: 0.6025943881308523, val_loss: 0.6041832286315257 \n",
      "round 224, train_loss: 0.6023350005832534, val_loss: 0.6038656322138974 \n",
      "round 225, train_loss: 0.6020761563894415, val_loss: 0.6035487725930094 \n",
      "round 226, train_loss: 0.6018178537643359, val_loss: 0.6032326469940942 \n",
      "round 227, train_loss: 0.6015600909317128, val_loss: 0.6029172526526342 \n",
      "round 228, train_loss: 0.6013028661241383, val_loss: 0.6026025868145033 \n",
      "round 229, train_loss: 0.6010461775829002, val_loss: 0.6022886467361016 \n",
      "round 230, train_loss: 0.6007900235579402, val_loss: 0.6019754296844771 \n",
      "round 231, train_loss: 0.6005344023077884, val_loss: 0.6016629329374468 \n",
      "round 232, train_loss: 0.6002793120994986, val_loss: 0.6013511537837011 \n",
      "round 233, train_loss: 0.6000247512085831, val_loss: 0.6010400895229103 \n",
      "round 234, train_loss: 0.5997707179189486, val_loss: 0.6007297374658168 \n",
      "round 235, train_loss: 0.5995172105228344, val_loss: 0.6004200949343254 \n",
      "round 236, train_loss: 0.5992642273207485, val_loss: 0.6001111592615833 \n",
      "round 237, train_loss: 0.5990117666214071, val_loss: 0.5998029277920578 \n",
      "round 238, train_loss: 0.5987598267416733, val_loss: 0.5994953978816039 \n",
      "round 239, train_loss: 0.598508406006496, val_loss: 0.5991885668975294 \n",
      "round 240, train_loss: 0.5982575027488519, val_loss: 0.5988824322186537 \n",
      "round 241, train_loss: 0.5980071153096852, val_loss: 0.5985769912353583 \n",
      "round 242, train_loss: 0.59775724203785, val_loss: 0.5982722413496381 \n",
      "round 243, train_loss: 0.5975078812900524, val_loss: 0.5979681799751417 \n",
      "round 244, train_loss: 0.5972590314307936, val_loss: 0.5976648045372112 \n",
      "round 245, train_loss: 0.597010690832313, val_loss: 0.5973621124729144 \n",
      "round 246, train_loss: 0.5967628578745331, val_loss: 0.5970601012310748 \n",
      "round 247, train_loss: 0.5965155309450046, val_loss: 0.5967587682722975 \n",
      "round 248, train_loss: 0.5962687084388503, val_loss: 0.5964581110689884 \n",
      "round 249, train_loss: 0.5960223887587127, val_loss: 0.596158127105374 \n",
      "round 250, train_loss: 0.595776570314699, val_loss: 0.5958588138775119 \n",
      "round 251, train_loss: 0.5955312515243305, val_loss: 0.5955601688933032 \n",
      "round 252, train_loss: 0.5952864308124877, val_loss: 0.5952621896724976 \n",
      "round 253, train_loss: 0.59504210661136, val_loss: 0.5949648737466967 \n",
      "round 254, train_loss: 0.5947982773603946, val_loss: 0.5946682186593548 \n",
      "round 255, train_loss: 0.5945549415062453, val_loss: 0.5943722219657763 \n",
      "round 256, train_loss: 0.594312097502722, val_loss: 0.5940768812331091 \n",
      "round 257, train_loss: 0.5940697438107418, val_loss: 0.5937821940403355 \n",
      "round 258, train_loss: 0.5938278788982797, val_loss: 0.5934881579782622 \n",
      "round 259, train_loss: 0.5935865012403202, val_loss: 0.5931947706495077 \n",
      "round 260, train_loss: 0.5933456093188079, val_loss: 0.5929020296684825 \n",
      "round 261, train_loss: 0.5931052016226013, val_loss: 0.5926099326613748 \n",
      "round 262, train_loss: 0.5928652766474247, val_loss: 0.5923184772661279 \n",
      "round 263, train_loss: 0.5926258328958232, val_loss: 0.5920276611324164 \n",
      "round 264, train_loss: 0.5923868688771139, val_loss: 0.5917374819216247 \n",
      "round 265, train_loss: 0.5921483831073425, val_loss: 0.5914479373068166 \n",
      "round 266, train_loss: 0.5919103741092357, val_loss: 0.5911590249727099 \n",
      "round 267, train_loss: 0.5916728404121594, val_loss: 0.5908707426156448 \n",
      "round 268, train_loss: 0.5914357805520704, val_loss: 0.5905830879435514 \n",
      "round 269, train_loss: 0.5911991930714774, val_loss: 0.5902960586759177 \n",
      "round 270, train_loss: 0.5909630765193924, val_loss: 0.5900096525437545 \n",
      "round 271, train_loss: 0.5907274294512913, val_loss: 0.5897238672895565 \n",
      "round 272, train_loss: 0.5904922504290692, val_loss: 0.5894387006672681 \n",
      "round 273, train_loss: 0.5902575380209993, val_loss: 0.5891541504422421 \n",
      "round 274, train_loss: 0.5900232908016901, val_loss: 0.5888702143912002 \n",
      "round 275, train_loss: 0.5897895073520453, val_loss: 0.5885868903021909 \n",
      "round 276, train_loss: 0.5895561862592207, val_loss: 0.5883041759745473 \n",
      "round 277, train_loss: 0.5893233261165857, val_loss: 0.5880220692188434 \n",
      "round 278, train_loss: 0.5890909255236821, val_loss: 0.5877405678568502 \n",
      "round 279, train_loss: 0.5888589830861848, val_loss: 0.587459669721489 \n",
      "round 280, train_loss: 0.5886274974158601, val_loss: 0.5871793726567857 \n",
      "round 281, train_loss: 0.5883964671305307, val_loss: 0.5868996745178227 \n",
      "round 282, train_loss: 0.5881658908540326, val_loss: 0.5866205731706925 \n",
      "round 283, train_loss: 0.5879357672161792, val_loss: 0.5863420664924466 \n",
      "round 284, train_loss: 0.5877060948527245, val_loss: 0.586064152371049 \n",
      "round 285, train_loss: 0.587476872405321, val_loss: 0.5857868287053232 \n",
      "round 286, train_loss: 0.5872480985214872, val_loss: 0.5855100934049023 \n",
      "round 287, train_loss: 0.5870197718545681, val_loss: 0.5852339443901795 \n",
      "round 288, train_loss: 0.5867918910636988, val_loss: 0.5849583795922537 \n",
      "round 289, train_loss: 0.5865644548137691, val_loss: 0.5846833969528791 \n",
      "round 290, train_loss: 0.5863374617753865, val_loss: 0.5844089944244109 \n",
      "round 291, train_loss: 0.5861109106248414, val_loss: 0.5841351699697541 \n",
      "round 292, train_loss: 0.5858848000440717, val_loss: 0.5838619215623073 \n",
      "round 293, train_loss: 0.5856591287206273, val_loss: 0.583589247185912 \n",
      "round 294, train_loss: 0.5854338953476358, val_loss: 0.5833171448347951 \n",
      "round 295, train_loss: 0.585209098623769, val_loss: 0.5830456125135162 \n",
      "round 296, train_loss: 0.5849847372532073, val_loss: 0.5827746482369133 \n",
      "round 297, train_loss: 0.5847608099456071, val_loss: 0.5825042500300464 \n",
      "round 298, train_loss: 0.5845373154160671, val_loss: 0.5822344159281423 \n",
      "round 299, train_loss: 0.5843142523850954, val_loss: 0.5819651439765409 \n",
      "round 300, train_loss: 0.584091619578576, val_loss: 0.5816964322306373 \n",
      "round 301, train_loss: 0.5838694157277375, val_loss: 0.5814282787558273 \n",
      "round 302, train_loss: 0.5836476395691198, val_loss: 0.581160681627452 \n",
      "round 303, train_loss: 0.5834262898445423, val_loss: 0.580893638930741 \n",
      "round 304, train_loss: 0.5832053653010724, val_loss: 0.5806271487607562 \n",
      "round 305, train_loss: 0.5829848646909952, val_loss: 0.5803612092223362 \n",
      "round 306, train_loss: 0.5827647867717795, val_loss: 0.5800958184300408 \n",
      "round 307, train_loss: 0.5825451303060508, val_loss: 0.5798309745080937 \n",
      "round 308, train_loss: 0.5823258940615577, val_loss: 0.5795666755903256 \n",
      "round 309, train_loss: 0.5821070768111428, val_loss: 0.579302919820122 \n",
      "round 310, train_loss: 0.5818886773327127, val_loss: 0.5790397053503622 \n",
      "round 311, train_loss: 0.5816706944092078, val_loss: 0.5787770303433658 \n",
      "round 312, train_loss: 0.581453126828573, val_loss: 0.5785148929708367 \n",
      "round 313, train_loss: 0.5812359733837286, val_loss: 0.578253291413807 \n",
      "round 314, train_loss: 0.5810192328725413, val_loss: 0.5779922238625803 \n",
      "round 315, train_loss: 0.5808029040977948, val_loss: 0.5777316885166769 \n",
      "round 316, train_loss: 0.5805869858671617, val_loss: 0.5774716835847777 \n",
      "round 317, train_loss: 0.5803714769931758, val_loss: 0.5772122072846694 \n",
      "round 318, train_loss: 0.5801563762932026, val_loss: 0.5769532578431874 \n",
      "round 319, train_loss: 0.5799416825894133, val_loss: 0.5766948334961634 \n",
      "round 320, train_loss: 0.5797273947087556, val_loss: 0.5764369324883674 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 321, train_loss: 0.5795135114829264, val_loss: 0.5761795530734535 \n",
      "round 322, train_loss: 0.5793000317483467, val_loss: 0.5759226935139073 \n",
      "round 323, train_loss: 0.5790869543461322, val_loss: 0.5756663520809886 \n",
      "round 324, train_loss: 0.5788742781220679, val_loss: 0.5754105270546784 \n",
      "round 325, train_loss: 0.5786620019265822, val_loss: 0.5751552167236236 \n",
      "round 326, train_loss: 0.5784501246147187, val_loss: 0.5749004193850851 \n",
      "round 327, train_loss: 0.5782386450461113, val_loss: 0.5746461333448818 \n",
      "round 328, train_loss: 0.5780275620849591, val_loss: 0.5743923569173379 \n",
      "round 329, train_loss: 0.5778168746000009, val_loss: 0.5741390884252302 \n",
      "round 330, train_loss: 0.5776065814644871, val_loss: 0.573886326199734 \n",
      "round 331, train_loss: 0.5773966815561575, val_loss: 0.5736340685803705 \n",
      "round 332, train_loss: 0.5771871737572152, val_loss: 0.5733823139149541 \n",
      "round 333, train_loss: 0.5769780569543015, val_loss: 0.5731310605595408 \n",
      "round 334, train_loss: 0.5767693300384716, val_loss: 0.5728803068783747 \n",
      "round 335, train_loss: 0.5765609919051715, val_loss: 0.5726300512438373 \n",
      "round 336, train_loss: 0.5763530414542105, val_loss: 0.5723802920363943 \n",
      "round 337, train_loss: 0.5761454775897404, val_loss: 0.5721310276445465 \n",
      "round 338, train_loss: 0.5759382992202307, val_loss: 0.5718822564647776 \n",
      "round 339, train_loss: 0.5757315052584442, val_loss: 0.5716339769015016 \n",
      "round 340, train_loss: 0.5755250946214144, val_loss: 0.5713861873670151 \n",
      "round 341, train_loss: 0.5753190662304218, val_loss: 0.5711388862814452 \n",
      "round 342, train_loss: 0.5751134190109706, val_loss: 0.5708920720727004 \n",
      "round 343, train_loss: 0.5749081518927671, val_loss: 0.5706457431764198 \n",
      "round 344, train_loss: 0.5747032638096956, val_loss: 0.5703998980359244 \n",
      "round 345, train_loss: 0.5744987536997964, val_loss: 0.5701545351021684 \n",
      "round 346, train_loss: 0.5742946205052427, val_loss: 0.5699096528336884 \n",
      "round 347, train_loss: 0.5740908631723195, val_loss: 0.5696652496965574 \n",
      "round 348, train_loss: 0.5738874806514015, val_loss: 0.5694213241643341 \n",
      "round 349, train_loss: 0.5736844718969298, val_loss: 0.5691778747180163 \n",
      "round 350, train_loss: 0.5734818358673923, val_loss: 0.5689348998459928 \n",
      "round 351, train_loss: 0.5732795715253, val_loss: 0.5686923980439952 \n",
      "round 352, train_loss: 0.5730776778371677, val_loss: 0.5684503678150524 \n",
      "round 353, train_loss: 0.5728761537734912, val_loss: 0.5682088076694419 \n",
      "round 354, train_loss: 0.5726749983087271, val_loss: 0.5679677161246445 \n",
      "round 355, train_loss: 0.5724742104212714, val_loss: 0.5677270917052976 \n",
      "round 356, train_loss: 0.5722737890934392, val_loss: 0.5674869329431492 \n",
      "round 357, train_loss: 0.572073733311444, val_loss: 0.5672472383770122 \n",
      "round 358, train_loss: 0.5718740420653768, val_loss: 0.5670080065527178 \n",
      "round 359, train_loss: 0.5716747143491867, val_loss: 0.5667692360230743 \n",
      "round 360, train_loss: 0.5714757491606602, val_loss: 0.5665309253478172 \n",
      "round 361, train_loss: 0.5712771455014012, val_loss: 0.5662930730935686 \n",
      "round 362, train_loss: 0.5710789023768112, val_loss: 0.5660556778337908 \n",
      "round 363, train_loss: 0.57088101879607, val_loss: 0.5658187381487438 \n",
      "round 364, train_loss: 0.5706834937721158, val_loss: 0.5655822526254403 \n",
      "round 365, train_loss: 0.5704863263216252, val_loss: 0.5653462198576035 \n",
      "round 366, train_loss: 0.5702895154649952, val_loss: 0.5651106384456237 \n",
      "round 367, train_loss: 0.5700930602263238, val_loss: 0.5648755069965158 \n",
      "round 368, train_loss: 0.56989695963339, val_loss: 0.5646408241238761 \n",
      "round 369, train_loss: 0.5697012127176359, val_loss: 0.5644065884478411 \n",
      "round 370, train_loss: 0.5695058185141475, val_loss: 0.5641727985950452 \n",
      "round 371, train_loss: 0.5693107760616372, val_loss: 0.5639394531985796 \n",
      "round 372, train_loss: 0.5691160844024233, val_loss: 0.5637065508979502 \n",
      "round 373, train_loss: 0.5689217425824131, val_loss: 0.5634740903390372 \n",
      "round 374, train_loss: 0.5687277496510863, val_loss: 0.5632420701740541 \n",
      "round 375, train_loss: 0.5685341046614723, val_loss: 0.5630104890615083 \n",
      "round 376, train_loss: 0.5683408066701372, val_loss: 0.5627793456661591 \n",
      "round 377, train_loss: 0.5681478547371629, val_loss: 0.5625486386589796 \n",
      "round 378, train_loss: 0.5679552479261305, val_loss: 0.5623183667171171 \n",
      "round 379, train_loss: 0.5677629853041041, val_loss: 0.5620885285238525 \n",
      "round 380, train_loss: 0.56757106594161, val_loss: 0.5618591227685616 \n",
      "round 381, train_loss: 0.5673794889126221, val_loss: 0.5616301481466791 \n",
      "round 382, train_loss: 0.5671882532945443, val_loss: 0.5614016033596554 \n",
      "round 383, train_loss: 0.566997358168193, val_loss: 0.5611734871149228 \n",
      "round 384, train_loss: 0.5668068026177794, val_loss: 0.5609457981258555 \n",
      "round 385, train_loss: 0.5666165857308944, val_loss: 0.5607185351117323 \n",
      "round 386, train_loss: 0.5664267065984907, val_loss: 0.5604916967976995 \n",
      "round 387, train_loss: 0.5662371643148668, val_loss: 0.5602652819147341 \n",
      "round 388, train_loss: 0.566047957977649, val_loss: 0.5600392891996065 \n",
      "round 389, train_loss: 0.5658590866877776, val_loss: 0.5598137173948444 \n",
      "round 390, train_loss: 0.5656705495494888, val_loss: 0.5595885652486965 \n",
      "round 391, train_loss: 0.5654823456702981, val_loss: 0.5593638315150956 \n",
      "round 392, train_loss: 0.5652944741609862, val_loss: 0.5591395149536257 \n",
      "round 393, train_loss: 0.5651069341355812, val_loss: 0.5589156143294828 \n",
      "round 394, train_loss: 0.5649197247113443, val_loss: 0.5586921284134421 \n",
      "round 395, train_loss: 0.5647328450087523, val_loss: 0.5584690559818237 \n",
      "round 396, train_loss: 0.5645462941514838, val_loss: 0.5582463958164547 \n",
      "round 397, train_loss: 0.5643600712664023, val_loss: 0.5580241467046393 \n",
      "round 398, train_loss: 0.5641741754835413, val_loss: 0.5578023074391206 \n",
      "round 399, train_loss: 0.5639886059360901, val_loss: 0.5575808768180492 \n",
      "round 400, train_loss: 0.5638033617603759, val_loss: 0.5573598536449483 \n",
      "round 401, train_loss: 0.5636184420958512, val_loss: 0.5571392367286819 \n",
      "round 402, train_loss: 0.5634338460850774, val_loss: 0.556919024883419 \n",
      "round 403, train_loss: 0.563249572873711, val_loss: 0.5566992169286039 \n",
      "round 404, train_loss: 0.5630656216104877, val_loss: 0.5564798116889206 \n",
      "round 405, train_loss: 0.5628819914472079, val_loss: 0.5562608079942625 \n",
      "round 406, train_loss: 0.5626986815387217, val_loss: 0.5560422046797 \n",
      "round 407, train_loss: 0.5625156910429171, val_loss: 0.5558240005854468 \n",
      "round 408, train_loss: 0.5623330191207011, val_loss: 0.5556061945568305 \n",
      "round 409, train_loss: 0.5621506649359885, val_loss: 0.5553887854442601 \n",
      "round 410, train_loss: 0.5619686276556872, val_loss: 0.5551717721031945 \n",
      "round 411, train_loss: 0.5617869064496828, val_loss: 0.5549551533941125 \n",
      "round 412, train_loss: 0.5616055004908261, val_loss: 0.5547389281824814 \n",
      "round 413, train_loss: 0.5614244089549177, val_loss: 0.5545230953387257 \n",
      "round 414, train_loss: 0.561243631020696, val_loss: 0.5543076537381989 \n",
      "round 415, train_loss: 0.5610631658698202, val_loss: 0.5540926022611518 \n",
      "round 416, train_loss: 0.5608830126868602, val_loss: 0.5538779397927036 \n",
      "round 417, train_loss: 0.560703170659281, val_loss: 0.5536636652228105 \n",
      "round 418, train_loss: 0.5605236389774287, val_loss: 0.5534497774462392 \n",
      "round 419, train_loss: 0.5603444168345191, val_loss: 0.5532362753625354 \n",
      "round 420, train_loss: 0.5601655034266217, val_loss: 0.5530231578759963 \n",
      "round 421, train_loss: 0.559986897952649, val_loss: 0.5528104238956398 \n",
      "round 422, train_loss: 0.5598085996143408, val_loss: 0.5525980723351794 \n",
      "round 423, train_loss: 0.5596306076162538, val_loss: 0.552386102112993 \n",
      "round 424, train_loss: 0.5594529211657456, val_loss: 0.5521745121520959 \n",
      "round 425, train_loss: 0.5592755394729642, val_loss: 0.5519633013801118 \n",
      "round 426, train_loss: 0.5590984617508338, val_loss: 0.5517524687292482 \n",
      "round 427, train_loss: 0.558921687215042, val_loss: 0.5515420131362652 \n",
      "round 428, train_loss: 0.5587452150840286, val_loss: 0.5513319335424507 \n",
      "round 429, train_loss: 0.5585690445789699, val_loss: 0.5511222288935921 \n",
      "round 430, train_loss: 0.55839317492377, val_loss: 0.5509128981399503 \n",
      "round 431, train_loss: 0.558217605345045, val_loss: 0.5507039402362329 \n",
      "round 432, train_loss: 0.5580423350721119, val_loss: 0.5504953541415671 \n",
      "round 433, train_loss: 0.5578673633369765, val_loss: 0.5502871388194742 \n",
      "round 434, train_loss: 0.5576926893743214, val_loss: 0.5500792932378431 \n",
      "round 435, train_loss: 0.5575183124214927, val_loss: 0.5498718163689045 \n",
      "round 436, train_loss: 0.5573442317184885, val_loss: 0.5496647071892059 \n",
      "round 437, train_loss: 0.5571704465079467, val_loss: 0.5494579646795853 \n",
      "round 438, train_loss: 0.5569969560351341, val_loss: 0.5492515878251455 \n",
      "round 439, train_loss: 0.556823759547932, val_loss: 0.5490455756152309 \n",
      "round 440, train_loss: 0.5566508562968272, val_loss: 0.5488399270434 \n",
      "round 441, train_loss: 0.5564782455348988, val_loss: 0.5486346411074036 \n",
      "round 442, train_loss: 0.5563059265178061, val_loss: 0.5484297168091575 \n",
      "round 443, train_loss: 0.5561338985037778, val_loss: 0.5482251531547201 \n",
      "round 444, train_loss: 0.5559621607536006, val_loss: 0.5480209491542669 \n",
      "round 445, train_loss: 0.5557907125306071, val_loss: 0.5478171038220677 \n",
      "round 446, train_loss: 0.5556195531006646, val_loss: 0.5476136161764615 \n",
      "round 447, train_loss: 0.555448681732163, val_loss: 0.5474104852398342 \n",
      "round 448, train_loss: 0.5552780976960061, val_loss: 0.5472077100385943 \n",
      "round 449, train_loss: 0.5551078002655975, val_loss: 0.5470052896031488 \n",
      "round 450, train_loss: 0.5549377887168302, val_loss: 0.5468032229678828 \n",
      "round 451, train_loss: 0.5547680623280763, val_loss: 0.546601509171133 \n",
      "round 452, train_loss: 0.5545986203801755, val_loss: 0.5464001472551683 \n",
      "round 453, train_loss: 0.5544294621564246, val_loss: 0.5461991362661641 \n",
      "round 454, train_loss: 0.5542605869425657, val_loss: 0.5459984752541827 \n",
      "round 455, train_loss: 0.5540919940267757, val_loss: 0.5457981632731483 \n",
      "round 456, train_loss: 0.553923682699657, val_loss: 0.5455981993808273 \n",
      "round 457, train_loss: 0.5537556522542232, val_loss: 0.5453985826388047 \n",
      "round 458, train_loss: 0.5535879019858928, val_loss: 0.5451993121124632 \n",
      "round 459, train_loss: 0.5534204311924764, val_loss: 0.545000386870961 \n",
      "round 460, train_loss: 0.5532532391741656, val_loss: 0.5448018059872103 \n",
      "round 461, train_loss: 0.5530863252335234, val_loss: 0.5446035685378567 \n",
      "round 462, train_loss: 0.5529196886754746, val_loss: 0.5444056736032576 \n",
      "round 463, train_loss: 0.5527533288072934, val_loss: 0.5442081202674605 \n",
      "round 464, train_loss: 0.5525872449385956, val_loss: 0.5440109076181833 \n",
      "round 465, train_loss: 0.5524214363813259, val_loss: 0.5438140347467926 \n",
      "round 466, train_loss: 0.55225590244975, val_loss: 0.5436175007482844 \n",
      "round 467, train_loss: 0.5520906424604423, val_loss: 0.5434213047212619 \n",
      "round 468, train_loss: 0.5519256557322783, val_loss: 0.5432254457679169 \n",
      "round 469, train_loss: 0.551760941586422, val_loss: 0.5430299229940088 \n",
      "round 470, train_loss: 0.5515964993463186, val_loss: 0.5428347355088448 \n",
      "round 471, train_loss: 0.551432328337682, val_loss: 0.5426398824252603 \n",
      "round 472, train_loss: 0.5512684278884873, val_loss: 0.5424453628595985 \n",
      "round 473, train_loss: 0.5511047973289591, val_loss: 0.5422511759316923 \n",
      "round 474, train_loss: 0.550941435991563, val_loss: 0.5420573207648426 \n",
      "round 475, train_loss: 0.5507783432109968, val_loss: 0.5418637964858017 \n",
      "round 476, train_loss: 0.5506155183241778, val_loss: 0.5416706022247524 \n",
      "round 477, train_loss: 0.5504529606702361, val_loss: 0.5414777371152895 \n",
      "round 478, train_loss: 0.5502906695905041, val_loss: 0.5412852002944011 \n",
      "round 479, train_loss: 0.5501286444285076, val_loss: 0.5410929909024491 \n",
      "round 480, train_loss: 0.5499668845299553, val_loss: 0.5409011080831525 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 481, train_loss: 0.5498053892427299, val_loss: 0.5407095509835664 \n",
      "round 482, train_loss: 0.5496441579168797, val_loss: 0.5405183187540655 \n",
      "round 483, train_loss: 0.5494831899046085, val_loss: 0.5403274105483257 \n",
      "round 484, train_loss: 0.5493224845602662, val_loss: 0.5401368255233053 \n",
      "round 485, train_loss: 0.5491620412403402, val_loss: 0.5399465628392278 \n",
      "round 486, train_loss: 0.5490018593034462, val_loss: 0.5397566216595636 \n",
      "round 487, train_loss: 0.5488419381103194, val_loss: 0.5395670011510126 \n",
      "round 488, train_loss: 0.5486822770238041, val_loss: 0.5393777004834864 \n",
      "round 489, train_loss: 0.5485228754088473, val_loss: 0.5391887188300916 \n",
      "round 490, train_loss: 0.5483637326324879, val_loss: 0.5390000553671113 \n",
      "round 491, train_loss: 0.5482048480638478, val_loss: 0.5388117092739887 \n",
      "round 492, train_loss: 0.5480462210741243, val_loss: 0.5386236797333104 \n",
      "round 493, train_loss: 0.5478878510365801, val_loss: 0.5384359659307879 \n",
      "round 494, train_loss: 0.5477297373265358, val_loss: 0.5382485670552427 \n",
      "round 495, train_loss: 0.5475718793213601, val_loss: 0.5380614822985887 \n",
      "round 496, train_loss: 0.5474142764004626, val_loss: 0.5378747108558153 \n",
      "round 497, train_loss: 0.547256927945283, val_loss: 0.5376882519249714 \n",
      "round 498, train_loss: 0.5470998333392855, val_loss: 0.5375021047071482 \n",
      "round 499, train_loss: 0.546942991967947, val_loss: 0.5373162684064651 \n",
      "round 500, train_loss: 0.5467864032187519, val_loss: 0.5371307422300508 \n",
      "round 501, train_loss: 0.5466300664811824, val_loss: 0.5369455253880295 \n",
      "round 502, train_loss: 0.5464739811467082, val_loss: 0.5367606170935035 \n",
      "round 503, train_loss: 0.5463181466087826, val_loss: 0.5365760165625377 \n",
      "round 504, train_loss: 0.5461625622628294, val_loss: 0.5363917230141454 \n",
      "round 505, train_loss: 0.5460072275062385, val_loss: 0.5362077356702707 \n",
      "round 506, train_loss: 0.5458521417383554, val_loss: 0.5360240537557733 \n",
      "round 507, train_loss: 0.5456973043604748, val_loss: 0.5358406764984149 \n",
      "round 508, train_loss: 0.5455427147758304, val_loss: 0.5356576031288418 \n",
      "round 509, train_loss: 0.5453883723895893, val_loss: 0.5354748328805713 \n",
      "round 510, train_loss: 0.5452342766088417, val_loss: 0.5352923649899755 \n",
      "round 511, train_loss: 0.5450804268425952, val_loss: 0.5351101986962675 \n",
      "round 512, train_loss: 0.544926822501765, val_loss: 0.5349283332414849 \n",
      "round 513, train_loss: 0.5447734629991673, val_loss: 0.5347467678704769 \n",
      "round 514, train_loss: 0.5446203477495101, val_loss: 0.534565501830889 \n",
      "round 515, train_loss: 0.5444674761693874, val_loss: 0.5343845343731474 \n",
      "round 516, train_loss: 0.5443148476772695, val_loss: 0.5342038647504462 \n",
      "round 517, train_loss: 0.5441624616934967, val_loss: 0.5340234922187318 \n",
      "round 518, train_loss: 0.5440103176402703, val_loss: 0.5338434160366897 \n",
      "round 519, train_loss: 0.5438584149416471, val_loss: 0.5336636354657289 \n",
      "round 520, train_loss: 0.5437067530235292, val_loss: 0.5334841497699699 \n",
      "round 521, train_loss: 0.5435553313136582, val_loss: 0.533304958216229 \n",
      "round 522, train_loss: 0.5434041492416071, val_loss: 0.5331260600740045 \n",
      "round 523, train_loss: 0.5432532062387735, val_loss: 0.5329474546154643 \n",
      "round 524, train_loss: 0.5431025017383707, val_loss: 0.5327691411154307 \n",
      "round 525, train_loss: 0.5429520351754218, val_loss: 0.532591118851368 \n",
      "round 526, train_loss: 0.5428018059867515, val_loss: 0.5324133871033677 \n",
      "round 527, train_loss: 0.54265181361098, val_loss: 0.532235945154137 \n",
      "round 528, train_loss: 0.5425020574885132, val_loss: 0.5320587922889831 \n",
      "round 529, train_loss: 0.5423525370615381, val_loss: 0.5318819277958021 \n",
      "round 530, train_loss: 0.5422032517740144, val_loss: 0.5317053509650644 \n",
      "round 531, train_loss: 0.5420542010716675, val_loss: 0.5315290610898027 \n",
      "round 532, train_loss: 0.5419053844019809, val_loss: 0.5313530574655981 \n",
      "round 533, train_loss: 0.5417568012141896, val_loss: 0.531177339390568 \n",
      "round 534, train_loss: 0.541608450959274, val_loss: 0.5310019061653524 \n",
      "round 535, train_loss: 0.5414603330899508, val_loss: 0.5308267570931025 \n",
      "round 536, train_loss: 0.5413124470606671, val_loss: 0.5306518914794668 \n",
      "round 537, train_loss: 0.5411647923275937, val_loss: 0.5304773086325794 \n",
      "round 538, train_loss: 0.5410173683486184, val_loss: 0.5303030078630472 \n",
      "round 539, train_loss: 0.5408701745833375, val_loss: 0.5301289884839373 \n",
      "round 540, train_loss: 0.5407232104930512, val_loss: 0.529955249810765 \n",
      "round 541, train_loss: 0.5405764755407544, val_loss: 0.5297817911614818 \n",
      "round 542, train_loss: 0.5404299691911327, val_loss: 0.5296086118564628 \n",
      "round 543, train_loss: 0.540283690910553, val_loss: 0.5294357112184948 \n",
      "round 544, train_loss: 0.5401376401670582, val_loss: 0.5292630885727642 \n",
      "round 545, train_loss: 0.5399918164303602, val_loss: 0.529090743246846 \n",
      "round 546, train_loss: 0.5398462191718335, val_loss: 0.5289186745706901 \n",
      "round 547, train_loss: 0.5397008478645083, val_loss: 0.5287468818766119 \n",
      "round 548, train_loss: 0.5395557019830641, val_loss: 0.5285753644992783 \n",
      "round 549, train_loss: 0.5394107810038227, val_loss: 0.5284041217756984 \n",
      "round 550, train_loss: 0.5392660844047421, val_loss: 0.5282331530452098 \n",
      "round 551, train_loss: 0.5391216116654105, val_loss: 0.5280624576494686 \n",
      "round 552, train_loss: 0.5389773622670386, val_loss: 0.5278920349324373 \n",
      "round 553, train_loss: 0.5388333356924544, val_loss: 0.5277218842403745 \n",
      "round 554, train_loss: 0.5386895314260959, val_loss: 0.5275520049218225 \n",
      "round 555, train_loss: 0.538545948954005, val_loss: 0.5273823963275964 \n",
      "round 556, train_loss: 0.5384025877638222, val_loss: 0.5272130578107737 \n",
      "round 557, train_loss: 0.5382594473447787, val_loss: 0.5270439887266827 \n",
      "round 558, train_loss: 0.5381165271876909, val_loss: 0.5268751884328915 \n",
      "round 559, train_loss: 0.5379738267849544, val_loss: 0.5267066562891979 \n",
      "round 560, train_loss: 0.5378313456305372, val_loss: 0.5265383916576171 \n",
      "round 561, train_loss: 0.5376890832199741, val_loss: 0.5263703939023732 \n",
      "round 562, train_loss: 0.5375470390503603, val_loss: 0.5262026623898857 \n",
      "round 563, train_loss: 0.5374052126203452, val_loss: 0.5260351964887616 \n",
      "round 564, train_loss: 0.5372636034301262, val_loss: 0.5258679955697836 \n",
      "round 565, train_loss: 0.5371222109814434, val_loss: 0.5257010590058988 \n",
      "round 566, train_loss: 0.5369810347775729, val_loss: 0.5255343861722114 \n",
      "round 567, train_loss: 0.5368400743233204, val_loss: 0.5253679764459674 \n",
      "round 568, train_loss: 0.5366993291250164, val_loss: 0.5252018292065495 \n",
      "round 569, train_loss: 0.5365587986905095, val_loss: 0.5250359438354635 \n",
      "round 570, train_loss: 0.5364184825291605, val_loss: 0.524870319716329 \n",
      "round 571, train_loss: 0.5362783801518369, val_loss: 0.524704956234871 \n",
      "round 572, train_loss: 0.5361384910709063, val_loss: 0.5245398527789068 \n",
      "round 573, train_loss: 0.5359988148002318, val_loss: 0.5243750087383386 \n",
      "round 574, train_loss: 0.5358593508551649, val_loss: 0.524210423505143 \n",
      "round 575, train_loss: 0.5357200987525409, val_loss: 0.5240460964733602 \n",
      "round 576, train_loss: 0.5355810580106718, val_loss: 0.5238820270390847 \n",
      "round 577, train_loss: 0.5354422281493422, val_loss: 0.5237182146004579 \n",
      "round 578, train_loss: 0.5353036086898025, val_loss: 0.5235546585576535 \n",
      "round 579, train_loss: 0.5351651991547631, val_loss: 0.5233913583128735 \n",
      "round 580, train_loss: 0.5350269990683897, val_loss: 0.5232283132703338 \n",
      "round 581, train_loss: 0.5348890079562973, val_loss: 0.523065522836259 \n",
      "round 582, train_loss: 0.534751225345544, val_loss: 0.5229029864188693 \n",
      "round 583, train_loss: 0.5346136507646262, val_loss: 0.522740703428374 \n",
      "round 584, train_loss: 0.5344762837434736, val_loss: 0.5225786732769604 \n",
      "round 585, train_loss: 0.5343391238134415, val_loss: 0.5224168953787854 \n",
      "round 586, train_loss: 0.5342021705073078, val_loss: 0.5222553691499664 \n",
      "round 587, train_loss: 0.5340654233592663, val_loss: 0.5220940940085713 \n",
      "round 588, train_loss: 0.5339288819049218, val_loss: 0.5219330693746104 \n",
      "round 589, train_loss: 0.5337925456812838, val_loss: 0.5217722946700274 \n",
      "round 590, train_loss: 0.5336564142267622, val_loss: 0.5216117693186897 \n",
      "round 591, train_loss: 0.5335204870811612, val_loss: 0.5214514927463795 \n",
      "round 592, train_loss: 0.5333847637856748, val_loss: 0.5212914643807872 \n",
      "round 593, train_loss: 0.5332492438828805, val_loss: 0.521131683651498 \n",
      "round 594, train_loss: 0.5331139269167346, val_loss: 0.5209721499899883 \n",
      "round 595, train_loss: 0.5329788124325671, val_loss: 0.5208128628296136 \n",
      "round 596, train_loss: 0.5328438999770762, val_loss: 0.5206538216056014 \n",
      "round 597, train_loss: 0.5327091890983228, val_loss: 0.5204950257550417 \n",
      "round 598, train_loss: 0.5325746793457261, val_loss: 0.520336474716879 \n",
      "round 599, train_loss: 0.5324403702700581, val_loss: 0.5201781679319046 \n",
      "round 600, train_loss: 0.5323062614234385, val_loss: 0.5200201048427464 \n",
      "round 601, train_loss: 0.5321723523593286, val_loss: 0.5198622848938614 \n",
      "round 602, train_loss: 0.5320386426325288, val_loss: 0.5197047075315281 \n",
      "round 603, train_loss: 0.5319051317991699, val_loss: 0.5195473722038381 \n",
      "round 604, train_loss: 0.5317718194167117, val_loss: 0.5193902783606857 \n",
      "round 605, train_loss: 0.531638705043936, val_loss: 0.5192334254537628 \n",
      "round 606, train_loss: 0.5315057882409411, val_loss: 0.5190768129365491 \n",
      "round 607, train_loss: 0.5313730685691386, val_loss: 0.5189204402643036 \n",
      "round 608, train_loss: 0.5312405455912479, val_loss: 0.518764306894058 \n",
      "round 609, train_loss: 0.5311082188712895, val_loss: 0.5186084122846082 \n",
      "round 610, train_loss: 0.5309760879745834, val_loss: 0.5184527558965052 \n",
      "round 611, train_loss: 0.5308441524677412, val_loss: 0.5182973371920492 \n",
      "round 612, train_loss: 0.5307124119186627, val_loss: 0.5181421556352799 \n",
      "round 613, train_loss: 0.5305808658965309, val_loss: 0.5179872106919702 \n",
      "round 614, train_loss: 0.5304495139718076, val_loss: 0.5178325018296178 \n",
      "round 615, train_loss: 0.5303183557162274, val_loss: 0.5176780285174369 \n",
      "round 616, train_loss: 0.5301873907027939, val_loss: 0.5175237902263518 \n",
      "round 617, train_loss: 0.5300566185057755, val_loss: 0.517369786428988 \n",
      "round 618, train_loss: 0.5299260387006985, val_loss: 0.5172160165996658 \n",
      "round 619, train_loss: 0.5297956508643458, val_loss: 0.517062480214392 \n",
      "round 620, train_loss: 0.5296654545747488, val_loss: 0.516909176750853 \n",
      "round 621, train_loss: 0.5295354494111844, val_loss: 0.5167561056884069 \n",
      "round 622, train_loss: 0.5294056349541709, val_loss: 0.5166032665080759 \n",
      "round 623, train_loss: 0.5292760107854623, val_loss: 0.5164506586925396 \n",
      "round 624, train_loss: 0.529146576488044, val_loss: 0.5162982817261275 \n",
      "round 625, train_loss: 0.5290173316461282, val_loss: 0.5161461350948117 \n",
      "round 626, train_loss: 0.5288882758451504, val_loss: 0.5159942182861993 \n",
      "round 627, train_loss: 0.528759408671763, val_loss: 0.5158425307895256 \n",
      "round 628, train_loss: 0.5286307297138321, val_loss: 0.5156910720956474 \n",
      "round 629, train_loss: 0.5285022385604327, val_loss: 0.5155398416970348 \n",
      "round 630, train_loss: 0.5283739348018448, val_loss: 0.5153888390877653 \n",
      "round 631, train_loss: 0.5282458180295473, val_loss: 0.5152380637635152 \n",
      "round 632, train_loss: 0.5281178878362156, val_loss: 0.5150875152215555 \n",
      "round 633, train_loss: 0.5279901438157156, val_loss: 0.5149371929607414 \n",
      "round 634, train_loss: 0.5278625855631006, val_loss: 0.5147870964815081 \n",
      "round 635, train_loss: 0.5277352126746057, val_loss: 0.5146372252858625 \n",
      "round 636, train_loss: 0.5276080247476445, val_loss: 0.5144875788773777 \n",
      "round 637, train_loss: 0.5274810213808037, val_loss: 0.5143381567611842 \n",
      "round 638, train_loss: 0.5273542021738409, val_loss: 0.5141889584439656 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 639, train_loss: 0.5272275667276773, val_loss: 0.5140399834339496 \n",
      "round 640, train_loss: 0.5271011146443954, val_loss: 0.5138912312409035 \n",
      "round 641, train_loss: 0.5269748455272348, val_loss: 0.5137427013761251 \n",
      "round 642, train_loss: 0.5268487589805876, val_loss: 0.5135943933524386 \n",
      "round 643, train_loss: 0.5267228546099927, val_loss: 0.5134463066841872 \n",
      "round 644, train_loss: 0.5265971320221349, val_loss: 0.5132984408872253 \n",
      "round 645, train_loss: 0.5264715908248375, val_loss: 0.5131507954789138 \n",
      "round 646, train_loss: 0.52634623062706, val_loss: 0.5130033699781121 \n",
      "round 647, train_loss: 0.5262210510388935, val_loss: 0.5128561639051743 \n",
      "round 648, train_loss: 0.5260960516715562, val_loss: 0.512709176781939 \n",
      "round 649, train_loss: 0.5259712321373896, val_loss: 0.5125624081317263 \n",
      "round 650, train_loss: 0.5258465920498552, val_loss: 0.5124158574793297 \n",
      "round 651, train_loss: 0.525722131023529, val_loss: 0.512269524351011 \n",
      "round 652, train_loss: 0.525597848674098, val_loss: 0.5121234082744929 \n",
      "round 653, train_loss: 0.5254737446183566, val_loss: 0.5119775087789534 \n",
      "round 654, train_loss: 0.5253498184742023, val_loss: 0.5118318253950199 \n",
      "round 655, train_loss: 0.5252260698606319, val_loss: 0.5116863576547628 \n",
      "round 656, train_loss: 0.5251024983977367, val_loss: 0.5115411050916892 \n",
      "round 657, train_loss: 0.5249791037066999, val_loss: 0.5113960672407368 \n",
      "round 658, train_loss: 0.5248558854097913, val_loss: 0.5112512436382687 \n",
      "round 659, train_loss: 0.5247328431303645, val_loss: 0.5111066338220669 \n",
      "round 660, train_loss: 0.5246099764928523, val_loss: 0.5109622373313258 \n",
      "round 661, train_loss: 0.524487285122763, val_loss: 0.510818053706647 \n",
      "round 662, train_loss: 0.5243647686466769, val_loss: 0.5106740824900334 \n",
      "round 663, train_loss: 0.5242424266922413, val_loss: 0.5105303232248828 \n",
      "round 664, train_loss: 0.524120258888168, val_loss: 0.5103867754559825 \n",
      "round 665, train_loss: 0.5239982648642292, val_loss: 0.5102434387295042 \n",
      "round 666, train_loss: 0.5238764442512525, val_loss: 0.510100312592996 \n",
      "round 667, train_loss: 0.5237547966811194, val_loss: 0.5099573965953794 \n",
      "round 668, train_loss: 0.523633321786759, val_loss: 0.5098146902869418 \n",
      "round 669, train_loss: 0.5235120192021459, val_loss: 0.5096721932193314 \n",
      "round 670, train_loss: 0.5233908885622953, val_loss: 0.5095299049455517 \n",
      "round 671, train_loss: 0.5232699295032618, val_loss: 0.5093878250199558 \n",
      "round 672, train_loss: 0.523149141662132, val_loss: 0.5092459529982405 \n",
      "round 673, train_loss: 0.5230285246770229, val_loss: 0.5091042884374415 \n",
      "round 674, train_loss: 0.5229080781870789, val_loss: 0.5089628308959264 \n",
      "round 675, train_loss: 0.5227878018324669, val_loss: 0.5088215799333915 \n",
      "round 676, train_loss: 0.522667695254372, val_loss: 0.5086805351108549 \n",
      "round 677, train_loss: 0.5225477580949962, val_loss: 0.5085396959906501 \n",
      "round 678, train_loss: 0.5224279899975532, val_loss: 0.5083990621364235 \n",
      "round 679, train_loss: 0.5223083906062643, val_loss: 0.5082586331131252 \n",
      "round 680, train_loss: 0.5221889595663566, val_loss: 0.5081184084870081 \n",
      "round 681, train_loss: 0.5220696965240568, val_loss: 0.5079783878256185 \n",
      "round 682, train_loss: 0.5219506011265914, val_loss: 0.5078385706977934 \n",
      "round 683, train_loss: 0.5218316730221798, val_loss: 0.507698956673654 \n",
      "round 684, train_loss: 0.5217129118600319, val_loss: 0.5075595453246015 \n",
      "round 685, train_loss: 0.521594317290345, val_loss: 0.5074203362233107 \n",
      "round 686, train_loss: 0.5214758889643005, val_loss: 0.507281328943726 \n",
      "round 687, train_loss: 0.521357626534059, val_loss: 0.5071425230610547 \n",
      "round 688, train_loss: 0.5212395296527585, val_loss: 0.507003918151764 \n",
      "round 689, train_loss: 0.52112159797451, val_loss: 0.506865513793575 \n",
      "round 690, train_loss: 0.5210038311543943, val_loss: 0.5067273095654559 \n",
      "round 691, train_loss: 0.5208862288484588, val_loss: 0.50658930504762 \n",
      "round 692, train_loss: 0.5207687907137135, val_loss: 0.5064514998215187 \n",
      "round 693, train_loss: 0.5206515164081286, val_loss: 0.5063138934698371 \n",
      "round 694, train_loss: 0.5205344055906298, val_loss: 0.5061764855764886 \n",
      "round 695, train_loss: 0.5204174579210965, val_loss: 0.5060392757266108 \n",
      "round 696, train_loss: 0.5203006730603572, val_loss: 0.5059022635065603 \n",
      "round 697, train_loss: 0.5201840506701866, val_loss: 0.5057654485039073 \n",
      "round 698, train_loss: 0.5200675904133022, val_loss: 0.505628830307431 \n",
      "round 699, train_loss: 0.519951291953362, val_loss: 0.5054924085071159 \n",
      "round 700, train_loss: 0.5198351549549591, val_loss: 0.5053561826941442 \n",
      "round 701, train_loss: 0.5197191790836203, val_loss: 0.5052201524608948 \n",
      "round 702, train_loss: 0.5196033640058018, val_loss: 0.505084317400936 \n",
      "round 703, train_loss: 0.5194877093888872, val_loss: 0.5049486771090199 \n",
      "round 704, train_loss: 0.5193722149011823, val_loss: 0.504813231181082 \n",
      "round 705, train_loss: 0.5192568802119142, val_loss: 0.5046779792142309 \n",
      "round 706, train_loss: 0.5191417049912257, val_loss: 0.504542920806748 \n",
      "round 707, train_loss: 0.519026688910174, val_loss: 0.5044080555580812 \n",
      "round 708, train_loss: 0.5189118316407267, val_loss: 0.5042733830688401 \n",
      "round 709, train_loss: 0.5187971328557589, val_loss: 0.5041389029407917 \n",
      "round 710, train_loss: 0.5186825922290497, val_loss: 0.5040046147768562 \n",
      "round 711, train_loss: 0.518568209435279, val_loss: 0.5038705181811023 \n",
      "round 712, train_loss: 0.5184539841500254, val_loss: 0.5037366127587416 \n",
      "round 713, train_loss: 0.518339916049762, val_loss: 0.5036028981161265 \n",
      "round 714, train_loss: 0.5182260048118538, val_loss: 0.5034693738607428 \n",
      "round 715, train_loss: 0.5181122501145536, val_loss: 0.5033360396012082 \n",
      "round 716, train_loss: 0.5179986516370008, val_loss: 0.5032028949472657 \n",
      "round 717, train_loss: 0.517885209059217, val_loss: 0.5030699395097795 \n",
      "round 718, train_loss: 0.5177719220621037, val_loss: 0.5029371729007325 \n",
      "round 719, train_loss: 0.5176587903274374, val_loss: 0.502804594733219 \n",
      "round 720, train_loss: 0.5175458135378701, val_loss: 0.5026722046214428 \n",
      "round 721, train_loss: 0.5174329913769229, val_loss: 0.502540002180712 \n",
      "round 722, train_loss: 0.5173203235289846, val_loss: 0.5024079870274346 \n",
      "round 723, train_loss: 0.5172078096793085, val_loss: 0.502276158779114 \n",
      "round 724, train_loss: 0.5170954495140092, val_loss: 0.502144517054346 \n",
      "round 725, train_loss: 0.5169832427200602, val_loss: 0.5020130614728128 \n",
      "round 726, train_loss: 0.5168711889852902, val_loss: 0.5018817916552802 \n",
      "round 727, train_loss: 0.5167592879983807, val_loss: 0.501750707223593 \n",
      "round 728, train_loss: 0.516647539448863, val_loss: 0.5016198078006708 \n",
      "round 729, train_loss: 0.5165359430271149, val_loss: 0.5014890930105036 \n",
      "round 730, train_loss: 0.5164244984243586, val_loss: 0.5013585624781478 \n",
      "round 731, train_loss: 0.5163132053326568, val_loss: 0.5012282158297231 \n",
      "round 732, train_loss: 0.5162020634449106, val_loss: 0.5010980526924066 \n",
      "round 733, train_loss: 0.5160910724548566, val_loss: 0.5009680726944306 \n",
      "round 734, train_loss: 0.5159802320570633, val_loss: 0.5008382754650766 \n",
      "round 735, train_loss: 0.5158695419469294, val_loss: 0.5007086606346739 \n",
      "round 736, train_loss: 0.5157590018206801, val_loss: 0.5005792278345929 \n",
      "round 737, train_loss: 0.5156486113753641, val_loss: 0.5004499766972428 \n",
      "round 738, train_loss: 0.5155383703088522, val_loss: 0.5003209068560673 \n",
      "round 739, train_loss: 0.5154282783198325, val_loss: 0.5001920179455401 \n",
      "round 740, train_loss: 0.51531833510781, val_loss: 0.500063309601162 \n",
      "round 741, train_loss: 0.515208540373101, val_loss: 0.4999347814594563 \n",
      "round 742, train_loss: 0.515098893816833, val_loss: 0.4998064331579645 \n",
      "round 743, train_loss: 0.5149893951409406, val_loss: 0.4996782643352445 \n",
      "round 744, train_loss: 0.5148800440481618, val_loss: 0.4995502746308634 \n",
      "round 745, train_loss: 0.5147708402420383, val_loss: 0.49942246368539694 \n",
      "round 746, train_loss: 0.5146617834269102, val_loss: 0.49929483114042394 \n",
      "round 747, train_loss: 0.5145528733079131, val_loss: 0.49916737663852273 \n",
      "round 748, train_loss: 0.5144441095909777, val_loss: 0.49904009982326825 \n",
      "round 749, train_loss: 0.5143354919828245, val_loss: 0.49891300033922703 \n",
      "round 750, train_loss: 0.5142270201909641, val_loss: 0.4987860778319537 \n",
      "round 751, train_loss: 0.5141186939236908, val_loss: 0.4986593319479891 \n",
      "round 752, train_loss: 0.5140105128900839, val_loss: 0.49853276233485383 \n",
      "round 753, train_loss: 0.5139024768000015, val_loss: 0.49840636864104637 \n",
      "round 754, train_loss: 0.5137945853640806, val_loss: 0.49828015051603947 \n",
      "round 755, train_loss: 0.5136868382937327, val_loss: 0.4981541076102753 \n",
      "round 756, train_loss: 0.513579235301143, val_loss: 0.4980282395751628 \n",
      "round 757, train_loss: 0.5134717760992654, val_loss: 0.49790254606307394 \n",
      "round 758, train_loss: 0.5133644604018217, val_loss: 0.4977770267273401 \n",
      "round 759, train_loss: 0.5132572879232992, val_loss: 0.49765168122224857 \n",
      "round 760, train_loss: 0.5131502583789461, val_loss: 0.49752650920303854 \n",
      "round 761, train_loss: 0.5130433714847722, val_loss: 0.4974015103258979 \n",
      "round 762, train_loss: 0.5129366269575428, val_loss: 0.4972766842479606 \n",
      "round 763, train_loss: 0.5128300245147785, val_loss: 0.4971520306273008 \n",
      "round 764, train_loss: 0.512723563874752, val_loss: 0.497027549122933 \n",
      "round 765, train_loss: 0.5126172447564863, val_loss: 0.4969032393948043 \n",
      "round 766, train_loss: 0.5125110668797506, val_loss: 0.49677910110379453 \n",
      "round 767, train_loss: 0.5124050299650587, val_loss: 0.49665513391171096 \n",
      "round 768, train_loss: 0.5122991337336672, val_loss: 0.49653133748128564 \n",
      "round 769, train_loss: 0.5121933779075719, val_loss: 0.49640771147617124 \n",
      "round 770, train_loss: 0.5120877622095062, val_loss: 0.49628425556093886 \n",
      "round 771, train_loss: 0.511982286362938, val_loss: 0.4961609694010737 \n",
      "round 772, train_loss: 0.5118769500920677, val_loss: 0.49603785266297135 \n",
      "round 773, train_loss: 0.5117717531218251, val_loss: 0.49591490501393637 \n",
      "round 774, train_loss: 0.5116666951778683, val_loss: 0.49579212612217655 \n",
      "round 775, train_loss: 0.5115617759865798, val_loss: 0.4956695156568012 \n",
      "round 776, train_loss: 0.5114569952750653, val_loss: 0.4955470732878178 \n",
      "round 777, train_loss: 0.5113523527711501, val_loss: 0.495424798686128 \n",
      "round 778, train_loss: 0.5112478482033775, val_loss: 0.49530269152352424 \n",
      "round 779, train_loss: 0.5111434813010066, val_loss: 0.4951807514726887 \n",
      "round 780, train_loss: 0.51103925179401, val_loss: 0.4950589782071859 \n",
      "round 781, train_loss: 0.5109351594130701, val_loss: 0.4949373714014646 \n",
      "round 782, train_loss: 0.5108312038895788, val_loss: 0.49481593073084995 \n",
      "round 783, train_loss: 0.5107273849556331, val_loss: 0.4946946558715435 \n",
      "round 784, train_loss: 0.5106237023440342, val_loss: 0.4945735465006188 \n",
      "round 785, train_loss: 0.5105201557882849, val_loss: 0.49445260229601773 \n",
      "round 786, train_loss: 0.5104167450225874, val_loss: 0.4943318229365487 \n",
      "round 787, train_loss: 0.51031346978184, val_loss: 0.4942112081018822 \n",
      "round 788, train_loss: 0.5102103298016357, val_loss: 0.49409075747254955 \n",
      "round 789, train_loss: 0.5101073248182605, val_loss: 0.49397047072993694 \n",
      "round 790, train_loss: 0.5100044545686896, val_loss: 0.4938503475562852 \n",
      "round 791, train_loss: 0.5099017187905863, val_loss: 0.493730387634685 \n",
      "round 792, train_loss: 0.509799117222299, val_loss: 0.49361059064907464 \n",
      "round 793, train_loss: 0.5096966496028601, val_loss: 0.4934909562842369 \n",
      "round 794, train_loss: 0.5095943156719821, val_loss: 0.49337148422579513 \n",
      "round 795, train_loss: 0.5094921151700571, val_loss: 0.4932521741602119 \n",
      "round 796, train_loss: 0.5093900478381531, val_loss: 0.49313302577478463 \n",
      "round 797, train_loss: 0.5092881134180124, val_loss: 0.49301403875764305 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 798, train_loss: 0.5091863116520501, val_loss: 0.49289521279774634 \n",
      "round 799, train_loss: 0.5090846422833508, val_loss: 0.49277654758488043 \n",
      "round 800, train_loss: 0.5089831050556669, val_loss: 0.49265804280965425 \n",
      "round 801, train_loss: 0.5088816997134156, val_loss: 0.49253969816349774 \n",
      "round 802, train_loss: 0.5087804260016795, val_loss: 0.4924215133386583 \n",
      "round 803, train_loss: 0.5086792836662004, val_loss: 0.492303488028198 \n",
      "round 804, train_loss: 0.5085782724533805, val_loss: 0.49218562192599097 \n",
      "round 805, train_loss: 0.5084773921102779, val_loss: 0.49206791472672073 \n",
      "round 806, train_loss: 0.5083766423846067, val_loss: 0.4919503661258768 \n",
      "round 807, train_loss: 0.5082760230247326, val_loss: 0.49183297581975133 \n",
      "round 808, train_loss: 0.508175533779673, val_loss: 0.49171574350543806 \n",
      "round 809, train_loss: 0.5080751743990924, val_loss: 0.4915986688808279 \n",
      "round 810, train_loss: 0.507974944633303, val_loss: 0.49148175164460683 \n",
      "round 811, train_loss: 0.5078748442332599, val_loss: 0.49136499149625273 \n",
      "round 812, train_loss: 0.5077748729505622, val_loss: 0.4912483881360331 \n",
      "round 813, train_loss: 0.5076750305374474, val_loss: 0.4911319412650022 \n",
      "round 814, train_loss: 0.5075753167467919, val_loss: 0.4910156505849974 \n",
      "round 815, train_loss: 0.5074757313321081, val_loss: 0.4908995157986375 \n",
      "round 816, train_loss: 0.5073762740475419, val_loss: 0.4907835366093207 \n",
      "round 817, train_loss: 0.5072769446478711, val_loss: 0.4906677127212189 \n",
      "round 818, train_loss: 0.5071777428885043, val_loss: 0.49055204383927903 \n",
      "round 819, train_loss: 0.5070786685254765, val_loss: 0.49043652966921647 \n",
      "round 820, train_loss: 0.5069797213154493, val_loss: 0.49032116991751534 \n",
      "round 821, train_loss: 0.5068809010157086, val_loss: 0.4902059642914247 \n",
      "round 822, train_loss: 0.5067822073841609, val_loss: 0.4900909124989552 \n",
      "round 823, train_loss: 0.5066836401793329, val_loss: 0.48997601424887754 \n",
      "round 824, train_loss: 0.5065851991603699, val_loss: 0.4898612692507191 \n",
      "round 825, train_loss: 0.506486884087032, val_loss: 0.48974667721476256 \n",
      "round 826, train_loss: 0.5063886947196933, val_loss: 0.48963223785204135 \n",
      "round 827, train_loss: 0.50629063081934, val_loss: 0.4895179508743388 \n",
      "round 828, train_loss: 0.5061926921475687, val_loss: 0.48940381599418425 \n",
      "round 829, train_loss: 0.5060948784665827, val_loss: 0.48928983292485173 \n",
      "round 830, train_loss: 0.5059971895391925, val_loss: 0.4891760013803561 \n",
      "round 831, train_loss: 0.5058996251288123, val_loss: 0.48906232107545194 \n",
      "round 832, train_loss: 0.5058021849994581, val_loss: 0.4889487917256295 \n",
      "round 833, train_loss: 0.5057048689157466, val_loss: 0.4888354130471131 \n",
      "round 834, train_loss: 0.5056076766428923, val_loss: 0.48872218475685875 \n",
      "round 835, train_loss: 0.505510607946707, val_loss: 0.4886091065725508 \n",
      "round 836, train_loss: 0.5054136625935957, val_loss: 0.48849617821260055 \n",
      "round 837, train_loss: 0.5053168403505571, val_loss: 0.48838339939614284 \n",
      "round 838, train_loss: 0.5052201409851805, val_loss: 0.4882707698430338 \n",
      "round 839, train_loss: 0.5051235642656433, val_loss: 0.4881582892738487 \n",
      "round 840, train_loss: 0.5050271099607108, val_loss: 0.48804595740987977 \n",
      "round 841, train_loss: 0.5049307778397325, val_loss: 0.48793377397313215 \n",
      "round 842, train_loss: 0.5048345676726419, val_loss: 0.48782173868632406 \n",
      "round 843, train_loss: 0.504738479229954, val_loss: 0.4877098512728821 \n",
      "round 844, train_loss: 0.5046425122827627, val_loss: 0.4875981114569395 \n",
      "round 845, train_loss: 0.5045466666027397, val_loss: 0.4874865189633342 \n",
      "round 846, train_loss: 0.5044509419621332, val_loss: 0.4873750735176069 \n",
      "round 847, train_loss: 0.504355338133765, val_loss: 0.487263774845997 \n",
      "round 848, train_loss: 0.5042598548910294, val_loss: 0.48715262267544107 \n",
      "round 849, train_loss: 0.5041644920078907, val_loss: 0.4870416167335719 \n",
      "round 850, train_loss: 0.5040692492588824, val_loss: 0.48693075674871417 \n",
      "round 851, train_loss: 0.5039741264191047, val_loss: 0.4868200424498819 \n",
      "round 852, train_loss: 0.5038791232642222, val_loss: 0.4867094735667787 \n",
      "round 853, train_loss: 0.5037842395704646, val_loss: 0.48659904982979274 \n",
      "round 854, train_loss: 0.5036894751146205, val_loss: 0.48648877096999643 \n",
      "round 855, train_loss: 0.5035948296740411, val_loss: 0.4863786367191423 \n",
      "round 856, train_loss: 0.503500303026633, val_loss: 0.4862686468096618 \n",
      "round 857, train_loss: 0.5034058949508603, val_loss: 0.48615880097466385 \n",
      "round 858, train_loss: 0.5033116052257416, val_loss: 0.4860490989479302 \n",
      "round 859, train_loss: 0.5032174336308487, val_loss: 0.4859395404639159 \n",
      "round 860, train_loss: 0.503123379946303, val_loss: 0.4858301252577449 \n",
      "round 861, train_loss: 0.5030294439527766, val_loss: 0.48572085306520846 \n",
      "round 862, train_loss: 0.5029356254314881, val_loss: 0.48561172362276456 \n",
      "round 863, train_loss: 0.5028419241642024, val_loss: 0.4855027366675325 \n",
      "round 864, train_loss: 0.5027483399332289, val_loss: 0.4853938919372935 \n",
      "round 865, train_loss: 0.5026548725214187, val_loss: 0.48528518917048696 \n",
      "round 866, train_loss: 0.5025615217121647, val_loss: 0.48517662810620876 \n",
      "round 867, train_loss: 0.5024682872893971, val_loss: 0.4850682084842101 \n",
      "round 868, train_loss: 0.5023751690375852, val_loss: 0.48495993004489296 \n",
      "round 869, train_loss: 0.5022821667417333, val_loss: 0.4848517925293097 \n",
      "round 870, train_loss: 0.5021892801873796, val_loss: 0.48474379567916137 \n",
      "round 871, train_loss: 0.5020965091605952, val_loss: 0.4846359392367934 \n",
      "round 872, train_loss: 0.5020038534479808, val_loss: 0.4845282229451954 \n",
      "round 873, train_loss: 0.5019113128366673, val_loss: 0.48442064654799905 \n",
      "round 874, train_loss: 0.5018188871143127, val_loss: 0.4843132097894741 \n",
      "round 875, train_loss: 0.5017265760691004, val_loss: 0.4842059124145285 \n",
      "round 876, train_loss: 0.5016343794897379, val_loss: 0.4840987541687049 \n",
      "round 877, train_loss: 0.501542297165456, val_loss: 0.4839917347981795 \n",
      "round 878, train_loss: 0.5014503288860055, val_loss: 0.4838848540497583 \n",
      "round 879, train_loss: 0.5013584744416567, val_loss: 0.4837781116708776 \n",
      "round 880, train_loss: 0.501266733623198, val_loss: 0.48367150740959974 \n",
      "round 881, train_loss: 0.5011751062219335, val_loss: 0.4835650410146122 \n",
      "round 882, train_loss: 0.5010835920296816, val_loss: 0.4834587122352248 \n",
      "round 883, train_loss: 0.5009921908387739, val_loss: 0.4833525208213685 \n",
      "round 884, train_loss: 0.5009009024420529, val_loss: 0.4832464665235929 \n",
      "round 885, train_loss: 0.5008097266328713, val_loss: 0.48314054909306375 \n",
      "round 886, train_loss: 0.5007186632050894, val_loss: 0.48303476828156217 \n",
      "round 887, train_loss: 0.5006277119530745, val_loss: 0.4829291238414818 \n",
      "round 888, train_loss: 0.5005368726716986, val_loss: 0.48282361552582626 \n",
      "round 889, train_loss: 0.5004461451563376, val_loss: 0.4827182430882089 \n",
      "round 890, train_loss: 0.5003555292028686, val_loss: 0.4826130062828491 \n",
      "round 891, train_loss: 0.5002650246076695, val_loss: 0.48250790486457135 \n",
      "round 892, train_loss: 0.5001746311676171, val_loss: 0.4824029385888023 \n",
      "round 893, train_loss: 0.5000843486800852, val_loss: 0.4822981072115707 \n",
      "round 894, train_loss: 0.4999941769429438, val_loss: 0.4821934104895028 \n",
      "round 895, train_loss: 0.49990411575455607, val_loss: 0.48208884817982256 \n",
      "round 896, train_loss: 0.4998141649137788, val_loss: 0.4819844200403488 \n",
      "round 897, train_loss: 0.49972432421996005, val_loss: 0.4818801258294939 \n",
      "round 898, train_loss: 0.49963459347293737, val_loss: 0.4817759653062606 \n",
      "round 899, train_loss: 0.4995449724730363, val_loss: 0.4816719382302418 \n",
      "round 900, train_loss: 0.4994554610210692, val_loss: 0.48156804436161715 \n",
      "round 901, train_loss: 0.49936605891833363, val_loss: 0.4814642834611519 \n",
      "round 902, train_loss: 0.49927676596661114, val_loss: 0.48136065529019595 \n",
      "round 903, train_loss: 0.49918758196816504, val_loss: 0.4812571596106797 \n",
      "round 904, train_loss: 0.49909850672573963, val_loss: 0.48115379618511417 \n",
      "round 905, train_loss: 0.4990095400425592, val_loss: 0.48105056477658786 \n",
      "round 906, train_loss: 0.4989206817223247, val_loss: 0.4809474651487662 \n",
      "round 907, train_loss: 0.4988319315692142, val_loss: 0.4808444970658884 \n",
      "round 908, train_loss: 0.4987432893878805, val_loss: 0.4807416602927667 \n",
      "round 909, train_loss: 0.49865475498345024, val_loss: 0.4806389545947838 \n",
      "round 910, train_loss: 0.49856632816152163, val_loss: 0.48053637973789154 \n",
      "round 911, train_loss: 0.49847800872816406, val_loss: 0.480433935488608 \n",
      "round 912, train_loss: 0.4983897964899154, val_loss: 0.48033162161401755 \n",
      "round 913, train_loss: 0.49830169125378176, val_loss: 0.4802294378817678 \n",
      "round 914, train_loss: 0.4982136928272353, val_loss: 0.4801273840600676 \n",
      "round 915, train_loss: 0.49812580101821374, val_loss: 0.4800254599176866 \n",
      "round 916, train_loss: 0.4980380156351178, val_loss: 0.47992366522395136 \n",
      "round 917, train_loss: 0.4979503364868103, val_loss: 0.4798219997487458 \n",
      "round 918, train_loss: 0.49786276338261504, val_loss: 0.4797204632625083 \n",
      "round 919, train_loss: 0.49777529613231486, val_loss: 0.4796190555362299 \n",
      "round 920, train_loss: 0.49768793454615107, val_loss: 0.4795177763414525 \n",
      "round 921, train_loss: 0.4976006784348208, val_loss: 0.47941662545026814 \n",
      "round 922, train_loss: 0.49751352760947704, val_loss: 0.4793156026353157 \n",
      "round 923, train_loss: 0.49742648188172595, val_loss: 0.47921470766978064 \n",
      "round 924, train_loss: 0.49733954106362677, val_loss: 0.4791139403273922 \n",
      "round 925, train_loss: 0.49725270496768936, val_loss: 0.47901330038242224 \n",
      "round 926, train_loss: 0.4971659734068734, val_loss: 0.4789127876096837 \n",
      "round 927, train_loss: 0.49707934619458694, val_loss: 0.478812401784528 \n",
      "round 928, train_loss: 0.4969928231446853, val_loss: 0.47871214268284445 \n",
      "round 929, train_loss: 0.496906404071469, val_loss: 0.4786120100810581 \n",
      "round 930, train_loss: 0.4968200887896835, val_loss: 0.4785120037561277 \n",
      "round 931, train_loss: 0.4967338771145163, val_loss: 0.47841212348554457 \n",
      "round 932, train_loss: 0.4966477688615973, val_loss: 0.478312369047331 \n",
      "round 933, train_loss: 0.496561763846997, val_loss: 0.4782127402200379 \n",
      "round 934, train_loss: 0.496475861887224, val_loss: 0.4781132367827438 \n",
      "round 935, train_loss: 0.4963900627992252, val_loss: 0.47801385851505307 \n",
      "round 936, train_loss: 0.4963043664003842, val_loss: 0.477914605197094 \n",
      "round 937, train_loss: 0.49621877250851865, val_loss: 0.4778154766095176 \n",
      "round 938, train_loss: 0.4961332809418812, val_loss: 0.4777164725334955 \n",
      "round 939, train_loss: 0.49604789151915574, val_loss: 0.477617592750719 \n",
      "round 940, train_loss: 0.49596260405945874, val_loss: 0.47751883704339654 \n",
      "round 941, train_loss: 0.4958774183823353, val_loss: 0.47742020519425304 \n",
      "round 942, train_loss: 0.49579233430776004, val_loss: 0.47732169698652754 \n",
      "round 943, train_loss: 0.49570735165613433, val_loss: 0.47722331220397224 \n",
      "round 944, train_loss: 0.4956224702482863, val_loss: 0.47712505063085003 \n",
      "round 945, train_loss: 0.49553768990546787, val_loss: 0.47702691205193465 \n",
      "round 946, train_loss: 0.4954530104493557, val_loss: 0.47692889625250645 \n",
      "round 947, train_loss: 0.4953684317020475, val_loss: 0.47683100301835324 \n",
      "round 948, train_loss: 0.4952839534860629, val_loss: 0.47673323213576807 \n",
      "round 949, train_loss: 0.4951995756243411, val_loss: 0.4766355833915461 \n",
      "round 950, train_loss: 0.49511529794023984, val_loss: 0.47653805657298653 \n",
      "round 951, train_loss: 0.49503112025753376, val_loss: 0.4764406514678867 \n",
      "round 952, train_loss: 0.4949470424004144, val_loss: 0.47634336786454423 \n",
      "round 953, train_loss: 0.4948630641934869, val_loss: 0.476246205551753 \n",
      "round 954, train_loss: 0.49477918546177113, val_loss: 0.47614916431880344 \n",
      "round 955, train_loss: 0.49469540603069856, val_loss: 0.47605224395548 \n",
      "round 956, train_loss: 0.4946117257261121, val_loss: 0.47595544425205955 \n",
      "round 957, train_loss: 0.494528144374265, val_loss: 0.47585876499931046 \n",
      "round 958, train_loss: 0.49444466180181823, val_loss: 0.47576220598849095 \n",
      "round 959, train_loss: 0.4943612778358413, val_loss: 0.4756657670113469 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 960, train_loss: 0.49427799230380937, val_loss: 0.47556944786011096 \n",
      "round 961, train_loss: 0.4941948050336026, val_loss: 0.4754732483275023 \n",
      "round 962, train_loss: 0.4941117158535059, val_loss: 0.47537716820672227 \n",
      "round 963, train_loss: 0.4940287245922058, val_loss: 0.4752812072914552 \n",
      "round 964, train_loss: 0.49394583107879136, val_loss: 0.47518536537586625 \n",
      "round 965, train_loss: 0.49386303514275137, val_loss: 0.4750896422545997 \n",
      "round 966, train_loss: 0.4937803366139742, val_loss: 0.47499403772277815 \n",
      "round 967, train_loss: 0.4936977353227455, val_loss: 0.47489855157599997 \n",
      "round 968, train_loss: 0.49361523109974853, val_loss: 0.47480318361033996 \n",
      "round 969, train_loss: 0.49353282377606195, val_loss: 0.47470793362234476 \n",
      "round 970, train_loss: 0.49345051318315936, val_loss: 0.4746128014090342 \n",
      "round 971, train_loss: 0.4933682991529062, val_loss: 0.4745177867678989 \n",
      "round 972, train_loss: 0.4932861815175622, val_loss: 0.47442288949689826 \n",
      "round 973, train_loss: 0.49320416010977647, val_loss: 0.4743281093944595 \n",
      "round 974, train_loss: 0.49312223476258893, val_loss: 0.47423344625947705 \n",
      "round 975, train_loss: 0.49304040530942805, val_loss: 0.47413889989131014 \n",
      "round 976, train_loss: 0.4929586715841095, val_loss: 0.474044470089781 \n",
      "round 977, train_loss: 0.4928770334208361, val_loss: 0.47395015665517487 \n",
      "round 978, train_loss: 0.4927954906541957, val_loss: 0.47385595938823816 \n",
      "round 979, train_loss: 0.4927140431191604, val_loss: 0.47376187809017545 \n",
      "round 980, train_loss: 0.49263269065108534, val_loss: 0.47366791256265084 \n",
      "round 981, train_loss: 0.49255143308570787, val_loss: 0.47357406260778434 \n",
      "round 982, train_loss: 0.492470270259146, val_loss: 0.4734803280281519 \n",
      "round 983, train_loss: 0.49238920200789776, val_loss: 0.47338670862678284 \n",
      "round 984, train_loss: 0.49230822816883985, val_loss: 0.4732932042071604 \n",
      "round 985, train_loss: 0.4922273485792259, val_loss: 0.47319981457321747 \n",
      "round 986, train_loss: 0.4921465630766869, val_loss: 0.47310653952933773 \n",
      "round 987, train_loss: 0.4920658714992288, val_loss: 0.4730133788803539 \n",
      "round 988, train_loss: 0.4919852736852317, val_loss: 0.47292033243154546 \n",
      "round 989, train_loss: 0.4919047694734493, val_loss: 0.4728273999886377 \n",
      "round 990, train_loss: 0.4918243587030068, val_loss: 0.4727345813578011 \n",
      "round 991, train_loss: 0.49174404121340143, val_loss: 0.47264187634564864 \n",
      "round 992, train_loss: 0.49166381684449956, val_loss: 0.47254928475923635 \n",
      "round 993, train_loss: 0.4915836854365362, val_loss: 0.47245680640605986 \n",
      "round 994, train_loss: 0.4915036468301153, val_loss: 0.47236444109405507 \n",
      "round 995, train_loss: 0.4914237008662065, val_loss: 0.47227218863159526 \n",
      "round 996, train_loss: 0.491343847386146, val_loss: 0.472180048827491 \n",
      "round 997, train_loss: 0.4912640862316338, val_loss: 0.47208802149098783 \n",
      "round 998, train_loss: 0.4911844172447343, val_loss: 0.4719961064317659 \n",
      "round 999, train_loss: 0.4911048402678737, val_loss: 0.4719043034599383 \n",
      "round 1000, train_loss: 0.4910253551438404, val_loss: 0.4718126123860493 \n",
      "round 1001, train_loss: 0.49094596171578236, val_loss: 0.4717210330210741 \n",
      "round 1002, train_loss: 0.49086665982720845, val_loss: 0.4716295651764164 \n",
      "round 1003, train_loss: 0.4907874493219838, val_loss: 0.4715382086639082 \n",
      "round 1004, train_loss: 0.49070833004433295, val_loss: 0.4714469632958079 \n",
      "round 1005, train_loss: 0.4906293018388359, val_loss: 0.47135582888479877 \n",
      "round 1006, train_loss: 0.4905503645504275, val_loss: 0.47126480524398906 \n",
      "round 1007, train_loss: 0.4904715180243974, val_loss: 0.47117389218690936 \n",
      "round 1008, train_loss: 0.4903927621063885, val_loss: 0.47108308952751127 \n",
      "round 1009, train_loss: 0.4903140966423962, val_loss: 0.47099239708016805 \n",
      "round 1010, train_loss: 0.49023552147876626, val_loss: 0.47090181465967046 \n",
      "round 1011, train_loss: 0.4901570364621956, val_loss: 0.4708113420812283 \n",
      "round 1012, train_loss: 0.49007864143972973, val_loss: 0.4707209791604681 \n",
      "round 1013, train_loss: 0.49000033625876305, val_loss: 0.47063072571343123 \n",
      "round 1014, train_loss: 0.4899221207670366, val_loss: 0.4705405815565736 \n",
      "round 1015, train_loss: 0.4898439948126375, val_loss: 0.4704505465067635 \n",
      "round 1016, train_loss: 0.4897659582439992, val_loss: 0.47036062038128196 \n",
      "round 1017, train_loss: 0.48968801090989816, val_loss: 0.4702708029978204 \n",
      "round 1018, train_loss: 0.4896101526594547, val_loss: 0.47018109417447945 \n",
      "round 1019, train_loss: 0.48953238334213167, val_loss: 0.4700914937297678 \n",
      "round 1020, train_loss: 0.4894547028077329, val_loss: 0.4700020014826017 \n",
      "round 1021, train_loss: 0.4893771109064024, val_loss: 0.469912617252303 \n",
      "round 1022, train_loss: 0.4892996074886242, val_loss: 0.46982334085859795 \n",
      "round 1023, train_loss: 0.4892221924052202, val_loss: 0.4697341721216167 \n",
      "round 1024, train_loss: 0.4891448655073498, val_loss: 0.46964511086189187 \n",
      "round 1025, train_loss: 0.48906762664650916, val_loss: 0.4695561569003568 \n",
      "round 1026, train_loss: 0.4889904756745301, val_loss: 0.4694673100583453 \n",
      "round 1027, train_loss: 0.48891341244357794, val_loss: 0.46937857015758977 \n",
      "round 1028, train_loss: 0.48883643680615346, val_loss: 0.46928993702022015 \n",
      "round 1029, train_loss: 0.48875954861508875, val_loss: 0.4692014104687629 \n",
      "round 1030, train_loss: 0.4886827477235477, val_loss: 0.46911299032614084 \n",
      "round 1031, train_loss: 0.4886060339850258, val_loss: 0.4690246764156702 \n",
      "round 1032, train_loss: 0.4885294072533479, val_loss: 0.46893646856106036 \n",
      "round 1033, train_loss: 0.48845286738266785, val_loss: 0.46884836658641293 \n",
      "round 1034, train_loss: 0.4883764142274674, val_loss: 0.46876037031622053 \n",
      "round 1035, train_loss: 0.48830004764255525, val_loss: 0.46867247957536523 \n",
      "round 1036, train_loss: 0.48822376748306695, val_loss: 0.468584694189118 \n",
      "round 1037, train_loss: 0.4881475736044628, val_loss: 0.4684970139831372 \n",
      "round 1038, train_loss: 0.4880714658625273, val_loss: 0.46840943878346764 \n",
      "round 1039, train_loss: 0.4879954441133686, val_loss: 0.46832196841653945 \n",
      "round 1040, train_loss: 0.48791950821341723, val_loss: 0.468234602709167 \n",
      "round 1041, train_loss: 0.48784365801942514, val_loss: 0.46814734148854786 \n",
      "round 1042, train_loss: 0.4877678933884652, val_loss: 0.4680601845822612 \n",
      "round 1043, train_loss: 0.4876922141779302, val_loss: 0.4679731318182675 \n",
      "round 1044, train_loss: 0.48761662024553176, val_loss: 0.4678861830249073 \n",
      "round 1045, train_loss: 0.4875411114492987, val_loss: 0.46779933803089957 \n",
      "round 1046, train_loss: 0.48746568764757814, val_loss: 0.46771259666534054 \n",
      "round 1047, train_loss: 0.48739034869903225, val_loss: 0.46762595875770346 \n",
      "round 1048, train_loss: 0.4873150944626396, val_loss: 0.4675394241378379 \n",
      "round 1049, train_loss: 0.4872399247976927, val_loss: 0.4674529926359661 \n",
      "round 1050, train_loss: 0.4871648395637969, val_loss: 0.4673666640826854 \n",
      "round 1051, train_loss: 0.48708983862087146, val_loss: 0.46728043830896454 \n",
      "round 1052, train_loss: 0.48701492182914685, val_loss: 0.46719431514614373 \n",
      "round 1053, train_loss: 0.4869400890491636, val_loss: 0.46710829442593343 \n",
      "round 1054, train_loss: 0.48686534014177457, val_loss: 0.46702237598041385 \n",
      "round 1055, train_loss: 0.486790674968139, val_loss: 0.46693655964203207 \n",
      "round 1056, train_loss: 0.48671609338972616, val_loss: 0.4668508452436032 \n",
      "round 1057, train_loss: 0.4866415952683134, val_loss: 0.4667652326183084 \n",
      "round 1058, train_loss: 0.4865671804659823, val_loss: 0.4666797215996934 \n",
      "round 1059, train_loss: 0.4864928488451225, val_loss: 0.46659431202166857 \n",
      "round 1060, train_loss: 0.4864186002684271, val_loss: 0.46650900371850623 \n",
      "round 1061, train_loss: 0.4863444345988941, val_loss: 0.4664237965248422 \n",
      "round 1062, train_loss: 0.48627035169982386, val_loss: 0.4663386902756711 \n",
      "round 1063, train_loss: 0.4861963514348203, val_loss: 0.4662536848063497 \n",
      "round 1064, train_loss: 0.48612243366778785, val_loss: 0.4661687799525917 \n",
      "round 1065, train_loss: 0.48604859826293123, val_loss: 0.4660839755504703 \n",
      "round 1066, train_loss: 0.4859748450847564, val_loss: 0.4659992714364145 \n",
      "round 1067, train_loss: 0.4859011739980675, val_loss: 0.4659146674472099 \n",
      "round 1068, train_loss: 0.4858275848679666, val_loss: 0.4658301634199963 \n",
      "round 1069, train_loss: 0.4857540775598537, val_loss: 0.46574575919226796 \n",
      "round 1070, train_loss: 0.4856806519394247, val_loss: 0.465661454601872 \n",
      "round 1071, train_loss: 0.48560730787267214, val_loss: 0.46557724948700685 \n",
      "round 1072, train_loss: 0.48553404522588267, val_loss: 0.46549314368622224 \n",
      "round 1073, train_loss: 0.48546086386563664, val_loss: 0.4654091370384186 \n",
      "round 1074, train_loss: 0.4853877636588089, val_loss: 0.4653252293828437 \n",
      "round 1075, train_loss: 0.4853147444725656, val_loss: 0.4652414205590946 \n",
      "round 1076, train_loss: 0.4852418061743654, val_loss: 0.4651577104071154 \n",
      "round 1077, train_loss: 0.4851689486319572, val_loss: 0.4650740987671957 \n",
      "round 1078, train_loss: 0.4850961717133798, val_loss: 0.4649905854799701 \n",
      "round 1079, train_loss: 0.4850234752869622, val_loss: 0.4649071703864179 \n",
      "round 1080, train_loss: 0.4849508592213204, val_loss: 0.4648238533278609 \n",
      "round 1081, train_loss: 0.4848783233853591, val_loss: 0.46474063414596456 \n",
      "round 1082, train_loss: 0.4848058676482696, val_loss: 0.46465751268273353 \n",
      "round 1083, train_loss: 0.4847334918795293, val_loss: 0.4645744887805141 \n",
      "round 1084, train_loss: 0.4846611959489007, val_loss: 0.46449156228199173 \n",
      "round 1085, train_loss: 0.48458897972643017, val_loss: 0.46440873303019076 \n",
      "round 1086, train_loss: 0.4845168430824495, val_loss: 0.46432600086847203 \n",
      "round 1087, train_loss: 0.4844447858875719, val_loss: 0.46424336564053365 \n",
      "round 1088, train_loss: 0.48437280801269283, val_loss: 0.4641608271904097 \n",
      "round 1089, train_loss: 0.48430090932898995, val_loss: 0.4640783853624681 \n",
      "round 1090, train_loss: 0.4842290897079209, val_loss: 0.46399604000141065 \n",
      "round 1091, train_loss: 0.4841573490212232, val_loss: 0.4639137909522732 \n",
      "round 1092, train_loss: 0.4840856871409133, val_loss: 0.4638316380604221 \n",
      "round 1093, train_loss: 0.4840141039392866, val_loss: 0.46374958117155557 \n",
      "round 1094, train_loss: 0.4839425992889154, val_loss: 0.4636676201317021 \n",
      "round 1095, train_loss: 0.4838711730626494, val_loss: 0.4635857547872186 \n",
      "round 1096, train_loss: 0.48379982513361336, val_loss: 0.46350398498479084 \n",
      "round 1097, train_loss: 0.4837285553752079, val_loss: 0.46342231057143246 \n",
      "round 1098, train_loss: 0.4836573636611085, val_loss: 0.4633407313944827 \n",
      "round 1099, train_loss: 0.4835862498652637, val_loss: 0.46325924730160684 \n",
      "round 1100, train_loss: 0.4835152138618957, val_loss: 0.4631778581407952 \n",
      "round 1101, train_loss: 0.48344425552549863, val_loss: 0.4630965637603612 \n",
      "round 1102, train_loss: 0.483373374730838, val_loss: 0.4630153640089423 \n",
      "round 1103, train_loss: 0.4833025713529503, val_loss: 0.46293425873549665 \n",
      "round 1104, train_loss: 0.4832318452671426, val_loss: 0.46285324778930514 \n",
      "round 1105, train_loss: 0.48316119634899035, val_loss: 0.4627723310199677 \n",
      "round 1106, train_loss: 0.4830906244743381, val_loss: 0.46269150827740424 \n",
      "round 1107, train_loss: 0.48302012951929846, val_loss: 0.4626107794118533 \n",
      "round 1108, train_loss: 0.48294971136025083, val_loss: 0.46253014427387107 \n",
      "round 1109, train_loss: 0.482879369873841, val_loss: 0.4624496027143306 \n",
      "round 1110, train_loss: 0.4828091049369809, val_loss: 0.4623691545844207 \n",
      "round 1111, train_loss: 0.4827389164268469, val_loss: 0.4622887997356455 \n",
      "round 1112, train_loss: 0.48266880422088, val_loss: 0.46220853801982326 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1113, train_loss: 0.48259876819678443, val_loss: 0.4621283692890862 \n",
      "round 1114, train_loss: 0.4825288082325277, val_loss: 0.4620482933958781 \n",
      "round 1115, train_loss: 0.4824589242063385, val_loss: 0.4619683101929551 \n",
      "round 1116, train_loss: 0.48238911599670853, val_loss: 0.46188841953338433 \n",
      "round 1117, train_loss: 0.4823193834823887, val_loss: 0.4618086212705427 \n",
      "round 1118, train_loss: 0.4822497265423903, val_loss: 0.46172891525811605 \n",
      "round 1119, train_loss: 0.48218014505598417, val_loss: 0.461649301350099 \n",
      "round 1120, train_loss: 0.4821106389026999, val_loss: 0.4615697794007936 \n",
      "round 1121, train_loss: 0.48204120796232464, val_loss: 0.4614903492648084 \n",
      "round 1122, train_loss: 0.4819718521149027, val_loss: 0.4614110107970579 \n",
      "round 1123, train_loss: 0.48190257124073516, val_loss: 0.4613317638527618 \n",
      "round 1124, train_loss: 0.4818333652203786, val_loss: 0.4612526082874436 \n",
      "round 1125, train_loss: 0.481764233934645, val_loss: 0.46117354395693083 \n",
      "round 1126, train_loss: 0.4816951772646012, val_loss: 0.461094570717353 \n",
      "round 1127, train_loss: 0.4816261950915663, val_loss: 0.4610156884251415 \n",
      "round 1128, train_loss: 0.48155728729711456, val_loss: 0.4609368969370289 \n",
      "round 1129, train_loss: 0.481488453763071, val_loss: 0.4608581961100477 \n",
      "round 1130, train_loss: 0.48141969437151305, val_loss: 0.46077958580152995 \n",
      "round 1131, train_loss: 0.4813510090047692, val_loss: 0.4607010658691059 \n",
      "round 1132, train_loss: 0.4812823975454179, val_loss: 0.46062263617070404 \n",
      "round 1133, train_loss: 0.4812138598762885, val_loss: 0.4605442965645494 \n",
      "round 1134, train_loss: 0.48114539588045724, val_loss: 0.4604660469091626 \n",
      "round 1135, train_loss: 0.4810770054412508, val_loss: 0.460387887063361 \n",
      "round 1136, train_loss: 0.4810086884422427, val_loss: 0.4603098168862558 \n",
      "round 1137, train_loss: 0.48094044476725345, val_loss: 0.4602318362372512 \n",
      "round 1138, train_loss: 0.4808722743003504, val_loss: 0.4601539449760454 \n",
      "round 1139, train_loss: 0.480804176925846, val_loss: 0.46007614296262905 \n",
      "round 1140, train_loss: 0.4807361525282978, val_loss: 0.4599984300572829 \n",
      "round 1141, train_loss: 0.4806682009925089, val_loss: 0.4599208061205799 \n",
      "round 1142, train_loss: 0.4806003222035244, val_loss: 0.4598432710133815 \n",
      "round 1143, train_loss: 0.48053251604663433, val_loss: 0.4597658245968391 \n",
      "round 1144, train_loss: 0.48046478240736956, val_loss: 0.4596884667323922 \n",
      "round 1145, train_loss: 0.4803971211715038, val_loss: 0.45961119728176786 \n",
      "round 1146, train_loss: 0.480329532225052, val_loss: 0.45953401610698 \n",
      "round 1147, train_loss: 0.48026201545426883, val_loss: 0.4594569230703286 \n",
      "round 1148, train_loss: 0.48019457074564986, val_loss: 0.45937991803439854 \n",
      "round 1149, train_loss: 0.4801271979859291, val_loss: 0.4593030008620598 \n",
      "round 1150, train_loss: 0.48005989706207974, val_loss: 0.45922617141646566 \n",
      "round 1151, train_loss: 0.47999266786131256, val_loss: 0.459149429561053 \n",
      "round 1152, train_loss: 0.4799255102710761, val_loss: 0.45907277515954037 \n",
      "round 1153, train_loss: 0.47985842417905533, val_loss: 0.45899620807592795 \n",
      "round 1154, train_loss: 0.47979140947317167, val_loss: 0.45891972817449717 \n",
      "round 1155, train_loss: 0.47972446604158164, val_loss: 0.45884333531980903 \n",
      "round 1156, train_loss: 0.4796575937726767, val_loss: 0.4587670293767039 \n",
      "round 1157, train_loss: 0.4795907925550827, val_loss: 0.45869081021030095 \n",
      "round 1158, train_loss: 0.4795240622776594, val_loss: 0.45861467768599695 \n",
      "round 1159, train_loss: 0.4794574028294988, val_loss: 0.458538631669466 \n",
      "round 1160, train_loss: 0.4793908140999259, val_loss: 0.45846267202665825 \n",
      "round 1161, train_loss: 0.4793242959784976, val_loss: 0.45838679862379944 \n",
      "round 1162, train_loss: 0.47925784835500107, val_loss: 0.45831101132739127 \n",
      "round 1163, train_loss: 0.47919147111945537, val_loss: 0.4582353100042078 \n",
      "round 1164, train_loss: 0.4791251641621081, val_loss: 0.45815969452129857 \n",
      "round 1165, train_loss: 0.47905892737343764, val_loss: 0.45808416474598435 \n",
      "round 1166, train_loss: 0.47899276064414975, val_loss: 0.4580087205458587 \n",
      "round 1167, train_loss: 0.4789266638651791, val_loss: 0.457933361788786 \n",
      "round 1168, train_loss: 0.47886063692768793, val_loss: 0.45785808834290215 \n",
      "round 1169, train_loss: 0.4787946797230652, val_loss: 0.4577829000766122 \n",
      "round 1170, train_loss: 0.47872879214292613, val_loss: 0.4577077968585903 \n",
      "round 1171, train_loss: 0.4786629740791122, val_loss: 0.45763277855777973 \n",
      "round 1172, train_loss: 0.4785972254236894, val_loss: 0.45755784504339136 \n",
      "round 1173, train_loss: 0.4785315460689484, val_loss: 0.4574829961849027 \n",
      "round 1174, train_loss: 0.47846593590740444, val_loss: 0.4574082318520586 \n",
      "round 1175, train_loss: 0.47840039483179586, val_loss: 0.4573335519148687 \n",
      "round 1176, train_loss: 0.4783349227350833, val_loss: 0.4572589562436079 \n",
      "round 1177, train_loss: 0.4782695195104497, val_loss: 0.4571844447088159 \n",
      "round 1178, train_loss: 0.47820418505130124, val_loss: 0.4571100171812958 \n",
      "round 1179, train_loss: 0.4781389192512626, val_loss: 0.4570356735321131 \n",
      "round 1180, train_loss: 0.47807372200418125, val_loss: 0.4569614136325964 \n",
      "round 1181, train_loss: 0.47800859320412303, val_loss: 0.4568872373543357 \n",
      "round 1182, train_loss: 0.4779435327453739, val_loss: 0.45681314456918126 \n",
      "round 1183, train_loss: 0.47787854052243817, val_loss: 0.4567391351492446 \n",
      "round 1184, train_loss: 0.477813616430039, val_loss: 0.45666520896689605 \n",
      "round 1185, train_loss: 0.47774876036311603, val_loss: 0.4565913658947651 \n",
      "round 1186, train_loss: 0.47768397221682757, val_loss: 0.4565176058057397 \n",
      "round 1187, train_loss: 0.4776192518865471, val_loss: 0.4564439285729647 \n",
      "round 1188, train_loss: 0.4775545992678643, val_loss: 0.4563703340698425 \n",
      "round 1189, train_loss: 0.4774900142565847, val_loss: 0.45629682217003165 \n",
      "round 1190, train_loss: 0.47742549674872814, val_loss: 0.45622339274744544 \n",
      "round 1191, train_loss: 0.47736104664052925, val_loss: 0.4561500456762535 \n",
      "round 1192, train_loss: 0.4772966638284357, val_loss: 0.4560767808308786 \n",
      "round 1193, train_loss: 0.477232348209109, val_loss: 0.45600359808599733 \n",
      "round 1194, train_loss: 0.47716809967942264, val_loss: 0.45593049731653973 \n",
      "round 1195, train_loss: 0.4771039181364628, val_loss: 0.4558574783976873 \n",
      "round 1196, train_loss: 0.47703980347752595, val_loss: 0.45578454120487377 \n",
      "round 1197, train_loss: 0.47697575560012107, val_loss: 0.4557116856137837 \n",
      "round 1198, train_loss: 0.47691177440196675, val_loss: 0.45563891150035213 \n",
      "round 1199, train_loss: 0.4768478597809917, val_loss: 0.4555662187407636 \n",
      "round 1200, train_loss: 0.47678401163533307, val_loss: 0.4554936072114517 \n",
      "round 1201, train_loss: 0.476720229863338, val_loss: 0.4554210767890989 \n",
      "round 1202, train_loss: 0.4766565143635611, val_loss: 0.4553486273506349 \n",
      "round 1203, train_loss: 0.47659286503476533, val_loss: 0.4552762587732366 \n",
      "round 1204, train_loss: 0.47652928177591986, val_loss: 0.45520397093432763 \n",
      "round 1205, train_loss: 0.47646576448620137, val_loss: 0.45513176371157776 \n",
      "round 1206, train_loss: 0.476402313064992, val_loss: 0.4550596369829017 \n",
      "round 1207, train_loss: 0.47633892741188005, val_loss: 0.45498759062645877 \n",
      "round 1208, train_loss: 0.47627560742665853, val_loss: 0.45491562452065226 \n",
      "round 1209, train_loss: 0.4762123530093249, val_loss: 0.45484373854412935 \n",
      "round 1210, train_loss: 0.47614916406008073, val_loss: 0.4547719325757792 \n",
      "round 1211, train_loss: 0.47608604047933084, val_loss: 0.4547002064947338 \n",
      "round 1212, train_loss: 0.47602298216768346, val_loss: 0.4546285601803666 \n",
      "round 1213, train_loss: 0.47595998902594866, val_loss: 0.45455699351229145 \n",
      "round 1214, train_loss: 0.47589706095513906, val_loss: 0.454485506370363 \n",
      "round 1215, train_loss: 0.4758341978564681, val_loss: 0.4544140986346755 \n",
      "round 1216, train_loss: 0.47577139963134996, val_loss: 0.4543427701855623 \n",
      "round 1217, train_loss: 0.4757086661813999, val_loss: 0.45427152090359496 \n",
      "round 1218, train_loss: 0.47564599740843266, val_loss: 0.45420035066958353 \n",
      "round 1219, train_loss: 0.47558339321446175, val_loss: 0.4541292593645745 \n",
      "round 1220, train_loss: 0.4755208535017002, val_loss: 0.45405824686985213 \n",
      "round 1221, train_loss: 0.4754583781725594, val_loss: 0.4539873130669354 \n",
      "round 1222, train_loss: 0.4753959671296481, val_loss: 0.4539164578375799 \n",
      "round 1223, train_loss: 0.4753336202757727, val_loss: 0.45384568106377554 \n",
      "round 1224, train_loss: 0.4752713375139355, val_loss: 0.45377498262774674 \n",
      "round 1225, train_loss: 0.4752091187473366, val_loss: 0.45370436241195133 \n",
      "round 1226, train_loss: 0.4751469638793707, val_loss: 0.4536338202990808 \n",
      "round 1227, train_loss: 0.47508487281362854, val_loss: 0.45356335617205884 \n",
      "round 1228, train_loss: 0.47502284545389467, val_loss: 0.45349296991404053 \n",
      "round 1229, train_loss: 0.4749608817041491, val_loss: 0.4534226614084133 \n",
      "round 1230, train_loss: 0.4748989814685649, val_loss: 0.4533524305387944 \n",
      "round 1231, train_loss: 0.4748371446515085, val_loss: 0.45328227718903236 \n",
      "round 1232, train_loss: 0.4747753711575394, val_loss: 0.45321220124320416 \n",
      "round 1233, train_loss: 0.47471366089140987, val_loss: 0.4531422025856169 \n",
      "round 1234, train_loss: 0.47465201375806243, val_loss: 0.4530722811008047 \n",
      "round 1235, train_loss: 0.4745904296626324, val_loss: 0.4530024366735311 \n",
      "round 1236, train_loss: 0.4745289085104462, val_loss: 0.4529326691887859 \n",
      "round 1237, train_loss: 0.4744674502070192, val_loss: 0.4528629785317863 \n",
      "round 1238, train_loss: 0.4744060546580579, val_loss: 0.4527933645879753 \n",
      "round 1239, train_loss: 0.47434472176945736, val_loss: 0.4527238272430215 \n",
      "round 1240, train_loss: 0.47428345144730244, val_loss: 0.45265436638281853 \n",
      "round 1241, train_loss: 0.4742222435978659, val_loss: 0.45258498189348456 \n",
      "round 1242, train_loss: 0.4741610981276083, val_loss: 0.45251567366136203 \n",
      "round 1243, train_loss: 0.4741000149431786, val_loss: 0.4524464415730162 \n",
      "round 1244, train_loss: 0.47403899395141186, val_loss: 0.4523772855152352 \n",
      "round 1245, train_loss: 0.4739780350593301, val_loss: 0.45230820537502964 \n",
      "round 1246, train_loss: 0.47391713817414133, val_loss: 0.45223920103963156 \n",
      "round 1247, train_loss: 0.47385630320323946, val_loss: 0.45217027239649493 \n",
      "round 1248, train_loss: 0.4737955300542031, val_loss: 0.45210141933329256 \n",
      "round 1249, train_loss: 0.4737348186347961, val_loss: 0.45203264173791924 \n",
      "round 1250, train_loss: 0.4736741688529658, val_loss: 0.451963939498488 \n",
      "round 1251, train_loss: 0.47361358061684405, val_loss: 0.45189531250333126 \n",
      "round 1252, train_loss: 0.4735530538347456, val_loss: 0.4518267606409998 \n",
      "round 1253, train_loss: 0.4734925884151684, val_loss: 0.45175828380026206 \n",
      "round 1254, train_loss: 0.4734321842667921, val_loss: 0.45168988187010417 \n",
      "round 1255, train_loss: 0.473371841298479, val_loss: 0.45162155473972887 \n",
      "round 1256, train_loss: 0.4733115594192718, val_loss: 0.4515533022985548 \n",
      "round 1257, train_loss: 0.473251338538396, val_loss: 0.4514851244362169 \n",
      "round 1258, train_loss: 0.4731911785652559, val_loss: 0.4514170210425646 \n",
      "round 1259, train_loss: 0.47313107940943694, val_loss: 0.4513489920076628 \n",
      "round 1260, train_loss: 0.47307104098070335, val_loss: 0.45128103722178964 \n",
      "round 1261, train_loss: 0.47301106318899994, val_loss: 0.45121315657543737 \n",
      "round 1262, train_loss: 0.4729511459444484, val_loss: 0.45114534995931105 \n",
      "round 1263, train_loss: 0.47289128915735035, val_loss: 0.4510776172643285 \n",
      "round 1264, train_loss: 0.4728314927381846, val_loss: 0.45100995838161906 \n",
      "round 1265, train_loss: 0.47277175659760706, val_loss: 0.45094237320252417 \n",
      "round 1266, train_loss: 0.47271208064645187, val_loss: 0.45087486161859563 \n",
      "round 1267, train_loss: 0.47265246479572776, val_loss: 0.4508074235215963 \n",
      "round 1268, train_loss: 0.47259290895662087, val_loss: 0.4507400588034982 \n",
      "round 1269, train_loss: 0.47253341304049323, val_loss: 0.45067276735648365 \n",
      "round 1270, train_loss: 0.4724739769588811, val_loss: 0.4506055490729428 \n",
      "round 1271, train_loss: 0.4724146006234958, val_loss: 0.45053840384547506 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1272, train_loss: 0.4723552839462238, val_loss: 0.4504713315668872 \n",
      "round 1273, train_loss: 0.4722960268391243, val_loss: 0.45040433213019354 \n",
      "round 1274, train_loss: 0.4722368292144309, val_loss: 0.45033740542861506 \n",
      "round 1275, train_loss: 0.47217769098454926, val_loss: 0.45027055135557953 \n",
      "round 1276, train_loss: 0.47211861206205885, val_loss: 0.45020376980471966 \n",
      "round 1277, train_loss: 0.4720595923597105, val_loss: 0.45013706066987474 \n",
      "round 1278, train_loss: 0.47200063179042673, val_loss: 0.45007042384508744 \n",
      "round 1279, train_loss: 0.47194173026730224, val_loss: 0.4500038592246059 \n",
      "round 1280, train_loss: 0.47188288770360165, val_loss: 0.4499373667028815 \n",
      "round 1281, train_loss: 0.4718241040127606, val_loss: 0.4498709461745692 \n",
      "round 1282, train_loss: 0.4717653791083847, val_loss: 0.44980459753452634 \n",
      "round 1283, train_loss: 0.4717067129042492, val_loss: 0.44973832067781333 \n",
      "round 1284, train_loss: 0.47164810531429857, val_loss: 0.44967211549969177 \n",
      "round 1285, train_loss: 0.4715895562526456, val_loss: 0.4496059818956248 \n",
      "round 1286, train_loss: 0.4715310656335725, val_loss: 0.4495399197612764 \n",
      "round 1287, train_loss: 0.4714726333715284, val_loss: 0.44947392899251126 \n",
      "round 1288, train_loss: 0.4714142593811305, val_loss: 0.4494080094853933 \n",
      "round 1289, train_loss: 0.47135594357716304, val_loss: 0.4493421611361861 \n",
      "round 1290, train_loss: 0.47129768587457754, val_loss: 0.4492763838413523 \n",
      "round 1291, train_loss: 0.47123948618849043, val_loss: 0.44921067749755333 \n",
      "round 1292, train_loss: 0.4711813444341855, val_loss: 0.4491450420016474 \n",
      "round 1293, train_loss: 0.4711232605271111, val_loss: 0.44907947725069103 \n",
      "round 1294, train_loss: 0.4710652343828814, val_loss: 0.4490139831419376 \n",
      "round 1295, train_loss: 0.47100726591727443, val_loss: 0.4489485595728374 \n",
      "round 1296, train_loss: 0.47094935504623325, val_loss: 0.44888320644103535 \n",
      "round 1297, train_loss: 0.4708915016858641, val_loss: 0.44881792364437356 \n",
      "round 1298, train_loss: 0.47083370575243727, val_loss: 0.4487527110808884 \n",
      "round 1299, train_loss: 0.47077596716238584, val_loss: 0.4486875686488108 \n",
      "round 1300, train_loss: 0.47071828583230574, val_loss: 0.4486224962465661 \n",
      "round 1301, train_loss: 0.47066066167895476, val_loss: 0.44855749377277293 \n",
      "round 1302, train_loss: 0.4706030946192532, val_loss: 0.44849256112624375 \n",
      "round 1303, train_loss: 0.470545584570282, val_loss: 0.4484276982059831 \n",
      "round 1304, train_loss: 0.4704881314492839, val_loss: 0.44836290491118835 \n",
      "round 1305, train_loss: 0.4704307351736621, val_loss: 0.44829818114124803 \n",
      "round 1306, train_loss: 0.47037339566098, val_loss: 0.4482335267957427 \n",
      "round 1307, train_loss: 0.47031611282896074, val_loss: 0.4481689417744431 \n",
      "round 1308, train_loss: 0.47025888659548737, val_loss: 0.4481044259773109 \n",
      "round 1309, train_loss: 0.4702017168786021, val_loss: 0.44803997930449796 \n",
      "round 1310, train_loss: 0.47014460359650473, val_loss: 0.44797560165634487 \n",
      "round 1311, train_loss: 0.4700875466675554, val_loss: 0.44791129293338183 \n",
      "round 1312, train_loss: 0.4700305460102704, val_loss: 0.44784705303632716 \n",
      "round 1313, train_loss: 0.4699736015433244, val_loss: 0.44778288186608817 \n",
      "round 1314, train_loss: 0.46991671318554923, val_loss: 0.4477187793237589 \n",
      "round 1315, train_loss: 0.4698598808559331, val_loss: 0.4476547453106214 \n",
      "round 1316, train_loss: 0.4698031044736213, val_loss: 0.44759077972814415 \n",
      "round 1317, train_loss: 0.4697463839579146, val_loss: 0.44752688247798145 \n",
      "round 1318, train_loss: 0.46968971922826974, val_loss: 0.44746305346197496 \n",
      "round 1319, train_loss: 0.46963311020429854, val_loss: 0.4473992925821504 \n",
      "round 1320, train_loss: 0.4695765568057678, val_loss: 0.4473355997407192 \n",
      "round 1321, train_loss: 0.4695200589525989, val_loss: 0.4472719748400769 \n",
      "round 1322, train_loss: 0.4694636165648675, val_loss: 0.4472084177828037 \n",
      "round 1323, train_loss: 0.4694072295628025, val_loss: 0.4471449284716632 \n",
      "round 1324, train_loss: 0.46935089786678685, val_loss: 0.44708150680960224 \n",
      "round 1325, train_loss: 0.46929462139735595, val_loss: 0.4470181526997505 \n",
      "round 1326, train_loss: 0.4692384000751983, val_loss: 0.4469548660454202 \n",
      "round 1327, train_loss: 0.46918223382115465, val_loss: 0.44689164675010506 \n",
      "round 1328, train_loss: 0.4691261225562175, val_loss: 0.446828494717481 \n",
      "round 1329, train_loss: 0.46907006620153036, val_loss: 0.44676540985140417 \n",
      "round 1330, train_loss: 0.46901406467838963, val_loss: 0.4467023920559126 \n",
      "round 1331, train_loss: 0.46895811790824055, val_loss: 0.4466394412352234 \n",
      "round 1332, train_loss: 0.46890222581268026, val_loss: 0.4465765572937335 \n",
      "round 1333, train_loss: 0.4688463883134548, val_loss: 0.44651374013602035 \n",
      "round 1334, train_loss: 0.46879060533246114, val_loss: 0.4464509896668385 \n",
      "round 1335, train_loss: 0.4687348767917447, val_loss: 0.446388305791123 \n",
      "round 1336, train_loss: 0.46867920261350005, val_loss: 0.44632568841398573 \n",
      "round 1337, train_loss: 0.46862358272007115, val_loss: 0.4462631374407169 \n",
      "round 1338, train_loss: 0.46856801703394907, val_loss: 0.4462006527767829 \n",
      "round 1339, train_loss: 0.46851250547777423, val_loss: 0.4461382343278286 \n",
      "round 1340, train_loss: 0.4684570479743333, val_loss: 0.4460758819996736 \n",
      "round 1341, train_loss: 0.46840164444656046, val_loss: 0.44601359569831484 \n",
      "round 1342, train_loss: 0.4683462948175381, val_loss: 0.4459513753299242 \n",
      "round 1343, train_loss: 0.4682909990104927, val_loss: 0.4458892208008486 \n",
      "round 1344, train_loss: 0.4682357569487988, val_loss: 0.4458271320176105 \n",
      "round 1345, train_loss: 0.4681805685559767, val_loss: 0.44576510888690524 \n",
      "round 1346, train_loss: 0.4681254337556908, val_loss: 0.44570315131560384 \n",
      "round 1347, train_loss: 0.46807035247175205, val_loss: 0.4456412592107497 \n",
      "round 1348, train_loss: 0.4680153246281154, val_loss: 0.44557943247955967 \n",
      "round 1349, train_loss: 0.46796035014888043, val_loss: 0.44551767102942313 \n",
      "round 1350, train_loss: 0.46790542895829074, val_loss: 0.44545597476790183 \n",
      "round 1351, train_loss: 0.4678505609807338, val_loss: 0.4453943436027299 \n",
      "round 1352, train_loss: 0.4677957461407401, val_loss: 0.4453327774418122 \n",
      "round 1353, train_loss: 0.46774098436298356, val_loss: 0.44527127619322526 \n",
      "round 1354, train_loss: 0.4676862755722808, val_loss: 0.44520983976521594 \n",
      "round 1355, train_loss: 0.4676316196935906, val_loss: 0.4451484680662014 \n",
      "round 1356, train_loss: 0.4675770166520137, val_loss: 0.44508716100476914 \n",
      "round 1357, train_loss: 0.4675224663727926, val_loss: 0.44502591848967565 \n",
      "round 1358, train_loss: 0.467467968781311, val_loss: 0.4449647404298466 \n",
      "round 1359, train_loss: 0.46741352380309426, val_loss: 0.4449036267343765 \n",
      "round 1360, train_loss: 0.467359131363808, val_loss: 0.44484257731252813 \n",
      "round 1361, train_loss: 0.4673047913892574, val_loss: 0.4447815920737321 \n",
      "round 1362, train_loss: 0.4672505038053891, val_loss: 0.44472067092758666 \n",
      "round 1363, train_loss: 0.467196268538288, val_loss: 0.44465981378385727 \n",
      "round 1364, train_loss: 0.4671420855141795, val_loss: 0.44459902055247574 \n",
      "round 1365, train_loss: 0.4670879546594269, val_loss: 0.44453829114354054 \n",
      "round 1366, train_loss: 0.4670338759005333, val_loss: 0.444477625467316 \n",
      "round 1367, train_loss: 0.4669798491641392, val_loss: 0.44441702343423234 \n",
      "round 1368, train_loss: 0.46692587437702376, val_loss: 0.4443564849548841 \n",
      "round 1369, train_loss: 0.4668719514661034, val_loss: 0.44429600994003177 \n",
      "round 1370, train_loss: 0.46681808035843236, val_loss: 0.4442355983005995 \n",
      "round 1371, train_loss: 0.46676426098120155, val_loss: 0.44417524994767554 \n",
      "round 1372, train_loss: 0.46671049326173836, val_loss: 0.4441149647925122 \n",
      "round 1373, train_loss: 0.4666567771275072, val_loss: 0.4440547427465245 \n",
      "round 1374, train_loss: 0.46660311250610786, val_loss: 0.4439945837212908 \n",
      "round 1375, train_loss: 0.46654949932527645, val_loss: 0.443934487628552 \n",
      "round 1376, train_loss: 0.46649593751288443, val_loss: 0.4438744543802103 \n",
      "round 1377, train_loss: 0.4664424269969378, val_loss: 0.4438144838883315 \n",
      "round 1378, train_loss: 0.466388967705578, val_loss: 0.4437545760651405 \n",
      "round 1379, train_loss: 0.4663355595670808, val_loss: 0.4436947308230252 \n",
      "round 1380, train_loss: 0.46628220250985547, val_loss: 0.44363494807453274 \n",
      "round 1381, train_loss: 0.4662288964624465, val_loss: 0.44357522773237157 \n",
      "round 1382, train_loss: 0.46617564135353007, val_loss: 0.443515569709409 \n",
      "round 1383, train_loss: 0.466122437111917, val_loss: 0.4434559739186729 \n",
      "round 1384, train_loss: 0.4660692836665506, val_loss: 0.44339644027334985 \n",
      "round 1385, train_loss: 0.46601618094650615, val_loss: 0.44333696868678496 \n",
      "round 1386, train_loss: 0.46596312888099223, val_loss: 0.4432775590724823 \n",
      "round 1387, train_loss: 0.46591012739934856, val_loss: 0.44321821134410355 \n",
      "round 1388, train_loss: 0.4658571764310468, val_loss: 0.4431589254154685 \n",
      "round 1389, train_loss: 0.46580427590568985, val_loss: 0.44309970120055386 \n",
      "round 1390, train_loss: 0.4657514257530117, val_loss: 0.4430405386134935 \n",
      "round 1391, train_loss: 0.46569862590287725, val_loss: 0.4429814375685785 \n",
      "round 1392, train_loss: 0.46564587628528137, val_loss: 0.4429223979802549 \n",
      "round 1393, train_loss: 0.46559317683034906, val_loss: 0.4428634197631257 \n",
      "round 1394, train_loss: 0.46554052746833574, val_loss: 0.4428045028319494 \n",
      "round 1395, train_loss: 0.46548792812962575, val_loss: 0.44274564710163894 \n",
      "round 1396, train_loss: 0.46543537874473256, val_loss: 0.44268685248726264 \n",
      "round 1397, train_loss: 0.4653828792442986, val_loss: 0.44262811890404336 \n",
      "round 1398, train_loss: 0.46533042955909554, val_loss: 0.4425694462673578 \n",
      "round 1399, train_loss: 0.4652780296200222, val_loss: 0.44251083449273654 \n",
      "round 1400, train_loss: 0.4652256793581065, val_loss: 0.4424522834958635 \n",
      "round 1401, train_loss: 0.4651733787045031, val_loss: 0.4423937931925761 \n",
      "round 1402, train_loss: 0.46512112759049445, val_loss: 0.4423353634988634 \n",
      "round 1403, train_loss: 0.46506892594749044, val_loss: 0.4422769943308686 \n",
      "round 1404, train_loss: 0.46501677370702715, val_loss: 0.4422186856048847 \n",
      "round 1405, train_loss: 0.4649646708007674, val_loss: 0.44216043723735804 \n",
      "round 1406, train_loss: 0.4649126171605005, val_loss: 0.4421022491448857 \n",
      "round 1407, train_loss: 0.46486061271814105, val_loss: 0.4420441212442159 \n",
      "round 1408, train_loss: 0.4648086574057297, val_loss: 0.4419860534522472 \n",
      "round 1409, train_loss: 0.46475675115543263, val_loss: 0.4419280456860284 \n",
      "round 1410, train_loss: 0.4647048938995403, val_loss: 0.4418700978627588 \n",
      "round 1411, train_loss: 0.46465308557046847, val_loss: 0.441812209899787 \n",
      "round 1412, train_loss: 0.46460132610075744, val_loss: 0.4417543817146107 \n",
      "round 1413, train_loss: 0.46454961542307105, val_loss: 0.44169661322487674 \n",
      "round 1414, train_loss: 0.46449795347019796, val_loss: 0.44163890434838 \n",
      "round 1415, train_loss: 0.4644463401750494, val_loss: 0.4415812550030647 \n",
      "round 1416, train_loss: 0.46439477547066077, val_loss: 0.44152366510702185 \n",
      "round 1417, train_loss: 0.4643432592901897, val_loss: 0.4414661345784909 \n",
      "round 1418, train_loss: 0.46429179156691713, val_loss: 0.4414086633358577 \n",
      "round 1419, train_loss: 0.4642403722342464, val_loss: 0.44135125129765607 \n",
      "round 1420, train_loss: 0.46418900122570234, val_loss: 0.44129389838256533 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1421, train_loss: 0.46413767847493265, val_loss: 0.4412366045094116 \n",
      "round 1422, train_loss: 0.4640864039157063, val_loss: 0.4411793695971669 \n",
      "round 1423, train_loss: 0.46403517748191275, val_loss: 0.4411221935649487 \n",
      "round 1424, train_loss: 0.46398399910756344, val_loss: 0.4410650763320198 \n",
      "round 1425, train_loss: 0.46393286872679074, val_loss: 0.4410080178177879 \n",
      "round 1426, train_loss: 0.46388178627384624, val_loss: 0.4409510179418051 \n",
      "round 1427, train_loss: 0.4638307516831031, val_loss: 0.4408940766237684 \n",
      "round 1428, train_loss: 0.4637797648890535, val_loss: 0.4408371937835177 \n",
      "round 1429, train_loss: 0.4637288258263096, val_loss: 0.4407803693410373 \n",
      "round 1430, train_loss: 0.46367793442960326, val_loss: 0.44072360321645504 \n",
      "round 1431, train_loss: 0.46362709063378466, val_loss: 0.4406668953300409 \n",
      "round 1432, train_loss: 0.46357629437382336, val_loss: 0.440610245602208 \n",
      "round 1433, train_loss: 0.46352554558480746, val_loss: 0.4405536539535116 \n",
      "round 1434, train_loss: 0.46347484420194274, val_loss: 0.44049712030464916 \n",
      "round 1435, train_loss: 0.463424190160554, val_loss: 0.4404406445764598 \n",
      "round 1436, train_loss: 0.46337358339608276, val_loss: 0.4403842266899239 \n",
      "round 1437, train_loss: 0.46332302384408885, val_loss: 0.4403278665661629 \n",
      "round 1438, train_loss: 0.46327251144024834, val_loss: 0.4402715641264389 \n",
      "round 1439, train_loss: 0.4632220461203552, val_loss: 0.44021531929215485 \n",
      "round 1440, train_loss: 0.46317162782031923, val_loss: 0.4401591319848532 \n",
      "round 1441, train_loss: 0.4631212564761671, val_loss: 0.44010300212621656 \n",
      "round 1442, train_loss: 0.4630709320240418, val_loss: 0.4400469296380669 \n",
      "round 1443, train_loss: 0.4630206544002017, val_loss: 0.4399909144423653 \n",
      "round 1444, train_loss: 0.46297042354102047, val_loss: 0.439934956461212 \n",
      "round 1445, train_loss: 0.46292023938298804, val_loss: 0.4398790556168455 \n",
      "round 1446, train_loss: 0.4628701018627088, val_loss: 0.4398232118316424 \n",
      "round 1447, train_loss: 0.46282001091690206, val_loss: 0.4397674250281177 \n",
      "round 1448, train_loss: 0.46276996648240143, val_loss: 0.43971169512892355 \n",
      "round 1449, train_loss: 0.46271996849615527, val_loss: 0.4396560220568497 \n",
      "round 1450, train_loss: 0.4626700168952253, val_loss: 0.43960040573482256 \n",
      "round 1451, train_loss: 0.4626201116167876, val_loss: 0.4395448460859057 \n",
      "round 1452, train_loss: 0.46257025259813167, val_loss: 0.43948934303329895 \n",
      "round 1453, train_loss: 0.4625204397766598, val_loss: 0.4394338965003378 \n",
      "round 1454, train_loss: 0.4624706730898876, val_loss: 0.4393785064104939 \n",
      "round 1455, train_loss: 0.46242095247544335, val_loss: 0.4393231726873746 \n",
      "round 1456, train_loss: 0.462371277871068, val_loss: 0.43926789525472193 \n",
      "round 1457, train_loss: 0.4623216492146141, val_loss: 0.4392126740364131 \n",
      "round 1458, train_loss: 0.4622720664440465, val_loss: 0.4391575089564596 \n",
      "round 1459, train_loss: 0.4622225294974423, val_loss: 0.43910239993900796 \n",
      "round 1460, train_loss: 0.46217303831298884, val_loss: 0.4390473469083377 \n",
      "round 1461, train_loss: 0.4621235928289858, val_loss: 0.43899234978886253 \n",
      "round 1462, train_loss: 0.46207419298384306, val_loss: 0.43893740850512963 \n",
      "round 1463, train_loss: 0.46202483871608147, val_loss: 0.43888252298181907 \n",
      "round 1464, train_loss: 0.4619755299643326, val_loss: 0.43882769314374376 \n",
      "round 1465, train_loss: 0.46192626666733716, val_loss: 0.4387729189158493 \n",
      "round 1466, train_loss: 0.46187704876394714, val_loss: 0.4387182002232132 \n",
      "round 1467, train_loss: 0.46182787619312354, val_loss: 0.43866353699104504 \n",
      "round 1468, train_loss: 0.46177874889393644, val_loss: 0.438608929144686 \n",
      "round 1469, train_loss: 0.4617296668055659, val_loss: 0.4385543766096085 \n",
      "round 1470, train_loss: 0.4616806298673004, val_loss: 0.43849987931141615 \n",
      "round 1471, train_loss: 0.4616316380185373, val_loss: 0.4384454371758438 \n",
      "round 1472, train_loss: 0.461582691198782, val_loss: 0.4383910501287554 \n",
      "round 1473, train_loss: 0.4615337893476491, val_loss: 0.4383367180961462 \n",
      "round 1474, train_loss: 0.46148493240485994, val_loss: 0.4382824410041415 \n",
      "round 1475, train_loss: 0.4614361203102445, val_loss: 0.43822821877899515 \n",
      "round 1476, train_loss: 0.46138735300373973, val_loss: 0.43817405134709114 \n",
      "round 1477, train_loss: 0.4613386304253903, val_loss: 0.4381199386349423 \n",
      "round 1478, train_loss: 0.4612899525153466, val_loss: 0.4380658805691904 \n",
      "round 1479, train_loss: 0.46124131921386796, val_loss: 0.43801187707660516 \n",
      "round 1480, train_loss: 0.4611927304613184, val_loss: 0.4379579280840846 \n",
      "round 1481, train_loss: 0.4611441861981686, val_loss: 0.4379040335186552 \n",
      "round 1482, train_loss: 0.4610956863649955, val_loss: 0.4378501933074709 \n",
      "round 1483, train_loss: 0.4610472309024819, val_loss: 0.43779640737781184 \n",
      "round 1484, train_loss: 0.46099881975141627, val_loss: 0.43774267565708724 \n",
      "round 1485, train_loss: 0.46095045285269154, val_loss: 0.43768899807283135 \n",
      "round 1486, train_loss: 0.46090213014730724, val_loss: 0.4376353745527056 \n",
      "round 1487, train_loss: 0.460853851576366, val_loss: 0.43758180502449795 \n",
      "round 1488, train_loss: 0.46080561708107615, val_loss: 0.4375282894161215 \n",
      "round 1489, train_loss: 0.46075742660275065, val_loss: 0.4374748276556161 \n",
      "round 1490, train_loss: 0.4607092800828056, val_loss: 0.4374214196711461 \n",
      "round 1491, train_loss: 0.46066117746276153, val_loss: 0.43736806539100115 \n",
      "round 1492, train_loss: 0.4606131186842427, val_loss: 0.43731476474359593 \n",
      "round 1493, train_loss: 0.46056510368897663, val_loss: 0.4372615176574697 \n",
      "round 1494, train_loss: 0.46051713241879466, val_loss: 0.43720832406128607 \n",
      "round 1495, train_loss: 0.46046920481563003, val_loss: 0.43715518388383273 \n",
      "round 1496, train_loss: 0.46042132082151993, val_loss: 0.43710209705402064 \n",
      "round 1497, train_loss: 0.46037348037860276, val_loss: 0.4370490635008847 \n",
      "round 1498, train_loss: 0.46032568342912045, val_loss: 0.43699608315358307 \n",
      "round 1499, train_loss: 0.46027792991541633, val_loss: 0.4369431559413965 \n",
      "round 1500, train_loss: 0.46023021977993545, val_loss: 0.43689028179372896 \n",
      "round 1501, train_loss: 0.4601825529652251, val_loss: 0.43683746064010637 \n",
      "round 1502, train_loss: 0.46013492941393325, val_loss: 0.43678469241017714 \n",
      "round 1503, train_loss: 0.46008734906880966, val_loss: 0.4367319770337112 \n",
      "round 1504, train_loss: 0.4600398118727047, val_loss: 0.4366793144406003 \n",
      "round 1505, train_loss: 0.459992317768569, val_loss: 0.43662670456085795 \n",
      "round 1506, train_loss: 0.45994486669945495, val_loss: 0.43657414732461775 \n",
      "round 1507, train_loss: 0.45989745860851383, val_loss: 0.43652164266213533 \n",
      "round 1508, train_loss: 0.4598500934389975, val_loss: 0.43646919050378585 \n",
      "round 1509, train_loss: 0.459802771134258, val_loss: 0.43641679078006557 \n",
      "round 1510, train_loss: 0.4597554916377464, val_loss: 0.43636444342159053 \n",
      "round 1511, train_loss: 0.4597082548930134, val_loss: 0.4363121483590962 \n",
      "round 1512, train_loss: 0.459661060843709, val_loss: 0.43625990552343785 \n",
      "round 1513, train_loss: 0.4596139094335817, val_loss: 0.43620771484559023 \n",
      "round 1514, train_loss: 0.4595668006064793, val_loss: 0.43615557625664697 \n",
      "round 1515, train_loss: 0.45951973430634757, val_loss: 0.4361034896878201 \n",
      "round 1516, train_loss: 0.45947271047723043, val_loss: 0.43605145507044096 \n",
      "round 1517, train_loss: 0.4594257290632709, val_loss: 0.43599947233595826 \n",
      "round 1518, train_loss: 0.4593787900087088, val_loss: 0.435947541415939 \n",
      "round 1519, train_loss: 0.45933189325788193, val_loss: 0.43589566224206827 \n",
      "round 1520, train_loss: 0.45928503875522536, val_loss: 0.43584383474614813 \n",
      "round 1521, train_loss: 0.45923822644527174, val_loss: 0.43579205886009803 \n",
      "round 1522, train_loss: 0.45919145627265023, val_loss: 0.43574033451595456 \n",
      "round 1523, train_loss: 0.4591447281820872, val_loss: 0.43568866164587067 \n",
      "round 1524, train_loss: 0.4590980421184051, val_loss: 0.4356370401821165 \n",
      "round 1525, train_loss: 0.45905139802652317, val_loss: 0.43558547005707754 \n",
      "round 1526, train_loss: 0.45900479585145687, val_loss: 0.43553395120325583 \n",
      "round 1527, train_loss: 0.45895823553831644, val_loss: 0.43548248355326863 \n",
      "round 1528, train_loss: 0.45891171703230965, val_loss: 0.4354310670398492 \n",
      "round 1529, train_loss: 0.45886524027873815, val_loss: 0.43537970159584577 \n",
      "round 1530, train_loss: 0.4588188052229998, val_loss: 0.43532838715422173 \n",
      "round 1531, train_loss: 0.45877241181058737, val_loss: 0.43527712364805443 \n",
      "round 1532, train_loss: 0.45872605998708804, val_loss: 0.43522591101053704 \n",
      "round 1533, train_loss: 0.4586797496981845, val_loss: 0.4351747491749757 \n",
      "round 1534, train_loss: 0.45863348088965294, val_loss: 0.43512363807479154 \n",
      "round 1535, train_loss: 0.4585872535073645, val_loss: 0.4350725776435183 \n",
      "round 1536, train_loss: 0.4585410674972839, val_loss: 0.4350215678148046 \n",
      "round 1537, train_loss: 0.45849492280547033, val_loss: 0.4349706085224112 \n",
      "round 1538, train_loss: 0.45844881937807574, val_loss: 0.43491969970021227 \n",
      "round 1539, train_loss: 0.4584027571613461, val_loss: 0.43486884128219494 \n",
      "round 1540, train_loss: 0.4583567361016207, val_loss: 0.4348180332024588 \n",
      "round 1541, train_loss: 0.45831075614533107, val_loss: 0.43476727539521526 \n",
      "round 1542, train_loss: 0.4582648172390024, val_loss: 0.4347165677947884 \n",
      "round 1543, train_loss: 0.45821891932925224, val_loss: 0.43466591033561397 \n",
      "round 1544, train_loss: 0.4581730623627903, val_loss: 0.4346153029522392 \n",
      "round 1545, train_loss: 0.4581272462864186, val_loss: 0.4345647455793224 \n",
      "round 1546, train_loss: 0.45808147104703123, val_loss: 0.4345142381516335 \n",
      "round 1547, train_loss: 0.4580357365916144, val_loss: 0.4344637806040532 \n",
      "round 1548, train_loss: 0.45799004286724493, val_loss: 0.4344133728715724 \n",
      "round 1549, train_loss: 0.4579443898210924, val_loss: 0.43436301488929246 \n",
      "round 1550, train_loss: 0.4578987774004163, val_loss: 0.4343127065924255 \n",
      "round 1551, train_loss: 0.45785320555256803, val_loss: 0.4342624479162931 \n",
      "round 1552, train_loss: 0.45780767422498914, val_loss: 0.4342122387963265 \n",
      "round 1553, train_loss: 0.4577621833652129, val_loss: 0.4341620791680667 \n",
      "round 1554, train_loss: 0.45771673292086124, val_loss: 0.4341119689671635 \n",
      "round 1555, train_loss: 0.45767132283964823, val_loss: 0.43406190812937606 \n",
      "round 1556, train_loss: 0.45762595306937603, val_loss: 0.43401189659057215 \n",
      "round 1557, train_loss: 0.4575806235579381, val_loss: 0.43396193428672786 \n",
      "round 1558, train_loss: 0.45753533425331705, val_loss: 0.43391202115392824 \n",
      "round 1559, train_loss: 0.4574900851035849, val_loss: 0.43386215712836546 \n",
      "round 1560, train_loss: 0.4574448760569027, val_loss: 0.4338123421463407 \n",
      "round 1561, train_loss: 0.4573997070615209, val_loss: 0.43376257614426117 \n",
      "round 1562, train_loss: 0.4573545780657787, val_loss: 0.4337128590586434 \n",
      "round 1563, train_loss: 0.45730948901810375, val_loss: 0.43366319082610977 \n",
      "round 1564, train_loss: 0.4572644398670123, val_loss: 0.4336135713833895 \n",
      "round 1565, train_loss: 0.4572194305611091, val_loss: 0.4335640006673194 \n",
      "round 1566, train_loss: 0.4571744610490866, val_loss: 0.433514478614842 \n",
      "round 1567, train_loss: 0.45712953127972555, val_loss: 0.4334650051630069 \n",
      "round 1568, train_loss: 0.45708464120189385, val_loss: 0.4334155802489683 \n",
      "round 1569, train_loss: 0.4570397907645476, val_loss: 0.433366203809988 \n",
      "round 1570, train_loss: 0.45699497991672966, val_loss: 0.43331687578343203 \n",
      "round 1571, train_loss: 0.45695020860757013, val_loss: 0.43326759610677273 \n",
      "round 1572, train_loss: 0.4569054767862865, val_loss: 0.4332183647175864 \n",
      "round 1573, train_loss: 0.4568607844021826, val_loss: 0.43316918155355527 \n",
      "round 1574, train_loss: 0.45681613140464855, val_loss: 0.4331200465524664 \n",
      "round 1575, train_loss: 0.45677151774316205, val_loss: 0.43307095965221043 \n",
      "round 1576, train_loss: 0.4567269433672855, val_loss: 0.43302192079078305 \n",
      "round 1577, train_loss: 0.45668240822666795, val_loss: 0.43297292990628333 \n",
      "round 1578, train_loss: 0.45663791227104467, val_loss: 0.4329239869369149 \n",
      "round 1579, train_loss: 0.4565934554502362, val_loss: 0.43287509182098444 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1580, train_loss: 0.4565490377141487, val_loss: 0.43282624449690194 \n",
      "round 1581, train_loss: 0.45650465901277326, val_loss: 0.4327774449031815 \n",
      "round 1582, train_loss: 0.4564603192961863, val_loss: 0.4327286929784388 \n",
      "round 1583, train_loss: 0.4564160185145492, val_loss: 0.4326799886613931 \n",
      "round 1584, train_loss: 0.4563717566181082, val_loss: 0.43263133189086644 \n",
      "round 1585, train_loss: 0.4563275335571937, val_loss: 0.4325827226057823 \n",
      "round 1586, train_loss: 0.4562833492822208, val_loss: 0.43253416074516693 \n",
      "round 1587, train_loss: 0.4562392037436889, val_loss: 0.43248564624814806 \n",
      "round 1588, train_loss: 0.4561950968921805, val_loss: 0.4324371790539552 \n",
      "round 1589, train_loss: 0.4561510286783632, val_loss: 0.43238875910192 \n",
      "round 1590, train_loss: 0.45610699905298757, val_loss: 0.4323403863314741 \n",
      "round 1591, train_loss: 0.45606300796688776, val_loss: 0.43229206068215126 \n",
      "round 1592, train_loss: 0.4560190553709809, val_loss: 0.4322437820935853 \n",
      "round 1593, train_loss: 0.4559751412162677, val_loss: 0.43219555050551106 \n",
      "round 1594, train_loss: 0.45593126545383167, val_loss: 0.4321473658577637 \n",
      "round 1595, train_loss: 0.45588742803483884, val_loss: 0.43209922809027873 \n",
      "round 1596, train_loss: 0.4558436289105384, val_loss: 0.43205113714309124 \n",
      "round 1597, train_loss: 0.45579986803226125, val_loss: 0.43200309295633654 \n",
      "round 1598, train_loss: 0.45575614535142084, val_loss: 0.43195509547024885 \n",
      "round 1599, train_loss: 0.45571246081951267, val_loss: 0.43190714462516294 \n",
      "round 1600, train_loss: 0.45566881438811413, val_loss: 0.43185924036151174 \n",
      "round 1601, train_loss: 0.45562520600888445, val_loss: 0.4318113826198269 \n",
      "round 1602, train_loss: 0.4555816356335638, val_loss: 0.4317635713407401 \n",
      "round 1603, train_loss: 0.4555381032139747, val_loss: 0.43171580646498015 \n",
      "round 1604, train_loss: 0.45549460870201974, val_loss: 0.431668087933375 \n",
      "round 1605, train_loss: 0.4554511520496835, val_loss: 0.4316204156868504 \n",
      "round 1606, train_loss: 0.4554077332090309, val_loss: 0.4315727896664304 \n",
      "round 1607, train_loss: 0.4553643521322072, val_loss: 0.4315252098132368 \n",
      "round 1608, train_loss: 0.45532100877143933, val_loss: 0.43147767606848747 \n",
      "round 1609, train_loss: 0.4552777030790333, val_loss: 0.43143018837350006 \n",
      "round 1610, train_loss: 0.4552344350073758, val_loss: 0.4313827466696876 \n",
      "round 1611, train_loss: 0.4551912045089331, val_loss: 0.4313353508985605 \n",
      "round 1612, train_loss: 0.4551480115362522, val_loss: 0.43128800100172576 \n",
      "round 1613, train_loss: 0.455104856041959, val_loss: 0.43124069692088696 \n",
      "round 1614, train_loss: 0.45506173797875876, val_loss: 0.4311934385978444 \n",
      "round 1615, train_loss: 0.4550186572994369, val_loss: 0.4311462259744941 \n",
      "round 1616, train_loss: 0.4549756139568572, val_loss: 0.4310990589928276 \n",
      "round 1617, train_loss: 0.45493260790396234, val_loss: 0.4310519375949327 \n",
      "round 1618, train_loss: 0.454889639093775, val_loss: 0.4310048617229932 \n",
      "round 1619, train_loss: 0.45484670747939443, val_loss: 0.4309578313192872 \n",
      "round 1620, train_loss: 0.45480381301400047, val_loss: 0.43091084632618853 \n",
      "round 1621, train_loss: 0.45476095565085, val_loss: 0.4308639066861657 \n",
      "round 1622, train_loss: 0.45471813534327826, val_loss: 0.430817012341782 \n",
      "round 1623, train_loss: 0.45467535204469883, val_loss: 0.4307701632356955 \n",
      "round 1624, train_loss: 0.45463260570860287, val_loss: 0.4307233593106586 \n",
      "round 1625, train_loss: 0.4545898962885592, val_loss: 0.43067660050951706 \n",
      "round 1626, train_loss: 0.4545472237382138, val_loss: 0.430629886775212 \n",
      "round 1627, train_loss: 0.4545045880112908, val_loss: 0.43058321805077715 \n",
      "round 1628, train_loss: 0.4544619890615903, val_loss: 0.43053659427934055 \n",
      "round 1629, train_loss: 0.454419426842991, val_loss: 0.4304900154041228 \n",
      "round 1630, train_loss: 0.454376901309447, val_loss: 0.43044348136843824 \n",
      "round 1631, train_loss: 0.45433441241498956, val_loss: 0.43039699211569477 \n",
      "round 1632, train_loss: 0.45429196011372663, val_loss: 0.430350547589392 \n",
      "round 1633, train_loss: 0.45424954435984255, val_loss: 0.4303041477331225 \n",
      "round 1634, train_loss: 0.45420716510759734, val_loss: 0.430257792490572 \n",
      "round 1635, train_loss: 0.45416482231132776, val_loss: 0.43021148180551727 \n",
      "round 1636, train_loss: 0.45412251592544584, val_loss: 0.43016521562182813 \n",
      "round 1637, train_loss: 0.4540802459044393, val_loss: 0.43011899388346564 \n",
      "round 1638, train_loss: 0.4540380122028725, val_loss: 0.43007281653448337 \n",
      "round 1639, train_loss: 0.45399581477538353, val_loss: 0.43002668351902495 \n",
      "round 1640, train_loss: 0.45395365357668716, val_loss: 0.4299805947813264 \n",
      "round 1641, train_loss: 0.4539115285615724, val_loss: 0.42993455026571514 \n",
      "round 1642, train_loss: 0.4538694396849033, val_loss: 0.42988854991660824 \n",
      "round 1643, train_loss: 0.45382738690161945, val_loss: 0.4298425936785148 \n",
      "round 1644, train_loss: 0.4537853701667337, val_loss: 0.4297966814960337 \n",
      "round 1645, train_loss: 0.4537433894353349, val_loss: 0.42975081331385473 \n",
      "round 1646, train_loss: 0.45370144466258444, val_loss: 0.42970498907675736 \n",
      "round 1647, train_loss: 0.45365953580371954, val_loss: 0.429659208729611 \n",
      "round 1648, train_loss: 0.4536176628140503, val_loss: 0.4296134722173755 \n",
      "round 1649, train_loss: 0.4535758256489614, val_loss: 0.4295677794851003 \n",
      "round 1650, train_loss: 0.45353402426391065, val_loss: 0.42952213047792337 \n",
      "round 1651, train_loss: 0.45349225861442943, val_loss: 0.4294765251410728 \n",
      "round 1652, train_loss: 0.45345052865612284, val_loss: 0.4294309634198659 \n",
      "round 1653, train_loss: 0.45340883434466905, val_loss: 0.42938544525970834 \n",
      "round 1654, train_loss: 0.45336717563581913, val_loss: 0.42933997060609475 \n",
      "round 1655, train_loss: 0.45332555248539763, val_loss: 0.4292945394046085 \n",
      "round 1656, train_loss: 0.4532839648493007, val_loss: 0.4292491516009208 \n",
      "round 1657, train_loss: 0.4532424126834987, val_loss: 0.42920380714079154 \n",
      "round 1658, train_loss: 0.45320089594403296, val_loss: 0.42915850597006866 \n",
      "round 1659, train_loss: 0.453159414587018, val_loss: 0.4291132480346877 \n",
      "round 1660, train_loss: 0.45311796856864045, val_loss: 0.42906803328067195 \n",
      "round 1661, train_loss: 0.4530765578451588, val_loss: 0.429022861654132 \n",
      "round 1662, train_loss: 0.4530351823729033, val_loss: 0.428977733101266 \n",
      "round 1663, train_loss: 0.4529938421082762, val_loss: 0.42893264756835936 \n",
      "round 1664, train_loss: 0.45295253700775073, val_loss: 0.42888760500178386 \n",
      "round 1665, train_loss: 0.4529112670278724, val_loss: 0.42884260534799856 \n",
      "round 1666, train_loss: 0.4528700321252575, val_loss: 0.4287976485535488 \n",
      "round 1667, train_loss: 0.45282883225659354, val_loss: 0.42875273456506724 \n",
      "round 1668, train_loss: 0.4527876673786385, val_loss: 0.42870786332927135 \n",
      "round 1669, train_loss: 0.45274653744822235, val_loss: 0.4286630347929654 \n",
      "round 1670, train_loss: 0.4527054424222444, val_loss: 0.4286182489030399 \n",
      "round 1671, train_loss: 0.45266438225767586, val_loss: 0.42857350560647045 \n",
      "round 1672, train_loss: 0.452623356911557, val_loss: 0.4285288048503189 \n",
      "round 1673, train_loss: 0.45258236634099946, val_loss: 0.42848414658173184 \n",
      "round 1674, train_loss: 0.4525414105031842, val_loss: 0.42843953074794155 \n",
      "round 1675, train_loss: 0.4525004893553627, val_loss: 0.428394957296265 \n",
      "round 1676, train_loss: 0.45245960285485576, val_loss: 0.42835042617410396 \n",
      "round 1677, train_loss: 0.45241875095905426, val_loss: 0.42830593732894534 \n",
      "round 1678, train_loss: 0.45237793362541834, val_loss: 0.42826149070836056 \n",
      "round 1679, train_loss: 0.4523371508114778, val_loss: 0.428217086260005 \n",
      "round 1680, train_loss: 0.45229640247483144, val_loss: 0.42817272393161837 \n",
      "round 1681, train_loss: 0.45225568857314746, val_loss: 0.4281284036710245 \n",
      "round 1682, train_loss: 0.45221500906416184, val_loss: 0.428084125426131 \n",
      "round 1683, train_loss: 0.45217436390568166, val_loss: 0.4280398891449294 \n",
      "round 1684, train_loss: 0.4521337530555806, val_loss: 0.42799569477549426 \n",
      "round 1685, train_loss: 0.4520931764718016, val_loss: 0.4279515422659841 \n",
      "round 1686, train_loss: 0.4520526341123565, val_loss: 0.42790743156464023 \n",
      "round 1687, train_loss: 0.45201212593532464, val_loss: 0.4278633626197866 \n",
      "round 1688, train_loss: 0.4519716518988533, val_loss: 0.42781933537983124 \n",
      "round 1689, train_loss: 0.4519312119611589, val_loss: 0.4277753497932636 \n",
      "round 1690, train_loss: 0.4518908060805245, val_loss: 0.4277314058086562 \n",
      "round 1691, train_loss: 0.45185043421530174, val_loss: 0.4276875033746642 \n",
      "round 1692, train_loss: 0.4518100963239091, val_loss: 0.42764364244002406 \n",
      "round 1693, train_loss: 0.4517697923648329, val_loss: 0.4275998229535551 \n",
      "round 1694, train_loss: 0.4517295222966267, val_loss: 0.4275560448641584 \n",
      "round 1695, train_loss: 0.4516892860779111, val_loss: 0.42751230812081636 \n",
      "round 1696, train_loss: 0.45164908366737366, val_loss: 0.42746861267259323 \n",
      "round 1697, train_loss: 0.4516089150237689, val_loss: 0.4274249584686341 \n",
      "round 1698, train_loss: 0.4515687801059181, val_loss: 0.4273813454581663 \n",
      "round 1699, train_loss: 0.4515286788727093, val_loss: 0.4273377735904975 \n",
      "round 1700, train_loss: 0.45148861128309664, val_loss: 0.4272942428150163 \n",
      "round 1701, train_loss: 0.4514485772961007, val_loss: 0.4272507530811917 \n",
      "round 1702, train_loss: 0.45140857687080854, val_loss: 0.4272073043385743 \n",
      "round 1703, train_loss: 0.45136860996637274, val_loss: 0.427163896536794 \n",
      "round 1704, train_loss: 0.45132867654201236, val_loss: 0.4271205296255616 \n",
      "round 1705, train_loss: 0.451288776557012, val_loss: 0.427077203554668 \n",
      "round 1706, train_loss: 0.45124890997072176, val_loss: 0.42703391827398324 \n",
      "round 1707, train_loss: 0.4512090767425576, val_loss: 0.4269906737334586 \n",
      "round 1708, train_loss: 0.45116927683200053, val_loss: 0.4269474698831235 \n",
      "round 1709, train_loss: 0.4511295101985967, val_loss: 0.4269043066730876 \n",
      "round 1710, train_loss: 0.45108977680195844, val_loss: 0.42686118405353973 \n",
      "round 1711, train_loss: 0.4510500766017615, val_loss: 0.42681810197474757 \n",
      "round 1712, train_loss: 0.4510104095577479, val_loss: 0.4267750603870581 \n",
      "round 1713, train_loss: 0.45097077562972304, val_loss: 0.4267320592408974 \n",
      "round 1714, train_loss: 0.45093117477755834, val_loss: 0.4266890984867693 \n",
      "round 1715, train_loss: 0.4508916069611884, val_loss: 0.4266461780752573 \n",
      "round 1716, train_loss: 0.45085207214061296, val_loss: 0.426603297957022 \n",
      "round 1717, train_loss: 0.4508125702758959, val_loss: 0.4265604580828034 \n",
      "round 1718, train_loss: 0.4507731013271648, val_loss: 0.4265176584034191 \n",
      "round 1719, train_loss: 0.45073366525461145, val_loss: 0.42647489886976425 \n",
      "round 1720, train_loss: 0.4506942620184913, val_loss: 0.4264321794328119 \n",
      "round 1721, train_loss: 0.45065489157912414, val_loss: 0.42638950004361303 \n",
      "round 1722, train_loss: 0.4506155538968917, val_loss: 0.42634686065329597 \n",
      "round 1723, train_loss: 0.45057624893224113, val_loss: 0.42630426121306564 \n",
      "round 1724, train_loss: 0.4505369766456815, val_loss: 0.4262617016742053 \n",
      "round 1725, train_loss: 0.45049773699778567, val_loss: 0.42621918198807424 \n",
      "round 1726, train_loss: 0.4504585299491892, val_loss: 0.42617670210610864 \n",
      "round 1727, train_loss: 0.4504193554605908, val_loss: 0.4261342619798222 \n",
      "round 1728, train_loss: 0.4503802134927524, val_loss: 0.42609186156080386 \n",
      "round 1729, train_loss: 0.45034110400649735, val_loss: 0.42604950080072 \n",
      "round 1730, train_loss: 0.45030202696271293, val_loss: 0.4260071796513128 \n",
      "round 1731, train_loss: 0.4502629823223477, val_loss: 0.42596489806440063 \n",
      "round 1732, train_loss: 0.45022397004641335, val_loss: 0.4259226559918772 \n",
      "round 1733, train_loss: 0.45018499009598323, val_loss: 0.42588045338571334 \n",
      "round 1734, train_loss: 0.45014604243219314, val_loss: 0.42583829019795405 \n",
      "round 1735, train_loss: 0.45010712701624017, val_loss: 0.4257961663807204 \n",
      "round 1736, train_loss: 0.45006824380938404, val_loss: 0.4257540818862094 \n",
      "round 1737, train_loss: 0.4500293927729451, val_loss: 0.42571203666669205 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1738, train_loss: 0.44999057386830615, val_loss: 0.42567003067451537 \n",
      "round 1739, train_loss: 0.4499517870569113, val_loss: 0.4256280638621007 \n",
      "round 1740, train_loss: 0.4499130323002653, val_loss: 0.4255861361819443 \n",
      "round 1741, train_loss: 0.4498743095599347, val_loss: 0.4255442475866174 \n",
      "round 1742, train_loss: 0.44983561879754674, val_loss: 0.4255023980287648 \n",
      "round 1743, train_loss: 0.4497969599747898, val_loss: 0.4254605874611064 \n",
      "round 1744, train_loss: 0.4497583330534133, val_loss: 0.4254188158364363 \n",
      "round 1745, train_loss: 0.4497197379952267, val_loss: 0.4253770831076219 \n",
      "round 1746, train_loss: 0.44968117476210046, val_loss: 0.425335389227605 \n",
      "round 1747, train_loss: 0.4496426433159656, val_loss: 0.425293734149401 \n",
      "round 1748, train_loss: 0.44960414361881296, val_loss: 0.42525211782609873 \n",
      "round 1749, train_loss: 0.4495656756326939, val_loss: 0.42521054021086124 \n",
      "round 1750, train_loss: 0.4495272393197199, val_loss: 0.4251690012569235 \n",
      "round 1751, train_loss: 0.4494888346420622, val_loss: 0.4251275009175946 \n",
      "round 1752, train_loss: 0.44945046156195245, val_loss: 0.42508603914625664 \n",
      "round 1753, train_loss: 0.4494121200416813, val_loss: 0.4250446158963642 \n",
      "round 1754, train_loss: 0.44937381004359905, val_loss: 0.4250032311214449 \n",
      "round 1755, train_loss: 0.449335531530116, val_loss: 0.4249618847750988 \n",
      "round 1756, train_loss: 0.44929728446370154, val_loss: 0.4249205768109982 \n",
      "round 1757, train_loss: 0.449259068806884, val_loss: 0.424879307182888 \n",
      "round 1758, train_loss: 0.44922088452225145, val_loss: 0.4248380758445853 \n",
      "round 1759, train_loss: 0.44918273157245064, val_loss: 0.42479688274997907 \n",
      "round 1760, train_loss: 0.44914460992018684, val_loss: 0.4247557278530301 \n",
      "round 1761, train_loss: 0.44910651952822517, val_loss: 0.424714611107771 \n",
      "round 1762, train_loss: 0.449068460359388, val_loss: 0.4246735324683058 \n",
      "round 1763, train_loss: 0.4490304323765573, val_loss: 0.42463249188881097 \n",
      "round 1764, train_loss: 0.4489924355426736, val_loss: 0.4245914893235323 \n",
      "round 1765, train_loss: 0.4489544698207344, val_loss: 0.4245505247267893 \n",
      "round 1766, train_loss: 0.4489165351737967, val_loss: 0.4245095980529703 \n",
      "round 1767, train_loss: 0.44887863156497504, val_loss: 0.42446870925653574 \n",
      "round 1768, train_loss: 0.4488407589574421, val_loss: 0.4244278582920166 \n",
      "round 1769, train_loss: 0.4488029173144285, val_loss: 0.4243870451140144 \n",
      "round 1770, train_loss: 0.4487651065992223, val_loss: 0.4243462696772013 \n",
      "round 1771, train_loss: 0.44872732677516947, val_loss: 0.42430553193631954 \n",
      "round 1772, train_loss: 0.44868957780567303, val_loss: 0.4242648318461823 \n",
      "round 1773, train_loss: 0.44865185965419374, val_loss: 0.4242241693616717 \n",
      "round 1774, train_loss: 0.4486141722842498, val_loss: 0.42418354443774037 \n",
      "round 1775, train_loss: 0.44857651565941636, val_loss: 0.424142957029412 \n",
      "round 1776, train_loss: 0.44853888974332573, val_loss: 0.42410240709177754 \n",
      "round 1777, train_loss: 0.4485012944996667, val_loss: 0.42406189457999954 \n",
      "round 1778, train_loss: 0.44846372989218525, val_loss: 0.42402141944930877 \n",
      "round 1779, train_loss: 0.44842619588468463, val_loss: 0.4239809816550062 \n",
      "round 1780, train_loss: 0.44838869244102386, val_loss: 0.4239405811524611 \n",
      "round 1781, train_loss: 0.4483512195251188, val_loss: 0.42390021789711224 \n",
      "round 1782, train_loss: 0.44831377710094145, val_loss: 0.4238598918444672 \n",
      "round 1783, train_loss: 0.4482763651325205, val_loss: 0.42381960295010207 \n",
      "round 1784, train_loss: 0.4482389835839403, val_loss: 0.42377935116966203 \n",
      "round 1785, train_loss: 0.4482016324193419, val_loss: 0.42373913645886035 \n",
      "round 1786, train_loss: 0.4481643116029216, val_loss: 0.42369895877347924 \n",
      "round 1787, train_loss: 0.4481270210989318, val_loss: 0.4236588180693679 \n",
      "round 1788, train_loss: 0.44808976087168134, val_loss: 0.42361871430244524 \n",
      "round 1789, train_loss: 0.44805253088553304, val_loss: 0.4235786474286967 \n",
      "round 1790, train_loss: 0.448015331104907, val_loss: 0.4235386174041767 \n",
      "round 1791, train_loss: 0.44797816149427716, val_loss: 0.4234986241850065 \n",
      "round 1792, train_loss: 0.44794102201817404, val_loss: 0.4234586677273756 \n",
      "round 1793, train_loss: 0.4479039126411824, val_loss: 0.4234187479875401 \n",
      "round 1794, train_loss: 0.4478668333279426, val_loss: 0.42337886492182414 \n",
      "round 1795, train_loss: 0.44782978404314994, val_loss: 0.4233390184866191 \n",
      "round 1796, train_loss: 0.44779276475155405, val_loss: 0.4232992086383832 \n",
      "round 1797, train_loss: 0.44775577541796047, val_loss: 0.4232594353336414 \n",
      "round 1798, train_loss: 0.4477188160072275, val_loss: 0.4232196985289856 \n",
      "round 1799, train_loss: 0.44768188648426976, val_loss: 0.4231799981810742 \n",
      "round 1800, train_loss: 0.4476449868140556, val_loss: 0.4231403342466327 \n",
      "round 1801, train_loss: 0.44760811696160735, val_loss: 0.4231007066824526 \n",
      "round 1802, train_loss: 0.447571276892002, val_loss: 0.4230611154453914 \n",
      "round 1803, train_loss: 0.4475344665703705, val_loss: 0.42302156049237377 \n",
      "round 1804, train_loss: 0.4474976859618982, val_loss: 0.4229820417803894 \n",
      "round 1805, train_loss: 0.44746093503182344, val_loss: 0.42294255926649404 \n",
      "round 1806, train_loss: 0.44742421374543917, val_loss: 0.4229031129078098 \n",
      "round 1807, train_loss: 0.44738752206809185, val_loss: 0.4228637026615243 \n",
      "round 1808, train_loss: 0.4473508599651811, val_loss: 0.42282432848489 \n",
      "round 1809, train_loss: 0.44731422740216054, val_loss: 0.4227849903352253 \n",
      "round 1810, train_loss: 0.44727762434453683, val_loss: 0.42274568816991465 \n",
      "round 1811, train_loss: 0.44724105075787013, val_loss: 0.4227064219464061 \n",
      "round 1812, train_loss: 0.44720450660777383, val_loss: 0.42266719162221383 \n",
      "round 1813, train_loss: 0.4471679918599135, val_loss: 0.4226279971549166 \n",
      "round 1814, train_loss: 0.44713150648000904, val_loss: 0.42258883850215817 \n",
      "round 1815, train_loss: 0.4470950504338324, val_loss: 0.42254971562164645 \n",
      "round 1816, train_loss: 0.4470586236872083, val_loss: 0.4225106284711545 \n",
      "round 1817, train_loss: 0.44702222620601434, val_loss: 0.4224715770085196 \n",
      "round 1818, train_loss: 0.4469858579561803, val_loss: 0.42243256119164313 \n",
      "round 1819, train_loss: 0.4469495189036889, val_loss: 0.4223935809784912 \n",
      "round 1820, train_loss: 0.4469132090145748, val_loss: 0.42235463632709325 \n",
      "round 1821, train_loss: 0.4468769282549255, val_loss: 0.4223157271955426 \n",
      "round 1822, train_loss: 0.4468406765908795, val_loss: 0.4222768535419975 \n",
      "round 1823, train_loss: 0.44680445398862856, val_loss: 0.42223801532467914 \n",
      "round 1824, train_loss: 0.44676826041441564, val_loss: 0.4221992125018722 \n",
      "round 1825, train_loss: 0.4467320958345358, val_loss: 0.4221604450319249 \n",
      "round 1826, train_loss: 0.44669596021533586, val_loss: 0.42212171287324896 \n",
      "round 1827, train_loss: 0.4466598535232139, val_loss: 0.42208301598431885 \n",
      "round 1828, train_loss: 0.4466237757246206, val_loss: 0.4220443543236728 \n",
      "round 1829, train_loss: 0.4465877267860568, val_loss: 0.42200572784991175 \n",
      "round 1830, train_loss: 0.446551706674075, val_loss: 0.42196713652169954 \n",
      "round 1831, train_loss: 0.4465157153552796, val_loss: 0.4219285802977625 \n",
      "round 1832, train_loss: 0.44647975279632557, val_loss: 0.4218900591368898 \n",
      "round 1833, train_loss: 0.44644381896391905, val_loss: 0.42185157299793263 \n",
      "round 1834, train_loss: 0.4464079138248171, val_loss: 0.4218131218398059 \n",
      "round 1835, train_loss: 0.44637203734582775, val_loss: 0.4217747056214852 \n",
      "round 1836, train_loss: 0.4463361894938095, val_loss: 0.4217363243020093 \n",
      "round 1837, train_loss: 0.4463003702356715, val_loss: 0.42169797784047824 \n",
      "round 1838, train_loss: 0.4462645795383743, val_loss: 0.42165966619605505 \n",
      "round 1839, train_loss: 0.44622881736892767, val_loss: 0.4216213893279635 \n",
      "round 1840, train_loss: 0.4461930836943924, val_loss: 0.42158314719548906 \n",
      "round 1841, train_loss: 0.44615737848187986, val_loss: 0.4215449397579799 \n",
      "round 1842, train_loss: 0.44612170169855064, val_loss: 0.4215067669748449 \n",
      "round 1843, train_loss: 0.4460860533116162, val_loss: 0.42146862880555375 \n",
      "round 1844, train_loss: 0.44605043328833777, val_loss: 0.4214305252096382 \n",
      "round 1845, train_loss: 0.4460148415960262, val_loss: 0.42139245614669085 \n",
      "round 1846, train_loss: 0.4459792782020425, val_loss: 0.42135442157636505 \n",
      "round 1847, train_loss: 0.4459437430737972, val_loss: 0.4213164214583754 \n",
      "round 1848, train_loss: 0.44590823617875014, val_loss: 0.42127845575249695 \n",
      "round 1849, train_loss: 0.44587275748441135, val_loss: 0.4212405244185656 \n",
      "round 1850, train_loss: 0.44583730695833923, val_loss: 0.4212026274164778 \n",
      "round 1851, train_loss: 0.445801884568143, val_loss: 0.4211647647061903 \n",
      "round 1852, train_loss: 0.4457664902814792, val_loss: 0.4211269362477201 \n",
      "round 1853, train_loss: 0.4457311240660549, val_loss: 0.4210891420011448 \n",
      "round 1854, train_loss: 0.44569578588962583, val_loss: 0.42105138192660124 \n",
      "round 1855, train_loss: 0.44566047571999684, val_loss: 0.4210136559842875 \n",
      "round 1856, train_loss: 0.44562519352502067, val_loss: 0.42097596413446015 \n",
      "round 1857, train_loss: 0.4455899392726001, val_loss: 0.42093830633743634 \n",
      "round 1858, train_loss: 0.44555471293068566, val_loss: 0.4209006825535929 \n",
      "round 1859, train_loss: 0.4455195144672767, val_loss: 0.420863092743366 \n",
      "round 1860, train_loss: 0.4454843438504213, val_loss: 0.4208255368672508 \n",
      "round 1861, train_loss: 0.4454492010482157, val_loss: 0.42078801488580225 \n",
      "round 1862, train_loss: 0.4454140860288038, val_loss: 0.4207505267596348 \n",
      "round 1863, train_loss: 0.44537899876037934, val_loss: 0.42071307244942113 \n",
      "round 1864, train_loss: 0.44534393921118204, val_loss: 0.42067565191589357 \n",
      "round 1865, train_loss: 0.44530890734950135, val_loss: 0.42063826511984265 \n",
      "round 1866, train_loss: 0.44527390314367377, val_loss: 0.42060091202211874 \n",
      "round 1867, train_loss: 0.44523892656208386, val_loss: 0.42056359258362963 \n",
      "round 1868, train_loss: 0.445203977573164, val_loss: 0.4205263067653427 \n",
      "round 1869, train_loss: 0.4451690561453936, val_loss: 0.4204890545282826 \n",
      "round 1870, train_loss: 0.44513416224730074, val_loss: 0.42045183583353357 \n",
      "round 1871, train_loss: 0.44509929584746005, val_loss: 0.4204146506422371 \n",
      "round 1872, train_loss: 0.4450644569144935, val_loss: 0.4203774989155933 \n",
      "round 1873, train_loss: 0.44502964541707135, val_loss: 0.42034038061486007 \n",
      "round 1874, train_loss: 0.4449948613239097, val_loss: 0.42030329570135305 \n",
      "round 1875, train_loss: 0.4449601046037729, val_loss: 0.42026624413644625 \n",
      "round 1876, train_loss: 0.44492537522547115, val_loss: 0.4202292258815707 \n",
      "round 1877, train_loss: 0.4448906731578631, val_loss: 0.4201922408982149 \n",
      "round 1878, train_loss: 0.44485599836985257, val_loss: 0.4201552891479253 \n",
      "round 1879, train_loss: 0.4448213508303915, val_loss: 0.42011837059230595 \n",
      "round 1880, train_loss: 0.44478673050847745, val_loss: 0.4200814851930173 \n",
      "round 1881, train_loss: 0.44475213737315544, val_loss: 0.4200446329117775 \n",
      "round 1882, train_loss: 0.4447175713935164, val_loss: 0.4200078137103613 \n",
      "round 1883, train_loss: 0.44468303253869723, val_loss: 0.41997102755060123 \n",
      "round 1884, train_loss: 0.4446485207778827, val_loss: 0.41993427439438563 \n",
      "round 1885, train_loss: 0.444614036080302, val_loss: 0.4198975542036602 \n",
      "round 1886, train_loss: 0.4445795784152318, val_loss: 0.41986086694042724 \n",
      "round 1887, train_loss: 0.44454514775199355, val_loss: 0.4198242125667447 \n",
      "round 1888, train_loss: 0.4445107440599559, val_loss: 0.41978759104472846 \n",
      "round 1889, train_loss: 0.4444763673085326, val_loss: 0.4197510023365491 \n",
      "round 1890, train_loss: 0.44444201746718365, val_loss: 0.41971444640443467 \n",
      "round 1891, train_loss: 0.44440769450541423, val_loss: 0.41967792321066866 \n",
      "round 1892, train_loss: 0.4443733983927755, val_loss: 0.41964143271759063 \n",
      "round 1893, train_loss: 0.4443391290988645, val_loss: 0.4196049748875957 \n",
      "round 1894, train_loss: 0.44430488659332235, val_loss: 0.4195685496831359 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1895, train_loss: 0.44427067084583716, val_loss: 0.4195321570667174 \n",
      "round 1896, train_loss: 0.44423648182614134, val_loss: 0.4194957970009033 \n",
      "round 1897, train_loss: 0.4442023195040126, val_loss: 0.41945946944831103 \n",
      "round 1898, train_loss: 0.44416818384927415, val_loss: 0.41942317437161447 \n",
      "round 1899, train_loss: 0.44413407483179373, val_loss: 0.4193869117335419 \n",
      "round 1900, train_loss: 0.44409999242148435, val_loss: 0.41935068149687754 \n",
      "round 1901, train_loss: 0.44406593658830357, val_loss: 0.41931448362445994 \n",
      "round 1902, train_loss: 0.444031907302254, val_loss: 0.41927831807918275 \n",
      "round 1903, train_loss: 0.4439979045333827, val_loss: 0.41924218482399506 \n",
      "round 1904, train_loss: 0.44396392825178155, val_loss: 0.41920608382190017 \n",
      "round 1905, train_loss: 0.44392997842758675, val_loss: 0.41917001503595624 \n",
      "round 1906, train_loss: 0.4438960550309787, val_loss: 0.41913397842927597 \n",
      "round 1907, train_loss: 0.44386215803218293, val_loss: 0.41909797396502624 \n",
      "round 1908, train_loss: 0.4438282874014687, val_loss: 0.41906200160642915 \n",
      "round 1909, train_loss: 0.44379444310914873, val_loss: 0.41902606131676007 \n",
      "round 1910, train_loss: 0.44376062512558134, val_loss: 0.41899015305934906 \n",
      "round 1911, train_loss: 0.44372683342116814, val_loss: 0.41895427679758 \n",
      "round 1912, train_loss: 0.4436930679663542, val_loss: 0.41891843249489075 \n",
      "round 1913, train_loss: 0.44365932873162894, val_loss: 0.41888262011477356 \n",
      "round 1914, train_loss: 0.44362561568752584, val_loss: 0.41884683962077407 \n",
      "round 1915, train_loss: 0.44359192880462117, val_loss: 0.4188110909764913 \n",
      "round 1916, train_loss: 0.4435582680535355, val_loss: 0.41877537414557786 \n",
      "round 1917, train_loss: 0.44352463340493314, val_loss: 0.4187396890917406 \n",
      "round 1918, train_loss: 0.4434910248295212, val_loss: 0.41870403577873916 \n",
      "round 1919, train_loss: 0.44345744229804995, val_loss: 0.41866841417038625 \n",
      "round 1920, train_loss: 0.443423885781314, val_loss: 0.41863282423054843 \n",
      "round 1921, train_loss: 0.4433903552501503, val_loss: 0.41859726592314445 \n",
      "round 1922, train_loss: 0.443356850675439, val_loss: 0.4185617392121466 \n",
      "round 1923, train_loss: 0.443323372028104, val_loss: 0.41852624406158084 \n",
      "round 1924, train_loss: 0.4432899192791111, val_loss: 0.4184907804355242 \n",
      "round 1925, train_loss: 0.4432564923994697, val_loss: 0.4184553482981078 \n",
      "round 1926, train_loss: 0.44322309136023175, val_loss: 0.41841994761351486 \n",
      "round 1927, train_loss: 0.44318971613249186, val_loss: 0.4183845783459808 \n",
      "round 1928, train_loss: 0.4431563666873876, val_loss: 0.4183492404597942 \n",
      "round 1929, train_loss: 0.4431230429960984, val_loss: 0.4183139339192952 \n",
      "round 1930, train_loss: 0.4430897450298473, val_loss: 0.41827865868887687 \n",
      "round 1931, train_loss: 0.44305647275989846, val_loss: 0.4182434147329837 \n",
      "round 1932, train_loss: 0.44302322615755957, val_loss: 0.4182082020161127 \n",
      "round 1933, train_loss: 0.4429900051941794, val_loss: 0.4181730205028126 \n",
      "round 1934, train_loss: 0.4429568098411499, val_loss: 0.4181378701576844 \n",
      "round 1935, train_loss: 0.44292364006990453, val_loss: 0.4181027509453801 \n",
      "round 1936, train_loss: 0.44289049585191886, val_loss: 0.41806766283060404 \n",
      "round 1937, train_loss: 0.44285737715871054, val_loss: 0.4180326057781116 \n",
      "round 1938, train_loss: 0.44282428396183876, val_loss: 0.41799757975270985 \n",
      "round 1939, train_loss: 0.44279121623290507, val_loss: 0.4179625847192575 \n",
      "round 1940, train_loss: 0.442758173943552, val_loss: 0.41792762064266425 \n",
      "round 1941, train_loss: 0.4427251570654642, val_loss: 0.41789268748789105 \n",
      "round 1942, train_loss: 0.4426921655703679, val_loss: 0.41785778521994976 \n",
      "round 1943, train_loss: 0.44265919943003035, val_loss: 0.4178229138039034 \n",
      "round 1944, train_loss: 0.44262625861626065, val_loss: 0.4177880732048661 \n",
      "round 1945, train_loss: 0.44259334310090903, val_loss: 0.417753263388003 \n",
      "round 1946, train_loss: 0.442560452855867, val_loss: 0.4177184843185288 \n",
      "round 1947, train_loss: 0.4425275878530668, val_loss: 0.4176837359617104 \n",
      "round 1948, train_loss: 0.44249474806448275, val_loss: 0.4176490182828639 \n",
      "round 1949, train_loss: 0.4424619334621291, val_loss: 0.4176143312473566 \n",
      "round 1950, train_loss: 0.4424291440180619, val_loss: 0.41757967482060626 \n",
      "round 1951, train_loss: 0.44239637970437784, val_loss: 0.41754504896808065 \n",
      "round 1952, train_loss: 0.44236364049321364, val_loss: 0.4175104536552976 \n",
      "round 1953, train_loss: 0.4423309263567476, val_loss: 0.4174758888478251 \n",
      "round 1954, train_loss: 0.4422982372671988, val_loss: 0.4174413545112812 \n",
      "round 1955, train_loss: 0.44226557319682597, val_loss: 0.4174068506113343 \n",
      "round 1956, train_loss: 0.44223293411792913, val_loss: 0.4173723771137017 \n",
      "round 1957, train_loss: 0.4422003200028484, val_loss: 0.41733793398415076 \n",
      "round 1958, train_loss: 0.4421677308239639, val_loss: 0.4173035211884994 \n",
      "round 1959, train_loss: 0.44213516655369733, val_loss: 0.4172691386926139 \n",
      "round 1960, train_loss: 0.4421026271645087, val_loss: 0.41723478646241036 \n",
      "round 1961, train_loss: 0.4420701126288994, val_loss: 0.4172004644638542 \n",
      "round 1962, train_loss: 0.44203762291941073, val_loss: 0.4171661726629611 \n",
      "round 1963, train_loss: 0.4420051580086239, val_loss: 0.41713191102579433 \n",
      "round 1964, train_loss: 0.441972717869159, val_loss: 0.4170976795184669 \n",
      "round 1965, train_loss: 0.44194030247367805, val_loss: 0.41706347810714195 \n",
      "round 1966, train_loss: 0.4419079117948806, val_loss: 0.4170293067580294 \n",
      "round 1967, train_loss: 0.44187554580550753, val_loss: 0.41699516543739024 \n",
      "round 1968, train_loss: 0.4418432044783386, val_loss: 0.41696105411153256 \n",
      "round 1969, train_loss: 0.4418108877861929, val_loss: 0.416926972746814 \n",
      "round 1970, train_loss: 0.4417785957019295, val_loss: 0.4168929213096408 \n",
      "round 1971, train_loss: 0.44174632819844684, val_loss: 0.4168588997664666 \n",
      "round 1972, train_loss: 0.441714085248682, val_loss: 0.4168249080837954 \n",
      "round 1973, train_loss: 0.4416818668256121, val_loss: 0.4167909462281777 \n",
      "round 1974, train_loss: 0.44164967290225315, val_loss: 0.41675701416621297 \n",
      "round 1975, train_loss: 0.44161750345166023, val_loss: 0.41672311186454886 \n",
      "round 1976, train_loss: 0.44158535844692737, val_loss: 0.41668923928988083 \n",
      "round 1977, train_loss: 0.44155323786118766, val_loss: 0.4166553964089532 \n",
      "round 1978, train_loss: 0.44152114166761297, val_loss: 0.41662158318855713 \n",
      "round 1979, train_loss: 0.4414890698394145, val_loss: 0.4165877995955319 \n",
      "round 1980, train_loss: 0.44145702234984147, val_loss: 0.41655404559676446 \n",
      "round 1981, train_loss: 0.4414249991721818, val_loss: 0.41652032115918963 \n",
      "round 1982, train_loss: 0.441393000279763, val_loss: 0.41648662624979 \n",
      "round 1983, train_loss: 0.44136102564595037, val_loss: 0.4164529608355948 \n",
      "round 1984, train_loss: 0.44132907524414705, val_loss: 0.4164193248836813 \n",
      "round 1985, train_loss: 0.44129714904779604, val_loss: 0.4163857183611741 \n",
      "round 1986, train_loss: 0.44126524703037767, val_loss: 0.41635214123524467 \n",
      "round 1987, train_loss: 0.4412333691654105, val_loss: 0.41631859347311184 \n",
      "round 1988, train_loss: 0.44120151542645214, val_loss: 0.41628507504204126 \n",
      "round 1989, train_loss: 0.44116968578709675, val_loss: 0.41625158590934597 \n",
      "round 1990, train_loss: 0.4411378802209788, val_loss: 0.4162181260423854 \n",
      "round 1991, train_loss: 0.44110609870176837, val_loss: 0.41618469540856606 \n",
      "round 1992, train_loss: 0.441074341203175, val_loss: 0.41615129397534095 \n",
      "round 1993, train_loss: 0.44104260769894593, val_loss: 0.41611792171021 \n",
      "round 1994, train_loss: 0.4410108981628653, val_loss: 0.4160845785807198 \n",
      "round 1995, train_loss: 0.440979212568756, val_loss: 0.4160512645544626 \n",
      "round 1996, train_loss: 0.4409475508904776, val_loss: 0.41601797959907794 \n",
      "round 1997, train_loss: 0.4409159131019282, val_loss: 0.4159847236822514 \n",
      "round 1998, train_loss: 0.44088429917704264, val_loss: 0.41595149677171456 \n",
      "round 1999, train_loss: 0.4408527090897938, val_loss: 0.41591829883524534 \n",
      "round 2000, train_loss: 0.4408211428141912, val_loss: 0.4158851298406671 \n",
      "round 2001, train_loss: 0.4407896003242825, val_loss: 0.41585198975585047 \n",
      "round 2002, train_loss: 0.44075808159415203, val_loss: 0.4158188785487108 \n",
      "round 2003, train_loss: 0.4407265865979212, val_loss: 0.4157857961872097 \n",
      "round 2004, train_loss: 0.44069511530974903, val_loss: 0.4157527426393547 \n",
      "round 2005, train_loss: 0.4406636677038314, val_loss: 0.415719717873198 \n",
      "round 2006, train_loss: 0.44063224375440074, val_loss: 0.41568672185683914 \n",
      "round 2007, train_loss: 0.4406008434357268, val_loss: 0.41565375455842163 \n",
      "round 2008, train_loss: 0.4405694667221163, val_loss: 0.415620815946135 \n",
      "round 2009, train_loss: 0.4405381135879121, val_loss: 0.41558790598821366 \n",
      "round 2010, train_loss: 0.4405067840074949, val_loss: 0.4155550246529379 \n",
      "round 2011, train_loss: 0.44047547795528014, val_loss: 0.41552217190863283 \n",
      "round 2012, train_loss: 0.4404441954057219, val_loss: 0.4154893477236686 \n",
      "round 2013, train_loss: 0.4404129363333097, val_loss: 0.41545655206646065 \n",
      "round 2014, train_loss: 0.44038170071256916, val_loss: 0.4154237849054689 \n",
      "round 2015, train_loss: 0.44035048851806313, val_loss: 0.41539104620919826 \n",
      "round 2016, train_loss: 0.4403192997243903, val_loss: 0.4153583359461991 \n",
      "round 2017, train_loss: 0.4402881343061859, val_loss: 0.41532565408506544 \n",
      "round 2018, train_loss: 0.4402569922381208, val_loss: 0.4152930005944366 \n",
      "round 2019, train_loss: 0.44022587349490244, val_loss: 0.41526037544299615 \n",
      "round 2020, train_loss: 0.4401947780512742, val_loss: 0.4152277785994721 \n",
      "round 2021, train_loss: 0.4401637058820157, val_loss: 0.4151952100326368 \n",
      "round 2022, train_loss: 0.44013265696194165, val_loss: 0.4151626697113075 \n",
      "round 2023, train_loss: 0.44010163126590335, val_loss: 0.41513015760434474 \n",
      "round 2024, train_loss: 0.4400706287687881, val_loss: 0.4150976736806538 \n",
      "round 2025, train_loss: 0.44003964944551827, val_loss: 0.4150652179091839 \n",
      "round 2026, train_loss: 0.44000869327105196, val_loss: 0.41503279025892825 \n",
      "round 2027, train_loss: 0.4399777602203833, val_loss: 0.4150003906989239 \n",
      "round 2028, train_loss: 0.4399468502685416, val_loss: 0.4149680191982518 \n",
      "round 2029, train_loss: 0.43991596339059186, val_loss: 0.4149356757260368 \n",
      "round 2030, train_loss: 0.4398850995616342, val_loss: 0.41490336025144686 \n",
      "round 2031, train_loss: 0.4398542587568045, val_loss: 0.4148710727436945 \n",
      "round 2032, train_loss: 0.43982344095127385, val_loss: 0.4148388131720346 \n",
      "round 2033, train_loss: 0.43979264612024793, val_loss: 0.41480658150576694 \n",
      "round 2034, train_loss: 0.43976187423896856, val_loss: 0.41477437771423326 \n",
      "round 2035, train_loss: 0.43973112528271163, val_loss: 0.41474220176681936 \n",
      "round 2036, train_loss: 0.43970039922678905, val_loss: 0.41471005363295443 \n",
      "round 2037, train_loss: 0.43966969604654677, val_loss: 0.41467793328210983 \n",
      "round 2038, train_loss: 0.4396390157173668, val_loss: 0.41464584068380106 \n",
      "round 2039, train_loss: 0.4396083582146646, val_loss: 0.4146137758075865 \n",
      "round 2040, train_loss: 0.43957772351389157, val_loss: 0.4145817386230666 \n",
      "round 2041, train_loss: 0.43954711159053306, val_loss: 0.41454972909988547 \n",
      "round 2042, train_loss: 0.4395165224201096, val_loss: 0.4145177472077297 \n",
      "round 2043, train_loss: 0.4394859559781759, val_loss: 0.4144857929163287 \n",
      "round 2044, train_loss: 0.43945541224032153, val_loss: 0.41445386619545443 \n",
      "round 2045, train_loss: 0.43942489118217076, val_loss: 0.4144219670149216 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 2046, train_loss: 0.4393943927793813, val_loss: 0.4143900953445866 \n",
      "round 2047, train_loss: 0.4393639170076464, val_loss: 0.4143582511543497 \n",
      "round 2048, train_loss: 0.4393334638426929, val_loss: 0.4143264344141518 \n",
      "round 2049, train_loss: 0.4393030332602818, val_loss: 0.4142946450939773 \n",
      "round 2050, train_loss: 0.43927262523620875, val_loss: 0.41426288316385207 \n",
      "round 2051, train_loss: 0.43924223974630305, val_loss: 0.414231148593845 \n",
      "round 2052, train_loss: 0.43921187676642875, val_loss: 0.4141994413540657 \n",
      "round 2053, train_loss: 0.4391815362724825, val_loss: 0.4141677614146668 \n",
      "round 2054, train_loss: 0.43915121824039666, val_loss: 0.41413610874584256 \n",
      "round 2055, train_loss: 0.43912092264613606, val_loss: 0.41410448331782823 \n",
      "round 2056, train_loss: 0.4390906494657, val_loss: 0.4140728851009027 \n",
      "round 2057, train_loss: 0.4390603986751213, val_loss: 0.4140413140653844 \n",
      "round 2058, train_loss: 0.43903017025046676, val_loss: 0.4140097701816345 \n",
      "round 2059, train_loss: 0.4389999641678364, val_loss: 0.4139782534200557 \n",
      "round 2060, train_loss: 0.438969780403364, val_loss: 0.4139467637510921 \n",
      "round 2061, train_loss: 0.43893961893321715, val_loss: 0.4139153011452285 \n",
      "round 2062, train_loss: 0.43890947973359623, val_loss: 0.41388386557299217 \n",
      "round 2063, train_loss: 0.43887936278073564, val_loss: 0.41385245700495066 \n",
      "round 2064, train_loss: 0.43884926805090263, val_loss: 0.413821075411713 \n",
      "round 2065, train_loss: 0.4388191955203982, val_loss: 0.41378972076392984 \n",
      "round 2066, train_loss: 0.4387891451655565, val_loss: 0.41375839303229167 \n",
      "round 2067, train_loss: 0.4387591169627441, val_loss: 0.4137270921875312 \n",
      "round 2068, train_loss: 0.43872911088836164, val_loss: 0.4136958182004208 \n",
      "round 2069, train_loss: 0.43869912691884233, val_loss: 0.4136645710417753 \n",
      "round 2070, train_loss: 0.4386691650306525, val_loss: 0.4136333506824485 \n",
      "round 2071, train_loss: 0.43863922520029136, val_loss: 0.41360215709333564 \n",
      "round 2072, train_loss: 0.4386093074042909, val_loss: 0.4135709902453731 \n",
      "round 2073, train_loss: 0.43857941161921576, val_loss: 0.41353985010953664 \n",
      "round 2074, train_loss: 0.43854953782166406, val_loss: 0.41350873665684357 \n",
      "round 2075, train_loss: 0.43851968598826563, val_loss: 0.41347764985835117 \n",
      "round 2076, train_loss: 0.4384898560956837, val_loss: 0.4134465896851567 \n",
      "round 2077, train_loss: 0.43846004812061395, val_loss: 0.4134155561083982 \n",
      "round 2078, train_loss: 0.43843026203978414, val_loss: 0.41338454909925343 \n",
      "round 2079, train_loss: 0.43840049782995505, val_loss: 0.413353568628941 \n",
      "round 2080, train_loss: 0.4383707554679192, val_loss: 0.4133226146687184 \n",
      "round 2081, train_loss: 0.4383410349305025, val_loss: 0.4132916871898843 \n",
      "round 2082, train_loss: 0.4383113361945623, val_loss: 0.4132607861637764 \n",
      "round 2083, train_loss: 0.43828165923698836, val_loss: 0.41322991156177286 \n",
      "round 2084, train_loss: 0.43825200403470244, val_loss: 0.41319906335529116 \n",
      "round 2085, train_loss: 0.438222370564659, val_loss: 0.41316824151578874 \n",
      "round 2086, train_loss: 0.4381927588038444, val_loss: 0.41313744601476254 \n",
      "round 2087, train_loss: 0.43816316872927685, val_loss: 0.41310667682374924 \n",
      "round 2088, train_loss: 0.4381336003180061, val_loss: 0.41307593391432473 \n",
      "round 2089, train_loss: 0.43810405354711485, val_loss: 0.41304521725810467 \n",
      "round 2090, train_loss: 0.4380745283937166, val_loss: 0.4130145268267438 \n",
      "round 2091, train_loss: 0.4380450248349571, val_loss: 0.41298386259193626 \n",
      "round 2092, train_loss: 0.43801554284801414, val_loss: 0.41295322452541516 \n",
      "round 2093, train_loss: 0.43798608241009657, val_loss: 0.4129226125989536 \n",
      "round 2094, train_loss: 0.4379566434984454, val_loss: 0.4128920267843626 \n",
      "round 2095, train_loss: 0.43792722609033274, val_loss: 0.4128614670534932 \n",
      "round 2096, train_loss: 0.4378978301630629, val_loss: 0.41283093337823523 \n",
      "round 2097, train_loss: 0.4378684556939707, val_loss: 0.4128004257305163 \n",
      "round 2098, train_loss: 0.43783910266042336, val_loss: 0.4127699440823048 \n",
      "round 2099, train_loss: 0.4378097710398182, val_loss: 0.412739488405606 \n",
      "round 2100, train_loss: 0.43778046080958555, val_loss: 0.4127090586724651 \n",
      "round 2101, train_loss: 0.43775117194718544, val_loss: 0.4126786548549655 \n",
      "round 2102, train_loss: 0.43772190443010994, val_loss: 0.41264827692522926 \n",
      "round 2103, train_loss: 0.43769265823588205, val_loss: 0.4126179248554162 \n",
      "round 2104, train_loss: 0.43766343334205554, val_loss: 0.4125875986177261 \n",
      "round 2105, train_loss: 0.4376342297262156, val_loss: 0.4125572981843958 \n",
      "round 2106, train_loss: 0.43760504736597855, val_loss: 0.41252702352770054 \n",
      "round 2107, train_loss: 0.437575886238991, val_loss: 0.41249677461995454 \n",
      "round 2108, train_loss: 0.4375467463229308, val_loss: 0.41246655143350963 \n",
      "round 2109, train_loss: 0.4375176275955066, val_loss: 0.4124363539407557 \n",
      "round 2110, train_loss: 0.4374885300344582, val_loss: 0.41240618211412133 \n",
      "round 2111, train_loss: 0.43745945361755484, val_loss: 0.4123760359260722 \n",
      "round 2112, train_loss: 0.43743039832259833, val_loss: 0.41234591534911214 \n",
      "round 2113, train_loss: 0.43740136412741915, val_loss: 0.4123158203557834 \n",
      "round 2114, train_loss: 0.4373723510098795, val_loss: 0.4122857509186655 \n",
      "round 2115, train_loss: 0.4373433589478721, val_loss: 0.41225570701037545 \n",
      "round 2116, train_loss: 0.43731438791931926, val_loss: 0.4122256886035684 \n",
      "round 2117, train_loss: 0.4372854379021745, val_loss: 0.41219569567093695 \n",
      "round 2118, train_loss: 0.4372565088744212, val_loss: 0.4121657281852112 \n",
      "round 2119, train_loss: 0.4372276008140733, val_loss: 0.41213578611915846 \n",
      "round 2120, train_loss: 0.43719871369917496, val_loss: 0.41210586944558397 \n",
      "round 2121, train_loss: 0.4371698475078005, val_loss: 0.41207597813732966 \n",
      "round 2122, train_loss: 0.4371410022180541, val_loss: 0.41204611216727516 \n",
      "round 2123, train_loss: 0.43711217780807, val_loss: 0.41201627150833775 \n",
      "round 2124, train_loss: 0.4370833742560132, val_loss: 0.41198645613347057 \n",
      "round 2125, train_loss: 0.4370545915400777, val_loss: 0.41195666601566483 \n",
      "round 2126, train_loss: 0.437025829638488, val_loss: 0.4119269011279487 \n",
      "round 2127, train_loss: 0.43699708852949853, val_loss: 0.41189716144338706 \n",
      "round 2128, train_loss: 0.43696836819139295, val_loss: 0.4118674469350814 \n",
      "round 2129, train_loss: 0.43693966860248595, val_loss: 0.4118377575761705 \n",
      "round 2130, train_loss: 0.4369109897411198, val_loss: 0.4118080933398302 \n",
      "round 2131, train_loss: 0.4368823315856684, val_loss: 0.41177845419927217 \n",
      "round 2132, train_loss: 0.4368536941145346, val_loss: 0.41174884012774515 \n",
      "round 2133, train_loss: 0.43682507730615067, val_loss: 0.41171925109853486 \n",
      "round 2134, train_loss: 0.43679648113897834, val_loss: 0.41168968708496295 \n",
      "round 2135, train_loss: 0.436767905591509, val_loss: 0.41166014806038753 \n",
      "round 2136, train_loss: 0.4367393506422637, val_loss: 0.4116306339982035 \n",
      "round 2137, train_loss: 0.43671081626979236, val_loss: 0.41160114487184213 \n",
      "round 2138, train_loss: 0.4366823024526741, val_loss: 0.4115716806547707 \n",
      "round 2139, train_loss: 0.436653809169518, val_loss: 0.4115422413204922 \n",
      "round 2140, train_loss: 0.43662533639896167, val_loss: 0.4115128268425468 \n",
      "round 2141, train_loss: 0.43659688411967246, val_loss: 0.4114834371945101 \n",
      "round 2142, train_loss: 0.4365684523103463, val_loss: 0.41145407234999404 \n",
      "round 2143, train_loss: 0.4365400409497082, val_loss: 0.4114247322826465 \n",
      "round 2144, train_loss: 0.4365116500165129, val_loss: 0.41139541696615073 \n",
      "round 2145, train_loss: 0.436483279489543, val_loss: 0.4113661263742265 \n",
      "round 2146, train_loss: 0.436454929347611, val_loss: 0.41133686048062923 \n",
      "round 2147, train_loss: 0.43642659956955765, val_loss: 0.4113076192591497 \n",
      "round 2148, train_loss: 0.4363982901342527, val_loss: 0.4112784026836148 \n",
      "round 2149, train_loss: 0.4363700010205949, val_loss: 0.4112492107278868 \n",
      "round 2150, train_loss: 0.43634173220751105, val_loss: 0.41122004336586326 \n",
      "round 2151, train_loss: 0.43631348367395745, val_loss: 0.41119090057147784 \n",
      "round 2152, train_loss: 0.43628525539891866, val_loss: 0.41116178231869943 \n",
      "round 2153, train_loss: 0.43625704736140725, val_loss: 0.41113268858153185 \n",
      "round 2154, train_loss: 0.43622885954046514, val_loss: 0.4111036193340145 \n",
      "round 2155, train_loss: 0.43620069191516253, val_loss: 0.41107457455022245 \n",
      "round 2156, train_loss: 0.4361725444645976, val_loss: 0.411045554204265 \n",
      "round 2157, train_loss: 0.4361444171678974, val_loss: 0.41101655827028777 \n",
      "round 2158, train_loss: 0.4361163100042168, val_loss: 0.41098758672247065 \n",
      "round 2159, train_loss: 0.4360882229527398, val_loss: 0.41095863953502826 \n",
      "round 2160, train_loss: 0.4360601559926776, val_loss: 0.41092971668221107 \n",
      "round 2161, train_loss: 0.43603210910327017, val_loss: 0.410900818138304 \n",
      "round 2162, train_loss: 0.43600408226378556, val_loss: 0.41087194387762677 \n",
      "round 2163, train_loss: 0.4359760754535199, val_loss: 0.4108430938745342 \n",
      "round 2164, train_loss: 0.4359480886517969, val_loss: 0.41081426810341487 \n",
      "round 2165, train_loss: 0.43592012183796935, val_loss: 0.41078546653869324 \n",
      "round 2166, train_loss: 0.43589217499141675, val_loss: 0.4107566891548278 \n",
      "round 2167, train_loss: 0.43586424809154695, val_loss: 0.4107279359263116 \n",
      "round 2168, train_loss: 0.4358363411177963, val_loss: 0.4106992068276722 \n",
      "round 2169, train_loss: 0.43580845404962787, val_loss: 0.41067050183347154 \n",
      "round 2170, train_loss: 0.435780586866533, val_loss: 0.4106418209183062 \n",
      "round 2171, train_loss: 0.43575273954803095, val_loss: 0.41061316405680653 \n",
      "round 2172, train_loss: 0.4357249120736684, val_loss: 0.41058453122363764 \n",
      "round 2173, train_loss: 0.4356971044230193, val_loss: 0.41055592239349875 \n",
      "round 2174, train_loss: 0.4356693165756859, val_loss: 0.41052733754112325 \n",
      "round 2175, train_loss: 0.4356415485112974, val_loss: 0.41049877664127826 \n",
      "round 2176, train_loss: 0.4356138002095107, val_loss: 0.4104702396687654 \n",
      "round 2177, train_loss: 0.43558607165001006, val_loss: 0.41044172659842004 \n",
      "round 2178, train_loss: 0.4355583628125067, val_loss: 0.4104132374051114 \n",
      "round 2179, train_loss: 0.43553067367674037, val_loss: 0.4103847720637427 \n",
      "round 2180, train_loss: 0.435503004222477, val_loss: 0.41035633054925097 \n",
      "round 2181, train_loss: 0.43547535442950974, val_loss: 0.4103279128366067 \n",
      "round 2182, train_loss: 0.43544772427765993, val_loss: 0.4102995189008147 \n",
      "round 2183, train_loss: 0.4354201137467749, val_loss: 0.41027114871691256 \n",
      "round 2184, train_loss: 0.43539252281673, val_loss: 0.4102428022599724 \n",
      "round 2185, train_loss: 0.43536495146742676, val_loss: 0.4102144795050992 \n",
      "round 2186, train_loss: 0.4353373996787946, val_loss: 0.41018618042743116 \n",
      "round 2187, train_loss: 0.43530986743078937, val_loss: 0.4101579050021407 \n",
      "round 2188, train_loss: 0.4352823547033937, val_loss: 0.41012965320443323 \n",
      "round 2189, train_loss: 0.4352548614766179, val_loss: 0.41010142500954755 \n",
      "round 2190, train_loss: 0.43522738773049824, val_loss: 0.41007322039275546 \n",
      "round 2191, train_loss: 0.43519993344509794, val_loss: 0.4100450393293619 \n",
      "round 2192, train_loss: 0.4351724986005076, val_loss: 0.4100168817947055 \n",
      "round 2193, train_loss: 0.4351450831768433, val_loss: 0.4099887477641575 \n",
      "round 2194, train_loss: 0.43511768715424937, val_loss: 0.40996063721312226 \n",
      "round 2195, train_loss: 0.43509031051289554, val_loss: 0.409932550117037 \n",
      "round 2196, train_loss: 0.43506295323297817, val_loss: 0.40990448645137223 \n",
      "round 2197, train_loss: 0.43503561529472057, val_loss: 0.40987644619163077 \n",
      "round 2198, train_loss: 0.4350082966783723, val_loss: 0.4098484293133489 \n",
      "round 2199, train_loss: 0.4349809973642096, val_loss: 0.40982043579209504 \n",
      "round 2200, train_loss: 0.4349537173325349, val_loss: 0.4097924656034709 \n",
      "round 2201, train_loss: 0.43492645656367673, val_loss: 0.4097645187231103 \n",
      "round 2202, train_loss: 0.4348992150379903, val_loss: 0.40973659512668004 \n",
      "round 2203, train_loss: 0.43487199273585664, val_loss: 0.4097086947898789 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 2204, train_loss: 0.43484478963768375, val_loss: 0.40968081768843934 \n",
      "round 2205, train_loss: 0.4348176057239048, val_loss: 0.4096529637981247 \n",
      "round 2206, train_loss: 0.43479044097498, val_loss: 0.40962513309473186 \n",
      "round 2207, train_loss: 0.434763295371395, val_loss: 0.4095973255540893 \n",
      "round 2208, train_loss: 0.43473616889366157, val_loss: 0.40956954115205846 \n",
      "round 2209, train_loss: 0.4347090615223176, val_loss: 0.4095417798645323 \n",
      "round 2210, train_loss: 0.43468197323792745, val_loss: 0.4095140416674366 \n",
      "round 2211, train_loss: 0.43465490402108004, val_loss: 0.40948632653672856 \n",
      "round 2212, train_loss: 0.43462785385239155, val_loss: 0.4094586344483982 \n",
      "round 2213, train_loss: 0.43460082271250305, val_loss: 0.40943096537846674 \n",
      "round 2214, train_loss: 0.43457381058208155, val_loss: 0.4094033193029882 \n",
      "round 2215, train_loss: 0.4345468174418206, val_loss: 0.40937569619804776 \n",
      "round 2216, train_loss: 0.43451984327243814, val_loss: 0.40934809603976263 \n",
      "round 2217, train_loss: 0.4344928880546784, val_loss: 0.40932051880428244 \n",
      "round 2218, train_loss: 0.43446595176931163, val_loss: 0.40929296446778735 \n",
      "round 2219, train_loss: 0.4344390343971329, val_loss: 0.4092654330064905 \n",
      "round 2220, train_loss: 0.4344121359189633, val_loss: 0.4092379243966364 \n",
      "round 2221, train_loss: 0.434385256315649, val_loss: 0.4092104386144997 \n",
      "round 2222, train_loss: 0.4343583955680616, val_loss: 0.4091829756363889 \n",
      "round 2223, train_loss: 0.4343315536570988, val_loss: 0.40915553543864214 \n",
      "round 2224, train_loss: 0.4343047305636826, val_loss: 0.4091281179976298 \n",
      "round 2225, train_loss: 0.4342779262687611, val_loss: 0.4091007232897537 \n",
      "round 2226, train_loss: 0.4342511407533072, val_loss: 0.4090733512914464 \n",
      "round 2227, train_loss: 0.4342243739983194, val_loss: 0.4090460019791725 \n",
      "round 2228, train_loss: 0.4341976259848209, val_loss: 0.40901867532942743 \n",
      "round 2229, train_loss: 0.43417089669386055, val_loss: 0.4089913713187376 \n",
      "round 2230, train_loss: 0.4341441861065123, val_loss: 0.4089640899236609 \n",
      "round 2231, train_loss: 0.43411749420387413, val_loss: 0.4089368311207861 \n",
      "round 2232, train_loss: 0.43409082096707063, val_loss: 0.4089095948867334 \n",
      "round 2233, train_loss: 0.43406416637724987, val_loss: 0.4088823811981531 \n",
      "round 2234, train_loss: 0.43403753041558607, val_loss: 0.40885519003172727 \n",
      "round 2235, train_loss: 0.43401091306327716, val_loss: 0.4088280213641683 \n",
      "round 2236, train_loss: 0.4339843143015471, val_loss: 0.4088008751722201 \n",
      "round 2237, train_loss: 0.43395773411164373, val_loss: 0.4087737514326564 \n",
      "round 2238, train_loss: 0.4339311724748401, val_loss: 0.40874665012228206 \n",
      "round 2239, train_loss: 0.4339046293724339, val_loss: 0.4087195712179333 \n",
      "round 2240, train_loss: 0.4338781047857474, val_loss: 0.4086925146964759 \n",
      "round 2241, train_loss: 0.43385159869612777, val_loss: 0.4086654805348066 \n",
      "round 2242, train_loss: 0.4338251110849465, val_loss: 0.4086384687098528 \n",
      "round 2243, train_loss: 0.4337986419335999, val_loss: 0.4086114791985721 \n",
      "round 2244, train_loss: 0.4337721912235087, val_loss: 0.4085845119779534 \n",
      "round 2245, train_loss: 0.43374575893611717, val_loss: 0.40855756702501433 \n",
      "round 2246, train_loss: 0.4337193450528957, val_loss: 0.4085306443168043 \n",
      "round 2247, train_loss: 0.43369294955533866, val_loss: 0.4085037438304026 \n",
      "round 2248, train_loss: 0.4336665724249635, val_loss: 0.4084768655429182 \n",
      "round 2249, train_loss: 0.4336402136433132, val_loss: 0.4084500094314909 \n",
      "round 2250, train_loss: 0.4336138731919547, val_loss: 0.40842317547329027 \n",
      "round 2251, train_loss: 0.4335875510524792, val_loss: 0.40839636364551624 \n",
      "round 2252, train_loss: 0.4335612472065017, val_loss: 0.40836957392539847 \n",
      "round 2253, train_loss: 0.43353496163566246, val_loss: 0.408342806290197 \n",
      "round 2254, train_loss: 0.4335086943216248, val_loss: 0.40831606071720067 \n",
      "round 2255, train_loss: 0.4334824452460762, val_loss: 0.40828933718373006 \n",
      "round 2256, train_loss: 0.43345621439072834, val_loss: 0.4082626356671343 \n",
      "round 2257, train_loss: 0.4334300017373174, val_loss: 0.40823595614479213 \n",
      "round 2258, train_loss: 0.43340380726760297, val_loss: 0.40820929859411287 \n",
      "round 2259, train_loss: 0.43337763096336823, val_loss: 0.4081826629925351 \n",
      "round 2260, train_loss: 0.43335147280642106, val_loss: 0.4081560493175269 \n",
      "round 2261, train_loss: 0.4333253327785928, val_loss: 0.40812945754658636 \n",
      "round 2262, train_loss: 0.43329921086173845, val_loss: 0.4081028876572406 \n",
      "round 2263, train_loss: 0.43327310703773736, val_loss: 0.40807633962704654 \n",
      "round 2264, train_loss: 0.4332470212884917, val_loss: 0.408049813433591 \n",
      "round 2265, train_loss: 0.43322095359592755, val_loss: 0.40802330905448864 \n",
      "round 2266, train_loss: 0.4331949039419957, val_loss: 0.4079968264673855 \n",
      "round 2267, train_loss: 0.43316887230866885, val_loss: 0.40797036564995554 \n",
      "round 2268, train_loss: 0.4331428586779448, val_loss: 0.4079439265799026 \n",
      "round 2269, train_loss: 0.43311686303184366, val_loss: 0.40791750923495945 \n",
      "round 2270, train_loss: 0.43309088535240986, val_loss: 0.40789111359288777 \n",
      "round 2271, train_loss: 0.43306492562171145, val_loss: 0.40786473963147907 \n",
      "round 2272, train_loss: 0.43303898382183864, val_loss: 0.40783838732855354 \n",
      "round 2273, train_loss: 0.4330130599349063, val_loss: 0.40781205666196035 \n",
      "round 2274, train_loss: 0.43298715394305204, val_loss: 0.4077857476095773 \n",
      "round 2275, train_loss: 0.43296126582843697, val_loss: 0.40775946014931186 \n",
      "round 2276, train_loss: 0.4329353955732451, val_loss: 0.4077331942591001 \n",
      "round 2277, train_loss: 0.4329095431596846, val_loss: 0.40770694991690654 \n",
      "round 2278, train_loss: 0.4328837085699855, val_loss: 0.40768072710072506 \n",
      "round 2279, train_loss: 0.43285789178640216, val_loss: 0.40765452578857825 \n",
      "round 2280, train_loss: 0.43283209279121115, val_loss: 0.4076283459585165 \n",
      "round 2281, train_loss: 0.43280631156671295, val_loss: 0.4076021875886198 \n",
      "round 2282, train_loss: 0.4327805480952302, val_loss: 0.4075760506569968 \n",
      "round 2283, train_loss: 0.4327548023591092, val_loss: 0.40754993514178367 \n",
      "round 2284, train_loss: 0.43272907434071894, val_loss: 0.40752384102114647 \n",
      "round 2285, train_loss: 0.4327033640224514, val_loss: 0.40749776827327855 \n",
      "round 2286, train_loss: 0.43267767138672125, val_loss: 0.4074717168764027 \n",
      "round 2287, train_loss: 0.4326519964159667, val_loss: 0.40744568680876897 \n",
      "round 2288, train_loss: 0.4326263390926473, val_loss: 0.4074196780486565 \n",
      "round 2289, train_loss: 0.4326006993992472, val_loss: 0.40739369057437275 \n",
      "round 2290, train_loss: 0.432575077318272, val_loss: 0.40736772436425267 \n",
      "round 2291, train_loss: 0.43254947283225065, val_loss: 0.4073417793966606 \n",
      "round 2292, train_loss: 0.4325238859237344, val_loss: 0.4073158556499879 \n",
      "round 2293, train_loss: 0.43249831657529736, val_loss: 0.40728995310265476 \n",
      "round 2294, train_loss: 0.432472764769536, val_loss: 0.4072640717331089 \n",
      "round 2295, train_loss: 0.43244723048906925, val_loss: 0.4072382115198265 \n",
      "round 2296, train_loss: 0.432421713716539, val_loss: 0.4072123724413114 \n",
      "round 2297, train_loss: 0.4323962144346096, val_loss: 0.4071865544760952 \n",
      "round 2298, train_loss: 0.4323707326259673, val_loss: 0.4071607576027381 \n",
      "round 2299, train_loss: 0.43234526827332115, val_loss: 0.4071349817998277 \n",
      "round 2300, train_loss: 0.4323198213594026, val_loss: 0.4071092270459788 \n",
      "round 2301, train_loss: 0.4322943918669652, val_loss: 0.4070834933198351 \n",
      "round 2302, train_loss: 0.4322689797787853, val_loss: 0.4070577806000675 \n",
      "round 2303, train_loss: 0.432243585077661, val_loss: 0.40703208886537356 \n",
      "round 2304, train_loss: 0.4322182077464123, val_loss: 0.4070064180944804 \n",
      "round 2305, train_loss: 0.4321928477678825, val_loss: 0.40698076826614116 \n",
      "round 2306, train_loss: 0.43216750512493607, val_loss: 0.4069551393591367 \n",
      "round 2307, train_loss: 0.4321421798004602, val_loss: 0.40692953135227633 \n",
      "round 2308, train_loss: 0.4321168717773638, val_loss: 0.40690394422439535 \n",
      "round 2309, train_loss: 0.43209158103857775, val_loss: 0.40687837795435805 \n",
      "round 2310, train_loss: 0.4320663075670556, val_loss: 0.40685283252105453 \n",
      "round 2311, train_loss: 0.4320410513457719, val_loss: 0.40682730790340343 \n",
      "round 2312, train_loss: 0.43201581235772407, val_loss: 0.4068018040803498 \n",
      "round 2313, train_loss: 0.4319905905859307, val_loss: 0.40677632103086625 \n",
      "round 2314, train_loss: 0.43196538601343276, val_loss: 0.406750858733953 \n",
      "round 2315, train_loss: 0.431940198623293, val_loss: 0.40672541716863597 \n",
      "round 2316, train_loss: 0.43191502839859564, val_loss: 0.4066999963139698 \n",
      "round 2317, train_loss: 0.43188987532244677, val_loss: 0.4066745961490356 \n",
      "round 2318, train_loss: 0.4318647393779743, val_loss: 0.4066492166529409 \n",
      "round 2319, train_loss: 0.43183962054832803, val_loss: 0.40662385780482135 \n",
      "round 2320, train_loss: 0.43181451881667926, val_loss: 0.40659851958383825 \n",
      "round 2321, train_loss: 0.43178943416622056, val_loss: 0.40657320196918034 \n",
      "round 2322, train_loss: 0.4317643665801664, val_loss: 0.40654790494006354 \n",
      "round 2323, train_loss: 0.43173931604175336, val_loss: 0.4065226284757303 \n",
      "round 2324, train_loss: 0.4317142825342386, val_loss: 0.4064973725554492 \n",
      "round 2325, train_loss: 0.4316892660409012, val_loss: 0.40647213715851627 \n",
      "round 2326, train_loss: 0.4316642665450416, val_loss: 0.40644692226425444 \n",
      "round 2327, train_loss: 0.43163928402998186, val_loss: 0.4064217278520121 \n",
      "round 2328, train_loss: 0.43161431847906495, val_loss: 0.4063965539011657 \n",
      "round 2329, train_loss: 0.431589369875656, val_loss: 0.40637140039111647 \n",
      "round 2330, train_loss: 0.43156443820314055, val_loss: 0.406346267301294 \n",
      "round 2331, train_loss: 0.4315395234449259, val_loss: 0.4063211546111527 \n",
      "round 2332, train_loss: 0.43151462558444065, val_loss: 0.4062960623001744 \n",
      "round 2333, train_loss: 0.43148974460513456, val_loss: 0.4062709903478672 \n",
      "round 2334, train_loss: 0.4314648804904783, val_loss: 0.4062459387337651 \n",
      "round 2335, train_loss: 0.43144003322396407, val_loss: 0.40622090743742856 \n",
      "round 2336, train_loss: 0.4314152027891048, val_loss: 0.4061958964384444 \n",
      "round 2337, train_loss: 0.43139038916943473, val_loss: 0.40617090571642567 \n",
      "round 2338, train_loss: 0.4313655923485092, val_loss: 0.4061459352510113 \n",
      "round 2339, train_loss: 0.4313408123099045, val_loss: 0.40612098502186644 \n",
      "round 2340, train_loss: 0.43131604903721804, val_loss: 0.40609605500868234 \n",
      "round 2341, train_loss: 0.4312913025140672, val_loss: 0.40607114519117643 \n",
      "round 2342, train_loss: 0.4312665727240921, val_loss: 0.40604625554909207 \n",
      "round 2343, train_loss: 0.43124185965095185, val_loss: 0.40602138606219845 \n",
      "round 2344, train_loss: 0.43121716327832765, val_loss: 0.40599653671029073 \n",
      "round 2345, train_loss: 0.4311924835899211, val_loss: 0.40597170747319 \n",
      "round 2346, train_loss: 0.43116782056945435, val_loss: 0.40594689833074316 \n",
      "round 2347, train_loss: 0.4311431742006712, val_loss: 0.40592210926282213 \n",
      "round 2348, train_loss: 0.4311185444673346, val_loss: 0.40589734024932655 \n",
      "round 2349, train_loss: 0.43109393135322965, val_loss: 0.40587259127017944 \n",
      "round 2350, train_loss: 0.4310693348421611, val_loss: 0.40584786230533104 \n",
      "round 2351, train_loss: 0.43104475491795496, val_loss: 0.40582315333475666 \n",
      "round 2352, train_loss: 0.43102019156445776, val_loss: 0.4057984643384571 \n",
      "round 2353, train_loss: 0.43099564476553587, val_loss: 0.4057737952964592 \n",
      "round 2354, train_loss: 0.4309711145050771, val_loss: 0.40574914618881486 \n",
      "round 2355, train_loss: 0.4309466007669892, val_loss: 0.40572451699560125 \n",
      "round 2356, train_loss: 0.43092210353520055, val_loss: 0.40569990769692155 \n",
      "round 2357, train_loss: 0.4308976227936596, val_loss: 0.4056753182729038 \n",
      "round 2358, train_loss: 0.4308731585263362, val_loss: 0.4056507487037018 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 2359, train_loss: 0.430848710717219, val_loss: 0.40562619896949476 \n",
      "round 2360, train_loss: 0.43082427935031814, val_loss: 0.40560166905048634 \n",
      "round 2361, train_loss: 0.4307998644096637, val_loss: 0.4055771589269059 \n",
      "round 2362, train_loss: 0.43077546587930626, val_loss: 0.4055526685790087 \n",
      "round 2363, train_loss: 0.43075108374331583, val_loss: 0.4055281979870737 \n",
      "round 2364, train_loss: 0.43072671798578355, val_loss: 0.40550374713140624 \n",
      "round 2365, train_loss: 0.4307023685908201, val_loss: 0.40547931599233605 \n",
      "round 2366, train_loss: 0.43067803554255685, val_loss: 0.405454904550218 \n",
      "round 2367, train_loss: 0.4306537188251444, val_loss: 0.4054305127854323 \n",
      "round 2368, train_loss: 0.43062941842275443, val_loss: 0.4054061406783832 \n",
      "round 2369, train_loss: 0.43060513431957764, val_loss: 0.40538178820950127 \n",
      "round 2370, train_loss: 0.43058086649982574, val_loss: 0.40535745535924056 \n",
      "round 2371, train_loss: 0.43055661494773007, val_loss: 0.40533314210808086 \n",
      "round 2372, train_loss: 0.4305323796475408, val_loss: 0.4053088484365263 \n",
      "round 2373, train_loss: 0.43050816058352953, val_loss: 0.4052845743251059 \n",
      "round 2374, train_loss: 0.4304839577399872, val_loss: 0.4052603197543736 \n",
      "round 2375, train_loss: 0.43045977110122435, val_loss: 0.4052360847049074 \n",
      "round 2376, train_loss: 0.43043560065157194, val_loss: 0.4052118691573106 \n",
      "round 2377, train_loss: 0.4304114463753797, val_loss: 0.40518767309221104 \n",
      "round 2378, train_loss: 0.4303873082570179, val_loss: 0.4051634964902605 \n",
      "round 2379, train_loss: 0.4303631862808763, val_loss: 0.40513933933213614 \n",
      "round 2380, train_loss: 0.43033908043136454, val_loss: 0.4051152015985387 \n",
      "round 2381, train_loss: 0.43031499069291124, val_loss: 0.4050910832701943 \n",
      "round 2382, train_loss: 0.43029091704996586, val_loss: 0.4050669843278526 \n",
      "round 2383, train_loss: 0.43026685948699617, val_loss: 0.40504290475228827 \n",
      "round 2384, train_loss: 0.4302428179884904, val_loss: 0.4050188445243001 \n",
      "round 2385, train_loss: 0.43021879253895573, val_loss: 0.404994803624711 \n",
      "round 2386, train_loss: 0.4301947831229191, val_loss: 0.4049707820343684 \n",
      "round 2387, train_loss: 0.43017078972492684, val_loss: 0.40494677973414395 \n",
      "round 2388, train_loss: 0.430146812329545, val_loss: 0.40492279670493275 \n",
      "round 2389, train_loss: 0.4301228509213589, val_loss: 0.4048988329276555 \n",
      "round 2390, train_loss: 0.43009890548497254, val_loss: 0.40487488838325575 \n",
      "round 2391, train_loss: 0.43007497600501043, val_loss: 0.40485096305270146 \n",
      "round 2392, train_loss: 0.43005106246611563, val_loss: 0.4048270569169846 \n",
      "round 2393, train_loss: 0.43002716485295095, val_loss: 0.40480316995712157 \n",
      "round 2394, train_loss: 0.4300032831501978, val_loss: 0.4047793021541521 \n",
      "round 2395, train_loss: 0.42997941734255735, val_loss: 0.40475545348913994 \n",
      "round 2396, train_loss: 0.42995556741474994, val_loss: 0.4047316239431733 \n",
      "round 2397, train_loss: 0.42993173335151524, val_loss: 0.40470781349736384 \n",
      "round 2398, train_loss: 0.4299079151376108, val_loss: 0.40468402213284654 \n",
      "round 2399, train_loss: 0.42988411275781546, val_loss: 0.40466024983078097 \n",
      "round 2400, train_loss: 0.4298603261969251, val_loss: 0.4046364965723497 \n",
      "round 2401, train_loss: 0.42983655543975563, val_loss: 0.4046127623387602 \n",
      "round 2402, train_loss: 0.4298128004711423, val_loss: 0.4045890471112416 \n",
      "round 2403, train_loss: 0.4297890612759386, val_loss: 0.40456535087104895 \n",
      "round 2404, train_loss: 0.429765337839017, val_loss: 0.40454167359945914 \n",
      "round 2405, train_loss: 0.4297416301452691, val_loss: 0.40451801527777315 \n",
      "round 2406, train_loss: 0.42971793817960574, val_loss: 0.404494375887316 \n",
      "round 2407, train_loss: 0.4296942619269565, val_loss: 0.4044707554094354 \n",
      "round 2408, train_loss: 0.4296706013722689, val_loss: 0.40444715382550284 \n",
      "round 2409, train_loss: 0.42964695650051066, val_loss: 0.40442357111691324 \n",
      "round 2410, train_loss: 0.42962332729666747, val_loss: 0.4044000072650849 \n",
      "round 2411, train_loss: 0.4295997137457438, val_loss: 0.4043764622514598 \n",
      "round 2412, train_loss: 0.4295761158327629, val_loss: 0.404352936057502 \n",
      "round 2413, train_loss: 0.42955253354276707, val_loss: 0.40432942866470023 \n",
      "round 2414, train_loss: 0.4295289668608166, val_loss: 0.40430594005456566 \n",
      "round 2415, train_loss: 0.4295054157719906, val_loss: 0.40428247020863295 \n",
      "round 2416, train_loss: 0.42948188026138756, val_loss: 0.4042590191084596 \n",
      "round 2417, train_loss: 0.4294583603141236, val_loss: 0.404235586735627 \n",
      "round 2418, train_loss: 0.4294348559153336, val_loss: 0.404212173071738 \n",
      "round 2419, train_loss: 0.4294113670501716, val_loss: 0.4041887780984206 \n",
      "round 2420, train_loss: 0.42938789370380914, val_loss: 0.40416540179732396 \n",
      "round 2421, train_loss: 0.429364435861437, val_loss: 0.4041420441501217 \n",
      "round 2422, train_loss: 0.42934099350826377, val_loss: 0.404118705138509 \n",
      "round 2423, train_loss: 0.42931756662951687, val_loss: 0.40409538474420525 \n",
      "round 2424, train_loss: 0.4292941552104422, val_loss: 0.40407208294895175 \n",
      "round 2425, train_loss: 0.42927075923630353, val_loss: 0.40404879973451274 \n",
      "round 2426, train_loss: 0.42924737869238333, val_loss: 0.4040255350826759 \n",
      "round 2427, train_loss: 0.42922401356398215, val_loss: 0.40400228897525114 \n",
      "round 2428, train_loss: 0.42920066383641897, val_loss: 0.4039790613940711 \n",
      "round 2429, train_loss: 0.42917732949503096, val_loss: 0.40395585232099124 \n",
      "round 2430, train_loss: 0.42915401052517327, val_loss: 0.4039326617378895 \n",
      "round 2431, train_loss: 0.4291307069122196, val_loss: 0.40390948962666723 \n",
      "round 2432, train_loss: 0.42910741864156127, val_loss: 0.4038863359692469 \n",
      "round 2433, train_loss: 0.4290841456986084, val_loss: 0.403863200747575 \n",
      "round 2434, train_loss: 0.4290608880687889, val_loss: 0.4038400839436195 \n",
      "round 2435, train_loss: 0.42903764573754843, val_loss: 0.40381698553937145 \n",
      "round 2436, train_loss: 0.42901441869035095, val_loss: 0.40379390551684413 \n",
      "round 2437, train_loss: 0.42899120691267856, val_loss: 0.40377084385807316 \n",
      "round 2438, train_loss: 0.4289680103900312, val_loss: 0.40374780054511683 \n",
      "round 2439, train_loss: 0.42894482910792675, val_loss: 0.4037247755600554 \n",
      "round 2440, train_loss: 0.42892166305190094, val_loss: 0.40370176888499176 \n",
      "round 2441, train_loss: 0.42889851220750747, val_loss: 0.4036787805020509 \n",
      "round 2442, train_loss: 0.428875376560318, val_loss: 0.40365581039338005 \n",
      "round 2443, train_loss: 0.42885225609592215, val_loss: 0.4036328585411488 \n",
      "round 2444, train_loss: 0.42882915079992673, val_loss: 0.4036099249275489 \n",
      "round 2445, train_loss: 0.42880606065795696, val_loss: 0.4035870095347937 \n",
      "round 2446, train_loss: 0.4287829856556557, val_loss: 0.40356411234511935 \n",
      "round 2447, train_loss: 0.4287599257786835, val_loss: 0.40354123334078423 \n",
      "round 2448, train_loss: 0.42873688101271845, val_loss: 0.40351837250406786 \n",
      "round 2449, train_loss: 0.4287138513434563, val_loss: 0.40349552981727227 \n",
      "round 2450, train_loss: 0.42869083675661085, val_loss: 0.4034727052627216 \n",
      "round 2451, train_loss: 0.42866783723791296, val_loss: 0.40344989882276194 \n",
      "round 2452, train_loss: 0.4286448527731117, val_loss: 0.40342711047976093 \n",
      "round 2453, train_loss: 0.4286218833479732, val_loss: 0.40340434021610816 \n",
      "round 2454, train_loss: 0.4285989289482814, val_loss: 0.4033815880142153 \n",
      "round 2455, train_loss: 0.4285759895598376, val_loss: 0.403358853856516 \n",
      "round 2456, train_loss: 0.4285530651684608, val_loss: 0.4033361377254647 \n",
      "round 2457, train_loss: 0.4285301557599871, val_loss: 0.4033134396035391 \n",
      "round 2458, train_loss: 0.4285072613202705, val_loss: 0.40329075947323756 \n",
      "round 2459, train_loss: 0.42848438183518184, val_loss: 0.40326809731707963 \n",
      "round 2460, train_loss: 0.42846151729060994, val_loss: 0.4032454531176076 \n",
      "round 2461, train_loss: 0.4284386676724607, val_loss: 0.40322282685738536 \n",
      "round 2462, train_loss: 0.4284158329666572, val_loss: 0.4032002185189974 \n",
      "round 2463, train_loss: 0.4283930131591397, val_loss: 0.40317762808505064 \n",
      "round 2464, train_loss: 0.4283702082358666, val_loss: 0.40315505553817316 \n",
      "round 2465, train_loss: 0.4283474181828125, val_loss: 0.4031325008610141 \n",
      "round 2466, train_loss: 0.4283246429859695, val_loss: 0.4031099640362453 \n",
      "round 2467, train_loss: 0.4283018826313475, val_loss: 0.40308744504655825 \n",
      "round 2468, train_loss: 0.4282791371049732, val_loss: 0.40306494387466746 \n",
      "round 2469, train_loss: 0.4282564063928895, val_loss: 0.4030424605033077 \n",
      "round 2470, train_loss: 0.42823369048115806, val_loss: 0.4030199949152356 \n",
      "round 2471, train_loss: 0.4282109893558567, val_loss: 0.40299754709322916 \n",
      "round 2472, train_loss: 0.4281883030030803, val_loss: 0.40297511702008676 \n",
      "round 2473, train_loss: 0.42816563140894087, val_loss: 0.40295270467862904 \n",
      "round 2474, train_loss: 0.4281429745595675, val_loss: 0.40293031005169716 \n",
      "round 2475, train_loss: 0.4281203324411064, val_loss: 0.40290793312215384 \n",
      "round 2476, train_loss: 0.42809770503972033, val_loss: 0.40288557387288254 \n",
      "round 2477, train_loss: 0.4280750923415894, val_loss: 0.4028632322867882 \n",
      "round 2478, train_loss: 0.42805249433291037, val_loss: 0.4028409083467964 \n",
      "round 2479, train_loss: 0.42802991099989707, val_loss: 0.4028186020358542 \n",
      "round 2480, train_loss: 0.42800734232878024, val_loss: 0.4027963133369291 \n",
      "round 2481, train_loss: 0.4279847883058069, val_loss: 0.40277404223301017 \n",
      "round 2482, train_loss: 0.4279622489172412, val_loss: 0.4027517887071071 \n",
      "round 2483, train_loss: 0.4279397241493646, val_loss: 0.40272955274225014 \n",
      "round 2484, train_loss: 0.4279172139884744, val_loss: 0.4027073343214908 \n",
      "round 2485, train_loss: 0.42789471842088556, val_loss: 0.4026851334279016 \n",
      "round 2486, train_loss: 0.4278722374329287, val_loss: 0.40266295004457553 \n",
      "round 2487, train_loss: 0.427849771010952, val_loss: 0.40264078415462634 \n",
      "round 2488, train_loss: 0.42782731914131994, val_loss: 0.40261863574118867 \n",
      "round 2489, train_loss: 0.42780488181041343, val_loss: 0.40259650478741815 \n",
      "round 2490, train_loss: 0.4277824590046305, val_loss: 0.4025743912764903 \n",
      "round 2491, train_loss: 0.42776005071038503, val_loss: 0.4025522951916019 \n",
      "round 2492, train_loss: 0.4277376569141083, val_loss: 0.4025302165159697 \n",
      "round 2493, train_loss: 0.4277152776022474, val_loss: 0.4025081552328326 \n",
      "round 2494, train_loss: 0.4276929127612663, val_loss: 0.4024861113254478 \n",
      "round 2495, train_loss: 0.4276705623776454, val_loss: 0.4024640847770951 \n",
      "round 2496, train_loss: 0.4276482264378811, val_loss: 0.40244207557107303 \n",
      "round 2497, train_loss: 0.42762590492848723, val_loss: 0.4024200836907019 \n",
      "round 2498, train_loss: 0.427603597835993, val_loss: 0.40239810911932217 \n",
      "round 2499, train_loss: 0.42758130514694453, val_loss: 0.4023761518402939 \n",
      "round 2500, train_loss: 0.427559026847904, val_loss: 0.4023542118369987 \n",
      "round 2501, train_loss: 0.4275367629254502, val_loss: 0.4023322890928375 \n",
      "round 2502, train_loss: 0.42751451336617813, val_loss: 0.40231038359123206 \n",
      "round 2503, train_loss: 0.42749227815669866, val_loss: 0.40228849531562416 \n",
      "round 2504, train_loss: 0.42747005728363974, val_loss: 0.4022666242494762 \n",
      "round 2505, train_loss: 0.42744785073364516, val_loss: 0.4022447703762706 \n",
      "round 2506, train_loss: 0.4274256584933744, val_loss: 0.40222293367950934 \n",
      "round 2507, train_loss: 0.4274034805495037, val_loss: 0.402201114142716 \n",
      "round 2508, train_loss: 0.4273813168887253, val_loss: 0.40217931174943305 \n",
      "round 2509, train_loss: 0.4273591674977479, val_loss: 0.4021575264832229 \n",
      "round 2510, train_loss: 0.4273370323632953, val_loss: 0.40213575832766935 \n",
      "round 2511, train_loss: 0.4273149114721087, val_loss: 0.40211400726637475 \n",
      "round 2512, train_loss: 0.4272928048109444, val_loss: 0.40209227328296254 \n",
      "round 2513, train_loss: 0.42727071236657477, val_loss: 0.4020705563610757 \n",
      "round 2514, train_loss: 0.427248634125789, val_loss: 0.4020488564843767 \n",
      "round 2515, train_loss: 0.4272265700753914, val_loss: 0.40202717363654894 \n",
      "round 2516, train_loss: 0.4272045202022025, val_loss: 0.40200550780129457 \n",
      "round 2517, train_loss: 0.4271824844930591, val_loss: 0.4019838589623369 \n",
      "round 2518, train_loss: 0.42716046293481336, val_loss: 0.4019622271034179 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 2519, train_loss: 0.42713845551433394, val_loss: 0.40194061220829935 \n",
      "round 2520, train_loss: 0.4271164622185045, val_loss: 0.4019190142607639 \n",
      "round 2521, train_loss: 0.4270944830342254, val_loss: 0.4018974332446129 \n",
      "round 2522, train_loss: 0.4270725179484125, val_loss: 0.40187586914366763 \n",
      "round 2523, train_loss: 0.42705056694799715, val_loss: 0.40185432194176934 \n",
      "round 2524, train_loss: 0.42702863001992697, val_loss: 0.4018327916227787 \n",
      "round 2525, train_loss: 0.4270067071511649, val_loss: 0.40181127817057577 \n",
      "round 2526, train_loss: 0.4269847983286902, val_loss: 0.4017897815690607 \n",
      "round 2527, train_loss: 0.4269629035394968, val_loss: 0.40176830180215295 \n",
      "round 2528, train_loss: 0.4269410227705953, val_loss: 0.40174683885379137 \n",
      "round 2529, train_loss: 0.4269191560090115, val_loss: 0.4017253927079346 \n",
      "round 2530, train_loss: 0.4268973032417869, val_loss: 0.4017039633485604 \n",
      "round 2531, train_loss: 0.4268754644559785, val_loss: 0.4016825507596662 \n",
      "round 2532, train_loss: 0.4268536396386591, val_loss: 0.401661154925269 \n",
      "round 2533, train_loss: 0.4268318287769168, val_loss: 0.4016397758294048 \n",
      "round 2534, train_loss: 0.42681003185785565, val_loss: 0.401618413456129 \n",
      "round 2535, train_loss: 0.42678824886859446, val_loss: 0.4015970677895166 \n",
      "round 2536, train_loss: 0.42676647979626814, val_loss: 0.4015757388136616 \n",
      "round 2537, train_loss: 0.42674472462802715, val_loss: 0.40155442651267764 \n",
      "round 2538, train_loss: 0.42672298335103687, val_loss: 0.4015331308706975 \n",
      "round 2539, train_loss: 0.42670125595247826, val_loss: 0.4015118518718727 \n",
      "round 2540, train_loss: 0.42667954241954836, val_loss: 0.4014905895003741 \n",
      "round 2541, train_loss: 0.42665784273945817, val_loss: 0.40146934374039234 \n",
      "round 2542, train_loss: 0.42663615689943557, val_loss: 0.4014481145761369 \n",
      "round 2543, train_loss: 0.4266144848867229, val_loss: 0.40142690199183567 \n",
      "round 2544, train_loss: 0.42659282668857745, val_loss: 0.4014057059717362 \n",
      "round 2545, train_loss: 0.42657118229227275, val_loss: 0.4013845265001049 \n",
      "round 2546, train_loss: 0.4265495516850972, val_loss: 0.40136336356122776 \n",
      "round 2547, train_loss: 0.4265279348543543, val_loss: 0.40134221713940926 \n",
      "round 2548, train_loss: 0.4265063317873624, val_loss: 0.4013210872189724 \n",
      "round 2549, train_loss: 0.4264847424714559, val_loss: 0.4012999737842599 \n",
      "round 2550, train_loss: 0.4264631668939838, val_loss: 0.4012788768196328 \n",
      "round 2551, train_loss: 0.4264416050423103, val_loss: 0.4012577963094715 \n",
      "round 2552, train_loss: 0.42642005690381485, val_loss: 0.40123673223817485 \n",
      "round 2553, train_loss: 0.42639852246589227, val_loss: 0.40121568459016055 \n",
      "round 2554, train_loss: 0.4263770017159517, val_loss: 0.4011946533498653 \n",
      "round 2555, train_loss: 0.4263554946414174, val_loss: 0.4011736385017445 \n",
      "round 2556, train_loss: 0.4263340012297295, val_loss: 0.4011526400302721 \n",
      "round 2557, train_loss: 0.42631252146834264, val_loss: 0.4011316579199412 \n",
      "round 2558, train_loss: 0.42629105534472644, val_loss: 0.4011106921552629 \n",
      "round 2559, train_loss: 0.42626960284636506, val_loss: 0.401089742720767 \n",
      "round 2560, train_loss: 0.4262481639607587, val_loss: 0.40106880960100283 \n",
      "round 2561, train_loss: 0.4262267386754211, val_loss: 0.40104789278053754 \n",
      "round 2562, train_loss: 0.42620532697788194, val_loss: 0.40102699224395677 \n",
      "round 2563, train_loss: 0.42618392885568557, val_loss: 0.40100610797586517 \n",
      "round 2564, train_loss: 0.4261625442963907, val_loss: 0.4009852399608853 \n",
      "round 2565, train_loss: 0.4261411732875714, val_loss: 0.40096438818365904 \n",
      "round 2566, train_loss: 0.4261198158168163, val_loss: 0.4009435526288459 \n",
      "round 2567, train_loss: 0.4260984718717291, val_loss: 0.4009227332811243 \n",
      "round 2568, train_loss: 0.426077141439928, val_loss: 0.4009019301251908 \n",
      "round 2569, train_loss: 0.4260558245090454, val_loss: 0.40088114314576045 \n",
      "round 2570, train_loss: 0.4260345210667297, val_loss: 0.4008603723275667 \n",
      "round 2571, train_loss: 0.42601323110064293, val_loss: 0.40083961765536125 \n",
      "round 2572, train_loss: 0.4259919545984623, val_loss: 0.400818879113914 \n",
      "round 2573, train_loss: 0.4259706915478795, val_loss: 0.4007981566880137 \n",
      "round 2574, train_loss: 0.42594944193660095, val_loss: 0.40077745036246604 \n",
      "round 2575, train_loss: 0.4259282057523473, val_loss: 0.40075676012209616 \n",
      "round 2576, train_loss: 0.42590698298285434, val_loss: 0.400736085951747 \n",
      "round 2577, train_loss: 0.42588577361587227, val_loss: 0.4007154278362795 \n",
      "round 2578, train_loss: 0.4258645776391658, val_loss: 0.40069478576057305 \n",
      "round 2579, train_loss: 0.4258433950405139, val_loss: 0.4006741597095245 \n",
      "round 2580, train_loss: 0.4258222258077102, val_loss: 0.4006535496680498 \n",
      "round 2581, train_loss: 0.4258010699285632, val_loss: 0.4006329556210817 \n",
      "round 2582, train_loss: 0.4257799273908953, val_loss: 0.400612377553572 \n",
      "round 2583, train_loss: 0.42575879818254353, val_loss: 0.4005918154504903 \n",
      "round 2584, train_loss: 0.4257376822913596, val_loss: 0.4005712692968235 \n",
      "round 2585, train_loss: 0.4257165797052094, val_loss: 0.40055073907757754 \n",
      "round 2586, train_loss: 0.42569549041197274, val_loss: 0.4005302247777753 \n",
      "round 2587, train_loss: 0.42567441439954473, val_loss: 0.4005097263824581 \n",
      "round 2588, train_loss: 0.4256533516558341, val_loss: 0.40048924387668444 \n",
      "round 2589, train_loss: 0.42563230216876397, val_loss: 0.40046877724553187 \n",
      "round 2590, train_loss: 0.42561126592627196, val_loss: 0.4004483264740948 \n",
      "round 2591, train_loss: 0.4255902429163103, val_loss: 0.40042789154748576 \n",
      "round 2592, train_loss: 0.42556923312684447, val_loss: 0.4004074724508345 \n",
      "round 2593, train_loss: 0.425548236545855, val_loss: 0.4003870691692898 \n",
      "round 2594, train_loss: 0.4255272531613364, val_loss: 0.40036668168801653 \n",
      "round 2595, train_loss: 0.42550628296129694, val_loss: 0.4003463099921985 \n",
      "round 2596, train_loss: 0.42548532593376026, val_loss: 0.4003259540670366 \n",
      "round 2597, train_loss: 0.4254643820667627, val_loss: 0.40030561389774927 \n",
      "round 2598, train_loss: 0.4254434513483557, val_loss: 0.4002852894695734 \n",
      "round 2599, train_loss: 0.4254225337666042, val_loss: 0.40026498076776157 \n",
      "round 2600, train_loss: 0.4254016293095878, val_loss: 0.4002446877775862 \n",
      "round 2601, train_loss: 0.4253807379653994, val_loss: 0.40022441048433566 \n",
      "round 2602, train_loss: 0.42535985972214657, val_loss: 0.4002041488733169 \n",
      "round 2603, train_loss: 0.4253389945679511, val_loss: 0.4001839029298531 \n",
      "round 2604, train_loss: 0.4253181424909476, val_loss: 0.40016367263928615 \n",
      "round 2605, train_loss: 0.42529730347928635, val_loss: 0.4001434579869743 \n",
      "round 2606, train_loss: 0.42527647752113, val_loss: 0.400123258958294 \n",
      "round 2607, train_loss: 0.4252556646046564, val_loss: 0.4001030755386387 \n",
      "round 2608, train_loss: 0.4252348647180562, val_loss: 0.4000829077134195 \n",
      "round 2609, train_loss: 0.42521407784953474, val_loss: 0.40006275546806397 \n",
      "round 2610, train_loss: 0.42519330398731087, val_loss: 0.4000426187880183 \n",
      "round 2611, train_loss: 0.42517254311961733, val_loss: 0.40002249765874476 \n",
      "round 2612, train_loss: 0.4251517952347011, val_loss: 0.4000023920657237 \n",
      "round 2613, train_loss: 0.4251310603208223, val_loss: 0.39998230199445195 \n",
      "round 2614, train_loss: 0.42511033836625545, val_loss: 0.39996222743044446 \n",
      "round 2615, train_loss: 0.4250896293592885, val_loss: 0.39994216835923235 \n",
      "round 2616, train_loss: 0.425068933288223, val_loss: 0.3999221247663648 \n",
      "round 2617, train_loss: 0.4250482501413749, val_loss: 0.3999020966374073 \n",
      "round 2618, train_loss: 0.42502757990707307, val_loss: 0.39988208395794284 \n",
      "round 2619, train_loss: 0.4250069225736607, val_loss: 0.399862086713572 \n",
      "round 2620, train_loss: 0.42498627812949397, val_loss: 0.399842104889911 \n",
      "round 2621, train_loss: 0.4249656465629441, val_loss: 0.3998221384725949 \n",
      "round 2622, train_loss: 0.4249450278623938, val_loss: 0.39980218744727414 \n",
      "round 2623, train_loss: 0.42492442201624087, val_loss: 0.39978225179961685 \n",
      "round 2624, train_loss: 0.42490382901289697, val_loss: 0.3997623315153085 \n",
      "round 2625, train_loss: 0.4248832488407862, val_loss: 0.39974242658005055 \n",
      "round 2626, train_loss: 0.42486268148834705, val_loss: 0.3997225369795621 \n",
      "round 2627, train_loss: 0.4248421269440314, val_loss: 0.3997026626995792 \n",
      "round 2628, train_loss: 0.4248215851963042, val_loss: 0.39968280372585363 \n",
      "round 2629, train_loss: 0.4248010562336445, val_loss: 0.39966296004415564 \n",
      "round 2630, train_loss: 0.4247805400445441, val_loss: 0.3996431316402705 \n",
      "round 2631, train_loss: 0.42476003661750916, val_loss: 0.3996233185000023 \n",
      "round 2632, train_loss: 0.42473954594105884, val_loss: 0.39960352060917015 \n",
      "round 2633, train_loss: 0.4247190680037252, val_loss: 0.3995837379536105 \n",
      "round 2634, train_loss: 0.4246986027940548, val_loss: 0.3995639705191768 \n",
      "round 2635, train_loss: 0.4246781503006067, val_loss: 0.3995442182917386 \n",
      "round 2636, train_loss: 0.4246577105119536, val_loss: 0.39952448125718265 \n",
      "round 2637, train_loss: 0.4246372834166812, val_loss: 0.39950475940141206 \n",
      "round 2638, train_loss: 0.42461686900338935, val_loss: 0.39948505271034646 \n",
      "round 2639, train_loss: 0.4245964672606905, val_loss: 0.39946536116992204 \n",
      "round 2640, train_loss: 0.42457607817721055, val_loss: 0.39944568476609216 \n",
      "round 2641, train_loss: 0.42455570174158863, val_loss: 0.39942602348482603 \n",
      "round 2642, train_loss: 0.4245353379424773, val_loss: 0.39940637731210943 \n",
      "round 2643, train_loss: 0.42451498676854205, val_loss: 0.399386746233945 \n",
      "round 2644, train_loss: 0.4244946482084621, val_loss: 0.39936713023635156 \n",
      "round 2645, train_loss: 0.42447432225092924, val_loss: 0.3993475293053643 \n",
      "round 2646, train_loss: 0.4244540088846483, val_loss: 0.3993279434270351 \n",
      "round 2647, train_loss: 0.4244337080983384, val_loss: 0.3993083725874322 \n",
      "round 2648, train_loss: 0.4244134198807304, val_loss: 0.39928881677263994 \n",
      "round 2649, train_loss: 0.42439314422056923, val_loss: 0.3992692759687595 \n",
      "round 2650, train_loss: 0.42437288110661225, val_loss: 0.39924975016190756 \n",
      "round 2651, train_loss: 0.42435263052763095, val_loss: 0.3992302393382177 \n",
      "round 2652, train_loss: 0.424332392472408, val_loss: 0.3992107434838403 \n",
      "round 2653, train_loss: 0.4243121669297414, val_loss: 0.39919126258494037 \n",
      "round 2654, train_loss: 0.42429195388844, val_loss: 0.39917179662770125 \n",
      "round 2655, train_loss: 0.4242717533373276, val_loss: 0.3991523455983202 \n",
      "round 2656, train_loss: 0.42425156526523905, val_loss: 0.39913290948301283 \n",
      "round 2657, train_loss: 0.42423138966102353, val_loss: 0.3991134882680094 \n",
      "round 2658, train_loss: 0.4242112265135431, val_loss: 0.3990940819395571 \n",
      "round 2659, train_loss: 0.424191075811672, val_loss: 0.3990746904839187 \n",
      "round 2660, train_loss: 0.42417093754429797, val_loss: 0.3990553138873732 \n",
      "round 2661, train_loss: 0.42415081170032154, val_loss: 0.39903595213621607 \n",
      "round 2662, train_loss: 0.4241306982686554, val_loss: 0.3990166052167587 \n",
      "round 2663, train_loss: 0.42411059723822636, val_loss: 0.39899727311532784 \n",
      "round 2664, train_loss: 0.4240905085979731, val_loss: 0.39897795581826706 \n",
      "round 2665, train_loss: 0.4240704323368472, val_loss: 0.39895865331193536 \n",
      "round 2666, train_loss: 0.4240503684438137, val_loss: 0.3989393655827078 \n",
      "round 2667, train_loss: 0.4240303169078494, val_loss: 0.39892009261697603 \n",
      "round 2668, train_loss: 0.4240102777179449, val_loss: 0.39890083440114654 \n",
      "round 2669, train_loss: 0.4239902508631025, val_loss: 0.3988815909216422 \n",
      "round 2670, train_loss: 0.4239702363323381, val_loss: 0.39886236216490184 \n",
      "round 2671, train_loss: 0.42395023411467986, val_loss: 0.39884314811738036 \n",
      "round 2672, train_loss: 0.4239302441991688, val_loss: 0.3988239487655475 \n",
      "round 2673, train_loss: 0.4239102665748582, val_loss: 0.3988047640958897 \n",
      "round 2674, train_loss: 0.42389030123081456, val_loss: 0.3987855940949091 \n",
      "round 2675, train_loss: 0.4238703481561166, val_loss: 0.3987664387491233 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 2676, train_loss: 0.42385040733985574, val_loss: 0.3987472980450655 \n",
      "round 2677, train_loss: 0.4238304787711361, val_loss: 0.398728171969285 \n",
      "round 2678, train_loss: 0.42381056243907433, val_loss: 0.3987090605083461 \n",
      "round 2679, train_loss: 0.42379065833279955, val_loss: 0.39868996364882986 \n",
      "round 2680, train_loss: 0.4237707664414534, val_loss: 0.3986708813773323 \n",
      "round 2681, train_loss: 0.4237508867541902, val_loss: 0.3986518136804646 \n",
      "round 2682, train_loss: 0.42373101926017653, val_loss: 0.3986327605448546 \n",
      "round 2683, train_loss: 0.4237111639485918, val_loss: 0.39861372195714484 \n",
      "round 2684, train_loss: 0.42369132080862754, val_loss: 0.39859469790399343 \n",
      "round 2685, train_loss: 0.42367148982948805, val_loss: 0.39857568837207463 \n",
      "round 2686, train_loss: 0.4236516710003896, val_loss: 0.39855669334807803 \n",
      "round 2687, train_loss: 0.42363186431056116, val_loss: 0.39853771281870803 \n",
      "round 2688, train_loss: 0.42361206974924437, val_loss: 0.398518746770685 \n",
      "round 2689, train_loss: 0.42359228730569265, val_loss: 0.39849979519074524 \n",
      "round 2690, train_loss: 0.42357251696917214, val_loss: 0.39848085806563893 \n",
      "round 2691, train_loss: 0.42355275872896153, val_loss: 0.39846193538213365 \n",
      "round 2692, train_loss: 0.42353301257435105, val_loss: 0.39844302712701085 \n",
      "round 2693, train_loss: 0.42351327849464415, val_loss: 0.39842413328706766 \n",
      "round 2694, train_loss: 0.42349355647915576, val_loss: 0.39840525384911707 \n",
      "round 2695, train_loss: 0.4234738465172141, val_loss: 0.39838638879998667 \n",
      "round 2696, train_loss: 0.42345414859815844, val_loss: 0.3983675381265194 \n",
      "round 2697, train_loss: 0.42343446271134116, val_loss: 0.3983487018155745 \n",
      "round 2698, train_loss: 0.4234147888461264, val_loss: 0.3983298798540249 \n",
      "round 2699, train_loss: 0.42339512699189064, val_loss: 0.3983110722287598 \n",
      "round 2700, train_loss: 0.42337547713802276, val_loss: 0.3982922789266831 \n",
      "round 2701, train_loss: 0.42335583927392334, val_loss: 0.398273499934714 \n",
      "round 2702, train_loss: 0.4233362133890056, val_loss: 0.39825473523978716 \n",
      "round 2703, train_loss: 0.4233165994726946, val_loss: 0.398235984828852 \n",
      "round 2704, train_loss: 0.4232969975144274, val_loss: 0.39821724868887304 \n",
      "round 2705, train_loss: 0.4232774075036537, val_loss: 0.39819852680683 \n",
      "round 2706, train_loss: 0.42325782942983436, val_loss: 0.3981798191697176 \n",
      "round 2707, train_loss: 0.4232382632824434, val_loss: 0.39816112576454593 \n",
      "round 2708, train_loss: 0.42321870905096587, val_loss: 0.3981424465783399 \n",
      "round 2709, train_loss: 0.42319916672489954, val_loss: 0.3981237815981387 \n",
      "round 2710, train_loss: 0.42317963629375394, val_loss: 0.39810513081099785 \n",
      "round 2711, train_loss: 0.4231601177470507, val_loss: 0.3980864942039865 \n",
      "round 2712, train_loss: 0.42314061107432294, val_loss: 0.39806787176418956 \n",
      "round 2713, train_loss: 0.4231211162651166, val_loss: 0.39804926347870706 \n",
      "round 2714, train_loss: 0.42310163330898887, val_loss: 0.39803066933465286 \n",
      "round 2715, train_loss: 0.42308216219550887, val_loss: 0.39801208931915705 \n",
      "round 2716, train_loss: 0.4230627029142583, val_loss: 0.3979935234193634 \n",
      "round 2717, train_loss: 0.42304325545482996, val_loss: 0.3979749716224309 \n",
      "round 2718, train_loss: 0.4230238198068288, val_loss: 0.3979564339155338 \n",
      "round 2719, train_loss: 0.423004395959872, val_loss: 0.3979379102858604 \n",
      "round 2720, train_loss: 0.4229849839035882, val_loss: 0.3979194007206141 \n",
      "round 2721, train_loss: 0.42296558362761755, val_loss: 0.3979009052070133 \n",
      "round 2722, train_loss: 0.4229461951216126, val_loss: 0.397882423732291 \n",
      "round 2723, train_loss: 0.42292681837523777, val_loss: 0.39786395628369475 \n",
      "round 2724, train_loss: 0.4229074533781684, val_loss: 0.39784550284848624 \n",
      "round 2725, train_loss: 0.42288810012009276, val_loss: 0.39782706341394325 \n",
      "round 2726, train_loss: 0.42286875859070966, val_loss: 0.397808637967357 \n",
      "round 2727, train_loss: 0.42284942877973036, val_loss: 0.3977902264960336 \n",
      "round 2728, train_loss: 0.4228301106768779, val_loss: 0.3977718289872942 \n",
      "round 2729, train_loss: 0.42281080427188655, val_loss: 0.3977534454284737 \n",
      "round 2730, train_loss: 0.42279150955450273, val_loss: 0.3977350758069222 \n",
      "round 2731, train_loss: 0.4227722265144841, val_loss: 0.39771672011000453 \n",
      "round 2732, train_loss: 0.4227529551415999, val_loss: 0.39769837832509947 \n",
      "round 2733, train_loss: 0.4227336954256319, val_loss: 0.39768005043960053 \n",
      "round 2734, train_loss: 0.4227144473563721, val_loss: 0.39766173644091574 \n",
      "round 2735, train_loss: 0.4226952109236251, val_loss: 0.39764343631646737 \n",
      "round 2736, train_loss: 0.4226759861172069, val_loss: 0.39762515005369237 \n",
      "round 2737, train_loss: 0.42265677292694454, val_loss: 0.397606877640042 \n",
      "round 2738, train_loss: 0.4226375713426776, val_loss: 0.3975886190629823 \n",
      "round 2739, train_loss: 0.4226183813542561, val_loss: 0.397570374309993 \n",
      "round 2740, train_loss: 0.42259920295154185, val_loss: 0.39755214336856837 \n",
      "round 2741, train_loss: 0.4225800361244091, val_loss: 0.39753392622621725 \n",
      "round 2742, train_loss: 0.42256088086274246, val_loss: 0.397515722870463 \n",
      "round 2743, train_loss: 0.4225417371564379, val_loss: 0.39749753328884285 \n",
      "round 2744, train_loss: 0.422522604995404, val_loss: 0.39747935746890833 \n",
      "round 2745, train_loss: 0.4225034843695596, val_loss: 0.3974611953982254 \n",
      "round 2746, train_loss: 0.4224843752688357, val_loss: 0.3974430470643741 \n",
      "round 2747, train_loss: 0.42246527768317443, val_loss: 0.3974249124549489 \n",
      "round 2748, train_loss: 0.42244619160252883, val_loss: 0.3974067915575582 \n",
      "round 2749, train_loss: 0.4224271170168644, val_loss: 0.3973886843598251 \n",
      "round 2750, train_loss: 0.4224080539161572, val_loss: 0.3973705908493859 \n",
      "round 2751, train_loss: 0.4223890022903945, val_loss: 0.39735251101389174 \n",
      "round 2752, train_loss: 0.42236996212957517, val_loss: 0.39733444484100805 \n",
      "round 2753, train_loss: 0.42235093342370983, val_loss: 0.3973163923184136 \n",
      "round 2754, train_loss: 0.4223319161628194, val_loss: 0.3972983534338023 \n",
      "round 2755, train_loss: 0.4223129103369365, val_loss: 0.39728032817488096 \n",
      "round 2756, train_loss: 0.4222939159361061, val_loss: 0.397262316529371 \n",
      "round 2757, train_loss: 0.42227493295038226, val_loss: 0.39724431848500813 \n",
      "round 2758, train_loss: 0.4222559613698322, val_loss: 0.3972263340295414 \n",
      "round 2759, train_loss: 0.42223700118453283, val_loss: 0.39720836315073416 \n",
      "round 2760, train_loss: 0.42221805238457355, val_loss: 0.3971904058363642 \n",
      "round 2761, train_loss: 0.4221991149600541, val_loss: 0.39717246207422224 \n",
      "round 2762, train_loss: 0.422180188901086, val_loss: 0.39715453185211375 \n",
      "round 2763, train_loss: 0.4221612741977911, val_loss: 0.39713661515785786 \n",
      "round 2764, train_loss: 0.4221423708403029, val_loss: 0.3971187119792873 \n",
      "round 2765, train_loss: 0.4221234788187661, val_loss: 0.397100822304249 \n",
      "round 2766, train_loss: 0.4221045981233366, val_loss: 0.3970829461206035 \n",
      "round 2767, train_loss: 0.4220857287441804, val_loss: 0.39706508341622576 \n",
      "round 2768, train_loss: 0.42206687067147564, val_loss: 0.39704723417900345 \n",
      "round 2769, train_loss: 0.42204802389541146, val_loss: 0.39702939839683904 \n",
      "round 2770, train_loss: 0.4220291884061874, val_loss: 0.3970115760576481 \n",
      "round 2771, train_loss: 0.42201036419401444, val_loss: 0.3969937671493605 \n",
      "round 2772, train_loss: 0.4219915512491146, val_loss: 0.39697597165991927 \n",
      "round 2773, train_loss: 0.4219727495617205, val_loss: 0.39695818957728163 \n",
      "round 2774, train_loss: 0.42195395912207573, val_loss: 0.39694042088941806 \n",
      "round 2775, train_loss: 0.4219351799204359, val_loss: 0.39692266558431294 \n",
      "round 2776, train_loss: 0.4219164119470664, val_loss: 0.39690492364996427 \n",
      "round 2777, train_loss: 0.4218976551922433, val_loss: 0.39688719507438397 \n",
      "round 2778, train_loss: 0.42187890964625513, val_loss: 0.39686947984559723 \n",
      "round 2779, train_loss: 0.42186017529940023, val_loss: 0.3968517779516425 \n",
      "round 2780, train_loss: 0.42184145214198754, val_loss: 0.3968340893805726 \n",
      "round 2781, train_loss: 0.42182274016433735, val_loss: 0.3968164141204534 \n",
      "round 2782, train_loss: 0.42180403935678107, val_loss: 0.3967987521593641 \n",
      "round 2783, train_loss: 0.4217853497096605, val_loss: 0.39678110348539825 \n",
      "round 2784, train_loss: 0.4217666712133281, val_loss: 0.3967634680866619 \n",
      "round 2785, train_loss: 0.4217480038581479, val_loss: 0.39674584595127516 \n",
      "round 2786, train_loss: 0.4217293476344937, val_loss: 0.39672823706737176 \n",
      "round 2787, train_loss: 0.4217107025327512, val_loss: 0.39671064142309814 \n",
      "round 2788, train_loss: 0.421692068543316, val_loss: 0.3966930590066149 \n",
      "round 2789, train_loss: 0.4216734456565945, val_loss: 0.39667548980609585 \n",
      "round 2790, train_loss: 0.42165483386300456, val_loss: 0.3966579338097281 \n",
      "round 2791, train_loss: 0.4216362331529737, val_loss: 0.3966403910057116 \n",
      "round 2792, train_loss: 0.421617643516941, val_loss: 0.3966228613822609 \n",
      "round 2793, train_loss: 0.42159906494535615, val_loss: 0.3966053449276028 \n",
      "round 2794, train_loss: 0.4215804974286788, val_loss: 0.3965878416299775 \n",
      "round 2795, train_loss: 0.42156194095738014, val_loss: 0.3965703514776393 \n",
      "round 2796, train_loss: 0.4215433955219414, val_loss: 0.39655287445885484 \n",
      "round 2797, train_loss: 0.4215248611128546, val_loss: 0.3965354105619044 \n",
      "round 2798, train_loss: 0.4215063377206223, val_loss: 0.39651795977508164 \n",
      "round 2799, train_loss: 0.421487825335758, val_loss: 0.39650052208669345 \n",
      "round 2800, train_loss: 0.4214693239487858, val_loss: 0.39648309748505944 \n",
      "round 2801, train_loss: 0.4214508335502398, val_loss: 0.39646568595851295 \n",
      "round 2802, train_loss: 0.4214323541306646, val_loss: 0.39644828749540006 \n",
      "round 2803, train_loss: 0.4214138856806165, val_loss: 0.3964309020840804 \n",
      "round 2804, train_loss: 0.4213954281906609, val_loss: 0.39641352971292654 \n",
      "round 2805, train_loss: 0.42137698165137466, val_loss: 0.39639617037032404 \n",
      "round 2806, train_loss: 0.4213585460533447, val_loss: 0.39637882404467173 \n",
      "round 2807, train_loss: 0.42134012138716864, val_loss: 0.39636149072438104 \n",
      "round 2808, train_loss: 0.4213217076434547, val_loss: 0.3963441703978776 \n",
      "round 2809, train_loss: 0.42130330481282074, val_loss: 0.3963268630535987 \n",
      "round 2810, train_loss: 0.42128491288589615, val_loss: 0.396309568679996 \n",
      "round 2811, train_loss: 0.42126653185331986, val_loss: 0.39629228726553256 \n",
      "round 2812, train_loss: 0.4212481617057421, val_loss: 0.39627501879868576 \n",
      "round 2813, train_loss: 0.42122980243382235, val_loss: 0.3962577632679456 \n",
      "round 2814, train_loss: 0.42121145402823157, val_loss: 0.39624052066181475 \n",
      "round 2815, train_loss: 0.4211931164796503, val_loss: 0.3962232909688088 \n",
      "round 2816, train_loss: 0.4211747897787697, val_loss: 0.39620607417745685 \n",
      "round 2817, train_loss: 0.4211564739162918, val_loss: 0.39618887027630006 \n",
      "round 2818, train_loss: 0.42113816888292793, val_loss: 0.3961716792538931 \n",
      "round 2819, train_loss: 0.4211198746694008, val_loss: 0.39615450109880346 \n",
      "round 2820, train_loss: 0.4211015912664425, val_loss: 0.396137335799611 \n",
      "round 2821, train_loss: 0.4210833186647957, val_loss: 0.3961201833449088 \n",
      "round 2822, train_loss: 0.42106505685521356, val_loss: 0.3961030437233023 \n",
      "round 2823, train_loss: 0.42104680582845955, val_loss: 0.39608591692341066 \n",
      "round 2824, train_loss: 0.4210285655753069, val_loss: 0.3960688029338648 \n",
      "round 2825, train_loss: 0.4210103360865393, val_loss: 0.39605170174330917 \n",
      "round 2826, train_loss: 0.420992117352951, val_loss: 0.3960346133404 \n",
      "round 2827, train_loss: 0.4209739093653459, val_loss: 0.39601753771380727 \n",
      "round 2828, train_loss: 0.4209557121145384, val_loss: 0.39600047485221324 \n",
      "round 2829, train_loss: 0.4209375255913528, val_loss: 0.39598342474431264 \n",
      "round 2830, train_loss: 0.4209193497866239, val_loss: 0.3959663873788129 \n",
      "round 2831, train_loss: 0.4209011846911966, val_loss: 0.3959493627444347 \n",
      "round 2832, train_loss: 0.42088303029592544, val_loss: 0.3959323508299107 \n",
      "round 2833, train_loss: 0.42086488659167587, val_loss: 0.3959153516239861 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 2834, train_loss: 0.42084675356932244, val_loss: 0.3958983651154194 \n",
      "round 2835, train_loss: 0.42082863121975095, val_loss: 0.3958813912929811 \n",
      "round 2836, train_loss: 0.4208105195338564, val_loss: 0.39586443014545414 \n",
      "round 2837, train_loss: 0.42079241850254434, val_loss: 0.3958474816616348 \n",
      "round 2838, train_loss: 0.42077432811672955, val_loss: 0.39583054583033067 \n",
      "round 2839, train_loss: 0.4207562483673381, val_loss: 0.395813622640363 \n",
      "round 2840, train_loss: 0.420738179245305, val_loss: 0.3957967120805651 \n",
      "round 2841, train_loss: 0.42072012074157583, val_loss: 0.39577981413978264 \n",
      "round 2842, train_loss: 0.420702072847106, val_loss: 0.39576292880687375 \n",
      "round 2843, train_loss: 0.42068403555286055, val_loss: 0.395746056070709 \n",
      "round 2844, train_loss: 0.4206660088498153, val_loss: 0.3957291959201718 \n",
      "round 2845, train_loss: 0.4206479927289553, val_loss: 0.39571234834415714 \n",
      "round 2846, train_loss: 0.420629987181276, val_loss: 0.39569551333157327 \n",
      "round 2847, train_loss: 0.420611992197782, val_loss: 0.39567869087134044 \n",
      "round 2848, train_loss: 0.4205940077694889, val_loss: 0.395661880952391 \n",
      "round 2849, train_loss: 0.42057603388742115, val_loss: 0.39564508356367006 \n",
      "round 2850, train_loss: 0.42055807054261396, val_loss: 0.39562829869413474 \n",
      "round 2851, train_loss: 0.4205401177261119, val_loss: 0.3956115263327548 \n",
      "round 2852, train_loss: 0.4205221754289694, val_loss: 0.39559476646851216 \n",
      "round 2853, train_loss: 0.42050424364225103, val_loss: 0.3955780190904004 \n",
      "round 2854, train_loss: 0.42048632235703065, val_loss: 0.39556128418742653 \n",
      "round 2855, train_loss: 0.42046841156439285, val_loss: 0.395544561748609 \n",
      "round 2856, train_loss: 0.42045051125543087, val_loss: 0.3955278517629784 \n",
      "round 2857, train_loss: 0.4204326214212484, val_loss: 0.39551115421957794 \n",
      "round 2858, train_loss: 0.4204147420529589, val_loss: 0.3954944691074628 \n",
      "round 2859, train_loss: 0.42039687314168567, val_loss: 0.39547779641570036 \n",
      "round 2860, train_loss: 0.42037901467856137, val_loss: 0.39546113613337047 \n",
      "round 2861, train_loss: 0.4203611666547285, val_loss: 0.3954444882495644 \n",
      "round 2862, train_loss: 0.42034332906133975, val_loss: 0.3954278527533863 \n",
      "round 2863, train_loss: 0.42032550188955675, val_loss: 0.39541122963395164 \n",
      "round 2864, train_loss: 0.4203076851305513, val_loss: 0.39539461888038907 \n",
      "round 2865, train_loss: 0.42028987877550517, val_loss: 0.39537802048183823 \n",
      "round 2866, train_loss: 0.4202720828156088, val_loss: 0.39536143442745136 \n",
      "round 2867, train_loss: 0.4202542972420633, val_loss: 0.39534486070639246 \n",
      "round 2868, train_loss: 0.4202365220460793, val_loss: 0.3953282993078382 \n",
      "round 2869, train_loss: 0.4202187572188761, val_loss: 0.3953117502209766 \n",
      "round 2870, train_loss: 0.4202010027516837, val_loss: 0.39529521343500723 \n",
      "round 2871, train_loss: 0.42018325863574124, val_loss: 0.3952786889391431 \n",
      "round 2872, train_loss: 0.42016552486229747, val_loss: 0.395262176722608 \n",
      "round 2873, train_loss: 0.42014780142261077, val_loss: 0.39524567677463784 \n",
      "round 2874, train_loss: 0.4201300883079492, val_loss: 0.39522918908448074 \n",
      "round 2875, train_loss: 0.42011238550958985, val_loss: 0.3952127136413969 \n",
      "round 2876, train_loss: 0.42009469301882013, val_loss: 0.39519625043465767 \n",
      "round 2877, train_loss: 0.4200770108269363, val_loss: 0.39517979945354725 \n",
      "round 2878, train_loss: 0.4200593389252445, val_loss: 0.39516336068736035 \n",
      "round 2879, train_loss: 0.42004167730506015, val_loss: 0.39514693412540497 \n",
      "round 2880, train_loss: 0.4200240259577085, val_loss: 0.39513051975700025 \n",
      "round 2881, train_loss: 0.42000638487452385, val_loss: 0.3951141175714769 \n",
      "round 2882, train_loss: 0.4199887540468503, val_loss: 0.395097727558178 \n",
      "round 2883, train_loss: 0.4199711334660409, val_loss: 0.3950813497064584 \n",
      "round 2884, train_loss: 0.41995352312345907, val_loss: 0.39506498400568396 \n",
      "round 2885, train_loss: 0.4199359230104762, val_loss: 0.3950486304452328 \n",
      "round 2886, train_loss: 0.41991833311847493, val_loss: 0.39503228901449505 \n",
      "round 2887, train_loss: 0.4199007534388455, val_loss: 0.39501595970287195 \n",
      "round 2888, train_loss: 0.41988318396298846, val_loss: 0.39499964249977715 \n",
      "round 2889, train_loss: 0.419865624682314, val_loss: 0.3949833373946353 \n",
      "round 2890, train_loss: 0.41984807558824094, val_loss: 0.39496704437688307 \n",
      "round 2891, train_loss: 0.41983053667219805, val_loss: 0.39495076343596874 \n",
      "round 2892, train_loss: 0.419813007925623, val_loss: 0.3949344945613523 \n",
      "round 2893, train_loss: 0.4197954893399627, val_loss: 0.3949182377425048 \n",
      "round 2894, train_loss: 0.41977798090667384, val_loss: 0.3949019929689098 \n",
      "round 2895, train_loss: 0.41976048261722226, val_loss: 0.3948857602300622 \n",
      "round 2896, train_loss: 0.4197429944630829, val_loss: 0.39486953951546794 \n",
      "round 2897, train_loss: 0.41972551643573985, val_loss: 0.3948533308146449 \n",
      "round 2898, train_loss: 0.41970804852668686, val_loss: 0.39483713411712246 \n",
      "round 2899, train_loss: 0.4196905907274269, val_loss: 0.3948209494124415 \n",
      "round 2900, train_loss: 0.41967314302947156, val_loss: 0.3948047766901548 \n",
      "round 2901, train_loss: 0.4196557054243421, val_loss: 0.3947886159398259 \n",
      "round 2902, train_loss: 0.41963827790356956, val_loss: 0.3947724671510303 \n",
      "round 2903, train_loss: 0.41962086045869307, val_loss: 0.39475633031335494 \n",
      "round 2904, train_loss: 0.41960345308126135, val_loss: 0.39474020541639815 \n",
      "round 2905, train_loss: 0.419586055762833, val_loss: 0.3947240924497694 \n",
      "round 2906, train_loss: 0.41956866849497426, val_loss: 0.39470799140309054 \n",
      "round 2907, train_loss: 0.4195512912692626, val_loss: 0.39469190226599354 \n",
      "round 2908, train_loss: 0.41953392407728235, val_loss: 0.3946758250281225 \n",
      "round 2909, train_loss: 0.4195165669106284, val_loss: 0.39465975967913286 \n",
      "round 2910, train_loss: 0.41949921976090476, val_loss: 0.39464370620869127 \n",
      "round 2911, train_loss: 0.41948188261972363, val_loss: 0.3946276646064758 \n",
      "round 2912, train_loss: 0.4194645554787074, val_loss: 0.3946116348621755 \n",
      "round 2913, train_loss: 0.4194472383294867, val_loss: 0.3945956169654916 \n",
      "round 2914, train_loss: 0.41942993116370136, val_loss: 0.3945796109061359 \n",
      "round 2915, train_loss: 0.4194126339730002, val_loss: 0.3945636166738314 \n",
      "round 2916, train_loss: 0.41939534674904205, val_loss: 0.39454763425831296 \n",
      "round 2917, train_loss: 0.4193780694834932, val_loss: 0.3945316636493262 \n",
      "round 2918, train_loss: 0.41936080216802984, val_loss: 0.3945157048366281 \n",
      "round 2919, train_loss: 0.41934354479433744, val_loss: 0.39449975780998703 \n",
      "round 2920, train_loss: 0.41932629735410987, val_loss: 0.39448382255918213 \n",
      "round 2921, train_loss: 0.4193090598390499, val_loss: 0.39446789907400437 \n",
      "round 2922, train_loss: 0.41929183224087, val_loss: 0.3944519873442556 \n",
      "round 2923, train_loss: 0.41927461455129045, val_loss: 0.39443608735974817 \n",
      "round 2924, train_loss: 0.41925740676204176, val_loss: 0.39442019911030696 \n",
      "round 2925, train_loss: 0.41924020886486246, val_loss: 0.3944043225857668 \n",
      "round 2926, train_loss: 0.41922302085150015, val_loss: 0.3943884577759742 \n",
      "round 2927, train_loss: 0.4192058427137117, val_loss: 0.39437260467078655 \n",
      "round 2928, train_loss: 0.4191886744432628, val_loss: 0.39435676326007224 \n",
      "round 2929, train_loss: 0.41917151603192704, val_loss: 0.3943409335337114 \n",
      "round 2930, train_loss: 0.4191543674714886, val_loss: 0.3943251154815941 \n",
      "round 2931, train_loss: 0.4191372287537391, val_loss: 0.3943093090936223 \n",
      "round 2932, train_loss: 0.41912009987047966, val_loss: 0.394293514359709 \n",
      "round 2933, train_loss: 0.41910298081351977, val_loss: 0.3942777312697776 \n",
      "round 2934, train_loss: 0.4190858715746784, val_loss: 0.394261959813763 \n",
      "round 2935, train_loss: 0.4190687721457828, val_loss: 0.39424619998161087 \n",
      "round 2936, train_loss: 0.41905168251866937, val_loss: 0.394230451763278 \n",
      "round 2937, train_loss: 0.4190346026851829, val_loss: 0.39421471514873196 \n",
      "round 2938, train_loss: 0.4190175326371768, val_loss: 0.3941989901279514 \n",
      "round 2939, train_loss: 0.41900047236651433, val_loss: 0.3941832766909259 \n",
      "round 2940, train_loss: 0.4189834218650662, val_loss: 0.3941675748276559 \n",
      "round 2941, train_loss: 0.41896638112471296, val_loss: 0.3941518845281527 \n",
      "round 2942, train_loss: 0.4189493501373428, val_loss: 0.39413620578243824 \n",
      "round 2943, train_loss: 0.41893232889485343, val_loss: 0.3941205385805462 \n",
      "round 2944, train_loss: 0.41891531738915094, val_loss: 0.3941048829125196 \n",
      "round 2945, train_loss: 0.4188983156121503, val_loss: 0.39408923876841395 \n",
      "round 2946, train_loss: 0.41888132355577495, val_loss: 0.39407360613829456 \n",
      "round 2947, train_loss: 0.41886434121195676, val_loss: 0.3940579850122382 \n",
      "round 2948, train_loss: 0.4188473685726372, val_loss: 0.3940423753803314 \n",
      "round 2949, train_loss: 0.41883040562976526, val_loss: 0.39402677723267243 \n",
      "round 2950, train_loss: 0.4188134523752994, val_loss: 0.39401119055937023 \n",
      "round 2951, train_loss: 0.4187965088012062, val_loss: 0.3939956153505439 \n",
      "round 2952, train_loss: 0.4187795748994609, val_loss: 0.39398005159632393 \n",
      "round 2953, train_loss: 0.41876265066204776, val_loss: 0.3939644992868513 \n",
      "round 2954, train_loss: 0.41874573608095883, val_loss: 0.3939489584122774 \n",
      "round 2955, train_loss: 0.41872883114819603, val_loss: 0.3939334289627647 \n",
      "round 2956, train_loss: 0.41871193585576816, val_loss: 0.3939179109284861 \n",
      "round 2957, train_loss: 0.41869505019569403, val_loss: 0.39390240429962525 \n",
      "round 2958, train_loss: 0.4186781741600002, val_loss: 0.39388690906637697 \n",
      "round 2959, train_loss: 0.418661307740722, val_loss: 0.39387142521894575 \n",
      "round 2960, train_loss: 0.41864445092990327, val_loss: 0.39385595274754714 \n",
      "round 2961, train_loss: 0.41862760371959656, val_loss: 0.3938404916424076 \n",
      "round 2962, train_loss: 0.41861076610186226, val_loss: 0.3938250418937641 \n",
      "round 2963, train_loss: 0.41859393806877015, val_loss: 0.3938096034918635 \n",
      "round 2964, train_loss: 0.4185771196123978, val_loss: 0.39379417642696396 \n",
      "round 2965, train_loss: 0.41856031072483124, val_loss: 0.39377876068933426 \n",
      "round 2966, train_loss: 0.41854351139816565, val_loss: 0.3937633562692528 \n",
      "round 2967, train_loss: 0.4185267216245039, val_loss: 0.39374796315700966 \n",
      "round 2968, train_loss: 0.41850994139595743, val_loss: 0.3937325813429047 \n",
      "round 2969, train_loss: 0.41849317070464664, val_loss: 0.39371721081724853 \n",
      "round 2970, train_loss: 0.4184764095426995, val_loss: 0.39370185157036225 \n",
      "round 2971, train_loss: 0.4184596579022531, val_loss: 0.39368650359257745 \n",
      "round 2972, train_loss: 0.4184429157754525, val_loss: 0.3936711668742355 \n",
      "round 2973, train_loss: 0.4184261831544515, val_loss: 0.39365584140568954 \n",
      "round 2974, train_loss: 0.4184094600314117, val_loss: 0.393640527177302 \n",
      "round 2975, train_loss: 0.4183927463985036, val_loss: 0.39362522417944623 \n",
      "round 2976, train_loss: 0.4183760422479055, val_loss: 0.39360993240250597 \n",
      "round 2977, train_loss: 0.41835934757180476, val_loss: 0.3935946518368754 \n",
      "round 2978, train_loss: 0.4183426623623964, val_loss: 0.39357938247295843 \n",
      "round 2979, train_loss: 0.41832598661188386, val_loss: 0.39356412430117 \n",
      "round 2980, train_loss: 0.4183093203124793, val_loss: 0.3935488773119353 \n",
      "round 2981, train_loss: 0.4182926634564027, val_loss: 0.3935336414956896 \n",
      "round 2982, train_loss: 0.4182760160358827, val_loss: 0.3935184168428791 \n",
      "round 2983, train_loss: 0.4182593780431556, val_loss: 0.39350320334395944 \n",
      "round 2984, train_loss: 0.41824274947046686, val_loss: 0.3934880009893969 \n",
      "round 2985, train_loss: 0.41822613031006906, val_loss: 0.3934728097696682 \n",
      "round 2986, train_loss: 0.4182095205542242, val_loss: 0.3934576296752607 \n",
      "round 2987, train_loss: 0.41819292019520143, val_loss: 0.3934424606966708 \n",
      "round 2988, train_loss: 0.4181763292252792, val_loss: 0.39342730282440624 \n",
      "round 2989, train_loss: 0.41815974763674285, val_loss: 0.39341215604898455 \n",
      "round 2990, train_loss: 0.4181431754218871, val_loss: 0.3933970203609335 \n",
      "round 2991, train_loss: 0.4181266125730142, val_loss: 0.3933818957507909 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 2992, train_loss: 0.4181100590824348, val_loss: 0.39336678220910554 \n",
      "round 2993, train_loss: 0.4180935149424675, val_loss: 0.39335167972643514 \n",
      "round 2994, train_loss: 0.41807698014543954, val_loss: 0.3933365882933481 \n",
      "round 2995, train_loss: 0.41806045468368536, val_loss: 0.3933215079004241 \n",
      "round 2996, train_loss: 0.41804393854954847, val_loss: 0.3933064385382503 \n",
      "round 2997, train_loss: 0.4180274317353802, val_loss: 0.3932913801974271 \n",
      "round 2998, train_loss: 0.4180109342335399, val_loss: 0.393276332868562 \n",
      "round 2999, train_loss: 0.4179944460363946, val_loss: 0.39326129654227565 \n",
      "round 3000, train_loss: 0.41797796713632046, val_loss: 0.39324627120919603 \n",
      "round 3001, train_loss: 0.41796149752570055, val_loss: 0.3932312568599629 \n",
      "round 3002, train_loss: 0.417945037196927, val_loss: 0.3932162534852252 \n",
      "round 3003, train_loss: 0.4179285861423987, val_loss: 0.39320126107564224 \n",
      "round 3004, train_loss: 0.41791214435452456, val_loss: 0.39318627962188346 \n",
      "round 3005, train_loss: 0.41789571182571955, val_loss: 0.3931713091146284 \n",
      "round 3006, train_loss: 0.4178792885484077, val_loss: 0.3931563495445657 \n",
      "round 3007, train_loss: 0.41786287451502074, val_loss: 0.39314140090239547 \n",
      "round 3008, train_loss: 0.41784646971799844, val_loss: 0.3931264631788262 \n",
      "round 3009, train_loss: 0.41783007414978895, val_loss: 0.3931115363645775 \n",
      "round 3010, train_loss: 0.4178136878028477, val_loss: 0.39309662045037874 \n",
      "round 3011, train_loss: 0.4177973106696384, val_loss: 0.3930817154269685 \n",
      "round 3012, train_loss: 0.4177809427426331, val_loss: 0.39306682128509624 \n",
      "round 3013, train_loss: 0.4177645840143107, val_loss: 0.39305193801552096 \n",
      "round 3014, train_loss: 0.4177482344771597, val_loss: 0.3930370656090106 \n",
      "round 3015, train_loss: 0.4177318941236748, val_loss: 0.3930222040563447 \n",
      "round 3016, train_loss: 0.4177155629463598, val_loss: 0.3930073533483118 \n",
      "round 3017, train_loss: 0.4176992409377261, val_loss: 0.3929925134757096 \n",
      "round 3018, train_loss: 0.41768292809029267, val_loss: 0.3929776844293466 \n",
      "round 3019, train_loss: 0.41766662439658647, val_loss: 0.3929628662000415 \n",
      "round 3020, train_loss: 0.4176503298491428, val_loss: 0.3929480587786215 \n",
      "round 3021, train_loss: 0.4176340444405042, val_loss: 0.39293326215592445 \n",
      "round 3022, train_loss: 0.4176177681632217, val_loss: 0.3929184763227979 \n",
      "round 3023, train_loss: 0.4176015010098534, val_loss: 0.392903701270099 \n",
      "round 3024, train_loss: 0.4175852429729659, val_loss: 0.3928889369886946 \n",
      "round 3025, train_loss: 0.41756899404513337, val_loss: 0.39287418346946157 \n",
      "round 3026, train_loss: 0.41755275421893767, val_loss: 0.3928594407032867 \n",
      "round 3027, train_loss: 0.41753652348696874, val_loss: 0.39284470868106586 \n",
      "round 3028, train_loss: 0.4175203018418238, val_loss: 0.39282998739370495 \n",
      "round 3029, train_loss: 0.4175040892761085, val_loss: 0.39281527683211975 \n",
      "round 3030, train_loss: 0.4174878857824362, val_loss: 0.3928005769872354 \n",
      "round 3031, train_loss: 0.4174716913534271, val_loss: 0.392785887849987 \n",
      "round 3032, train_loss: 0.41745550598171033, val_loss: 0.3927712094113192 \n",
      "round 3033, train_loss: 0.4174393296599223, val_loss: 0.39275654166218604 \n",
      "round 3034, train_loss: 0.4174231623807067, val_loss: 0.3927418845935519 \n",
      "round 3035, train_loss: 0.4174070041367157, val_loss: 0.3927272381963901 \n",
      "round 3036, train_loss: 0.417390854920609, val_loss: 0.39271260246168344 \n",
      "round 3037, train_loss: 0.4173747147250535, val_loss: 0.3926979773804253 \n",
      "round 3038, train_loss: 0.41735858354272426, val_loss: 0.39268336294361766 \n",
      "round 3039, train_loss: 0.4173424613663036, val_loss: 0.39266875914227195 \n",
      "round 3040, train_loss: 0.41732634818848224, val_loss: 0.3926541659674108 \n",
      "round 3041, train_loss: 0.41731024400195776, val_loss: 0.3926395834100643 \n",
      "round 3042, train_loss: 0.41729414879943616, val_loss: 0.39262501146127343 \n",
      "round 3043, train_loss: 0.41727806257363026, val_loss: 0.392610450112088 \n",
      "round 3044, train_loss: 0.4172619853172611, val_loss: 0.3925958993535676 \n",
      "round 3045, train_loss: 0.41724591702305724, val_loss: 0.39258135917678155 \n",
      "round 3046, train_loss: 0.41722985768375453, val_loss: 0.39256682957280825 \n",
      "round 3047, train_loss: 0.4172138072920967, val_loss: 0.3925523105327357 \n",
      "round 3048, train_loss: 0.41719776584083534, val_loss: 0.3925378020476614 \n",
      "round 3049, train_loss: 0.4171817333227288, val_loss: 0.3925233041086925 \n",
      "round 3050, train_loss: 0.41716570973054423, val_loss: 0.3925088167069454 \n",
      "round 3051, train_loss: 0.41714969505705507, val_loss: 0.3924943398335455 \n",
      "round 3052, train_loss: 0.4171336892950429, val_loss: 0.3924798734796283 \n",
      "round 3053, train_loss: 0.417117692437297, val_loss: 0.3924654176363385 \n",
      "round 3054, train_loss: 0.41710170447661404, val_loss: 0.39245097229483006 \n",
      "round 3055, train_loss: 0.4170857254057978, val_loss: 0.3924365374462661 \n",
      "round 3056, train_loss: 0.4170697552176603, val_loss: 0.39242211308181973 \n",
      "round 3057, train_loss: 0.41705379390502073, val_loss: 0.392407699192673 \n",
      "round 3058, train_loss: 0.4170378414607056, val_loss: 0.3923932957700171 \n",
      "round 3059, train_loss: 0.41702189787754884, val_loss: 0.3923789028050528 \n",
      "round 3060, train_loss: 0.41700596314839244, val_loss: 0.3923645202889906 \n",
      "round 3061, train_loss: 0.4169900372660854, val_loss: 0.3923501482130493 \n",
      "round 3062, train_loss: 0.4169741202234841, val_loss: 0.39233578656845813 \n",
      "round 3063, train_loss: 0.4169582120134526, val_loss: 0.3923214353464547 \n",
      "round 3064, train_loss: 0.4169423126288622, val_loss: 0.39230709453828627 \n",
      "round 3065, train_loss: 0.416926422062592, val_loss: 0.39229276413520914 \n",
      "round 3066, train_loss: 0.41691054030752794, val_loss: 0.39227844412848967 \n",
      "round 3067, train_loss: 0.4168946673565641, val_loss: 0.3922641345094022 \n",
      "round 3068, train_loss: 0.416878803202601, val_loss: 0.39224983526923074 \n",
      "round 3069, train_loss: 0.4168629478385478, val_loss: 0.392235546399269 \n",
      "round 3070, train_loss: 0.41684710125731983, val_loss: 0.39222126789081974 \n",
      "round 3071, train_loss: 0.4168312634518402, val_loss: 0.3922069997351944 \n",
      "round 3072, train_loss: 0.4168154344150394, val_loss: 0.39219274192371373 \n",
      "round 3073, train_loss: 0.4167996141398563, val_loss: 0.39217849444770814 \n",
      "round 3074, train_loss: 0.41678380261923514, val_loss: 0.3921642572985168 \n",
      "round 3075, train_loss: 0.4167679998461287, val_loss: 0.39215003046748803 \n",
      "round 3076, train_loss: 0.416752205813497, val_loss: 0.3921358139459794 \n",
      "round 3077, train_loss: 0.4167364205143074, val_loss: 0.39212160772535704 \n",
      "round 3078, train_loss: 0.4167206439415341, val_loss: 0.39210741179699726 \n",
      "round 3079, train_loss: 0.4167048760881592, val_loss: 0.39209322615228437 \n",
      "round 3080, train_loss: 0.4166891169471716, val_loss: 0.39207905078261257 \n",
      "round 3081, train_loss: 0.4166733665115676, val_loss: 0.3920648856793846 \n",
      "round 3082, train_loss: 0.4166576247743513, val_loss: 0.3920507308340121 \n",
      "round 3083, train_loss: 0.4166418917285328, val_loss: 0.392036586237917 \n",
      "round 3084, train_loss: 0.4166261673671313, val_loss: 0.39202245188252854 \n",
      "round 3085, train_loss: 0.4166104516831711, val_loss: 0.39200832775928596 \n",
      "round 3086, train_loss: 0.41659474466968544, val_loss: 0.3919942138596375 \n",
      "round 3087, train_loss: 0.41657904631971404, val_loss: 0.39198011017504014 \n",
      "round 3088, train_loss: 0.41656335662630395, val_loss: 0.3919660166969599 \n",
      "round 3089, train_loss: 0.4165476755825091, val_loss: 0.39195193341687173 \n",
      "round 3090, train_loss: 0.41653200318139133, val_loss: 0.3919378603262598 \n",
      "round 3091, train_loss: 0.416516339416019, val_loss: 0.3919237974166167 \n",
      "round 3092, train_loss: 0.4165006842794683, val_loss: 0.3919097446794449 \n",
      "round 3093, train_loss: 0.4164850377648214, val_loss: 0.3918957021062543 \n",
      "round 3094, train_loss: 0.416469399865169, val_loss: 0.3918816696885655 \n",
      "round 3095, train_loss: 0.4164537705736083, val_loss: 0.39186764741790664 \n",
      "round 3096, train_loss: 0.4164381498832434, val_loss: 0.3918536352858152 \n",
      "round 3097, train_loss: 0.4164225377871859, val_loss: 0.39183963328383775 \n",
      "round 3098, train_loss: 0.4164069342785547, val_loss: 0.3918256414035296 \n",
      "round 3099, train_loss: 0.4163913393504754, val_loss: 0.3918116596364544 \n",
      "round 3100, train_loss: 0.4163757529960805, val_loss: 0.3917976879741855 \n",
      "round 3101, train_loss: 0.41636017520851043, val_loss: 0.3917837264083045 \n",
      "round 3102, train_loss: 0.41634460598091183, val_loss: 0.3917697749304023 \n",
      "round 3103, train_loss: 0.41632904530643894, val_loss: 0.3917558335320779 \n",
      "round 3104, train_loss: 0.41631349317825284, val_loss: 0.3917419022049398 \n",
      "round 3105, train_loss: 0.4162979495895219, val_loss: 0.39172798094060507 \n",
      "round 3106, train_loss: 0.4162824145334211, val_loss: 0.3917140697306991 \n",
      "round 3107, train_loss: 0.41626688800313305, val_loss: 0.39170016856685685 \n",
      "round 3108, train_loss: 0.4162513699918463, val_loss: 0.39168627744072126 \n",
      "round 3109, train_loss: 0.41623586049275835, val_loss: 0.3916723963439447 \n",
      "round 3110, train_loss: 0.4162203594990717, val_loss: 0.3916585252681879 \n",
      "round 3111, train_loss: 0.41620486700399695, val_loss: 0.39164466420512034 \n",
      "round 3112, train_loss: 0.41618938300075137, val_loss: 0.3916308131464202 \n",
      "round 3113, train_loss: 0.4161739074825594, val_loss: 0.3916169720837744 \n",
      "round 3114, train_loss: 0.41615844044265216, val_loss: 0.39160314100887855 \n",
      "round 3115, train_loss: 0.416142981874268, val_loss: 0.3915893199134367 \n",
      "round 3116, train_loss: 0.4161275317706521, val_loss: 0.39157550878916203 \n",
      "round 3117, train_loss: 0.4161120901250567, val_loss: 0.3915617076277762 \n",
      "round 3118, train_loss: 0.4160966569307407, val_loss: 0.39154791642100933 \n",
      "round 3119, train_loss: 0.41608123218097015, val_loss: 0.39153413516060054 \n",
      "round 3120, train_loss: 0.4160658158690182, val_loss: 0.3915203638382972 \n",
      "round 3121, train_loss: 0.41605040798816484, val_loss: 0.39150660244585517 \n",
      "round 3122, train_loss: 0.4160350085316964, val_loss: 0.39149285097503916 \n",
      "round 3123, train_loss: 0.41601961749290656, val_loss: 0.3914791094176228 \n",
      "round 3124, train_loss: 0.41600423486509636, val_loss: 0.39146537776538776 \n",
      "round 3125, train_loss: 0.4159888606415727, val_loss: 0.39145165601012466 \n",
      "round 3126, train_loss: 0.4159734948156498, val_loss: 0.39143794414363237 \n",
      "round 3127, train_loss: 0.4159581373806495, val_loss: 0.39142424215771854 \n",
      "round 3128, train_loss: 0.41594278832989934, val_loss: 0.3914105500441987 \n",
      "round 3129, train_loss: 0.4159274476567342, val_loss: 0.39139686779489846 \n",
      "round 3130, train_loss: 0.41591211535449574, val_loss: 0.39138319540165 \n",
      "round 3131, train_loss: 0.4158967914165324, val_loss: 0.39136953285629533 \n",
      "round 3132, train_loss: 0.41588147583619967, val_loss: 0.3913558801506846 \n",
      "round 3133, train_loss: 0.4158661686068595, val_loss: 0.3913422372766762 \n",
      "round 3134, train_loss: 0.4158508697218812, val_loss: 0.39132860422613736 \n",
      "round 3135, train_loss: 0.4158355791746398, val_loss: 0.39131498099094375 \n",
      "round 3136, train_loss: 0.4158202969585188, val_loss: 0.39130136756297884 \n",
      "round 3137, train_loss: 0.41580502306690625, val_loss: 0.3912877639341354 \n",
      "round 3138, train_loss: 0.4157897574931991, val_loss: 0.391274170096314 \n",
      "round 3139, train_loss: 0.4157745002307997, val_loss: 0.39126058604142416 \n",
      "round 3140, train_loss: 0.41575925127311797, val_loss: 0.3912470117613834 \n",
      "round 3141, train_loss: 0.4157440106135699, val_loss: 0.39123344724811765 \n",
      "round 3142, train_loss: 0.4157287782455783, val_loss: 0.39121989249356154 \n",
      "round 3143, train_loss: 0.4157135541625737, val_loss: 0.39120634748965766 \n",
      "round 3144, train_loss: 0.4156983383579917, val_loss: 0.39119281222835717 \n",
      "round 3145, train_loss: 0.4156831308252758, val_loss: 0.3911792867016196 \n",
      "round 3146, train_loss: 0.4156679315578758, val_loss: 0.3911657709014129 \n",
      "round 3147, train_loss: 0.41565274054924833, val_loss: 0.39115226481971305 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 3148, train_loss: 0.4156375577928566, val_loss: 0.391138768448505 \n",
      "round 3149, train_loss: 0.4156223832821703, val_loss: 0.39112528177978106 \n",
      "round 3150, train_loss: 0.41560721701066644, val_loss: 0.39111180480554236 \n",
      "round 3151, train_loss: 0.4155920589718276, val_loss: 0.3910983375177985 \n",
      "round 3152, train_loss: 0.41557690915914425, val_loss: 0.3910848799085671 \n",
      "round 3153, train_loss: 0.4155617675661124, val_loss: 0.39107143196987393 \n",
      "round 3154, train_loss: 0.4155466341862355, val_loss: 0.39105799369375355 \n",
      "round 3155, train_loss: 0.41553150901302305, val_loss: 0.39104456507224783 \n",
      "round 3156, train_loss: 0.4155163920399915, val_loss: 0.39103114609740813 \n",
      "round 3157, train_loss: 0.4155012832606638, val_loss: 0.3910177367612927 \n",
      "round 3158, train_loss: 0.41548618266856974, val_loss: 0.3910043370559691 \n",
      "round 3159, train_loss: 0.4154710902572451, val_loss: 0.39099094697351244 \n",
      "round 3160, train_loss: 0.41545600602023275, val_loss: 0.39097756650600607 \n",
      "round 3161, train_loss: 0.4154409299510821, val_loss: 0.39096419564554197 \n",
      "round 3162, train_loss: 0.41542586204334864, val_loss: 0.39095083438422024 \n",
      "round 3163, train_loss: 0.4154108022905953, val_loss: 0.3909374827141483 \n",
      "round 3164, train_loss: 0.4153957506863908, val_loss: 0.3909241406274425 \n",
      "round 3165, train_loss: 0.4153807072243105, val_loss: 0.39091080811622736 \n",
      "round 3166, train_loss: 0.4153656718979369, val_loss: 0.39089748517263534 \n",
      "round 3167, train_loss: 0.41535064470085786, val_loss: 0.3908841717888067 \n",
      "round 3168, train_loss: 0.41533562562666876, val_loss: 0.3908708679568904 \n",
      "round 3169, train_loss: 0.4153206146689716, val_loss: 0.39085757366904333 \n",
      "round 3170, train_loss: 0.4153056118213739, val_loss: 0.39084428891742984 \n",
      "round 3171, train_loss: 0.4152906170774901, val_loss: 0.39083101369422363 \n",
      "round 3172, train_loss: 0.4152756304309419, val_loss: 0.39081774799160524 \n",
      "round 3173, train_loss: 0.415260651875356, val_loss: 0.3908044918017637 \n",
      "round 3174, train_loss: 0.41524568140436724, val_loss: 0.3907912451168963 \n",
      "round 3175, train_loss: 0.4152307190116154, val_loss: 0.3907780079292085 \n",
      "round 3176, train_loss: 0.4152157646907478, val_loss: 0.39076478023091316 \n",
      "round 3177, train_loss: 0.41520081843541723, val_loss: 0.39075156201423134 \n",
      "round 3178, train_loss: 0.4151858802392839, val_loss: 0.3907383532713928 \n",
      "round 3179, train_loss: 0.41517095009601396, val_loss: 0.39072515399463426 \n",
      "round 3180, train_loss: 0.41515602799928, val_loss: 0.3907119641762014 \n",
      "round 3181, train_loss: 0.41514111394276054, val_loss: 0.39069878380834705 \n",
      "round 3182, train_loss: 0.4151262079201416, val_loss: 0.39068561288333264 \n",
      "round 3183, train_loss: 0.41511130992511475, val_loss: 0.3906724513934272 \n",
      "round 3184, train_loss: 0.4150964199513783, val_loss: 0.39065929933090776 \n",
      "round 3185, train_loss: 0.4150815379926366, val_loss: 0.3906461566880595 \n",
      "round 3186, train_loss: 0.41506666404260073, val_loss: 0.39063302345717554 \n",
      "round 3187, train_loss: 0.4150517980949876, val_loss: 0.39061989963055593 \n",
      "round 3188, train_loss: 0.4150369401435215, val_loss: 0.3906067852005101 \n",
      "round 3189, train_loss: 0.415022090181932, val_loss: 0.39059368015935475 \n",
      "round 3190, train_loss: 0.41500724820395557, val_loss: 0.3905805844994145 \n",
      "round 3191, train_loss: 0.4149924142033347, val_loss: 0.3905674982130214 \n",
      "round 3192, train_loss: 0.41497758817381836, val_loss: 0.390554421292516 \n",
      "round 3193, train_loss: 0.4149627701091622, val_loss: 0.3905413537302468 \n",
      "round 3194, train_loss: 0.41494796000312745, val_loss: 0.39052829551856905 \n",
      "round 3195, train_loss: 0.414933157849482, val_loss: 0.39051524664984705 \n",
      "round 3196, train_loss: 0.41491836364199997, val_loss: 0.39050220711645295 \n",
      "round 3197, train_loss: 0.4149035773744622, val_loss: 0.3904891769107654 \n",
      "round 3198, train_loss: 0.4148887990406553, val_loss: 0.39047615602517255 \n",
      "round 3199, train_loss: 0.414874028634372, val_loss: 0.3904631444520687 \n",
      "round 3200, train_loss: 0.41485926614941177, val_loss: 0.39045014218385743 \n",
      "round 3201, train_loss: 0.41484451157958, val_loss: 0.39043714921294914 \n",
      "round 3202, train_loss: 0.4148297649186887, val_loss: 0.39042416553176246 \n",
      "round 3203, train_loss: 0.4148150261605555, val_loss: 0.3904111911327234 \n",
      "round 3204, train_loss: 0.41480029529900486, val_loss: 0.3903982260082661 \n",
      "round 3205, train_loss: 0.41478557232786717, val_loss: 0.39038527015083213 \n",
      "round 3206, train_loss: 0.41477085724097895, val_loss: 0.3903723235528714 \n",
      "round 3207, train_loss: 0.4147561500321832, val_loss: 0.39035938620684063 \n",
      "round 3208, train_loss: 0.4147414506953288, val_loss: 0.3903464581052048 \n",
      "round 3209, train_loss: 0.41472675922427127, val_loss: 0.3903335392404364 \n",
      "round 3210, train_loss: 0.4147120756128717, val_loss: 0.39032062960501634 \n",
      "round 3211, train_loss: 0.41469739985499793, val_loss: 0.3903077291914317 \n",
      "round 3212, train_loss: 0.4146827319445232, val_loss: 0.39029483799217857 \n",
      "round 3213, train_loss: 0.4146680718753283, val_loss: 0.3902819559997605 \n",
      "round 3214, train_loss: 0.4146534196412984, val_loss: 0.3902690832066883 \n",
      "round 3215, train_loss: 0.41463877523632653, val_loss: 0.39025621960548035 \n",
      "round 3216, train_loss: 0.4146241386543103, val_loss: 0.39024336518866304 \n",
      "round 3217, train_loss: 0.41460950988915457, val_loss: 0.39023051994877017 \n",
      "round 3218, train_loss: 0.4145948889347699, val_loss: 0.39021768387834355 \n",
      "round 3219, train_loss: 0.4145802757850726, val_loss: 0.3902048569699319 \n",
      "round 3220, train_loss: 0.4145656704339863, val_loss: 0.3901920392160924 \n",
      "round 3221, train_loss: 0.4145510728754389, val_loss: 0.39017923060938886 \n",
      "round 3222, train_loss: 0.4145364831033662, val_loss: 0.39016643114239313 \n",
      "round 3223, train_loss: 0.4145219011117087, val_loss: 0.3901536408076851 \n",
      "round 3224, train_loss: 0.4145073268944138, val_loss: 0.3901408595978517 \n",
      "round 3225, train_loss: 0.41449276044543504, val_loss: 0.39012808750548705 \n",
      "round 3226, train_loss: 0.4144782017587311, val_loss: 0.3901153245231936 \n",
      "round 3227, train_loss: 0.41446365082826747, val_loss: 0.39010257064358095 \n",
      "round 3228, train_loss: 0.4144491076480158, val_loss: 0.39008982585926594 \n",
      "round 3229, train_loss: 0.4144345722119529, val_loss: 0.3900770901628737 \n",
      "round 3230, train_loss: 0.4144200445140631, val_loss: 0.39006436354703605 \n",
      "round 3231, train_loss: 0.4144055245483353, val_loss: 0.39005164600439274 \n",
      "round 3232, train_loss: 0.4143910123087645, val_loss: 0.39003893752759133 \n",
      "round 3233, train_loss: 0.41437650778935314, val_loss: 0.39002623810928555 \n",
      "round 3234, train_loss: 0.4143620109841081, val_loss: 0.39001354774213837 \n",
      "round 3235, train_loss: 0.41434752188704305, val_loss: 0.39000086641881876 \n",
      "round 3236, train_loss: 0.41433304049217745, val_loss: 0.389988194132004 \n",
      "round 3237, train_loss: 0.4143185667935367, val_loss: 0.3899755308743785 \n",
      "round 3238, train_loss: 0.414304100785152, val_loss: 0.3899628766386341 \n",
      "round 3239, train_loss: 0.41428964246106087, val_loss: 0.3899502314174699 \n",
      "round 3240, train_loss: 0.4142751918153066, val_loss: 0.3899375952035929 \n",
      "round 3241, train_loss: 0.4142607488419386, val_loss: 0.3899249679897169 \n",
      "round 3242, train_loss: 0.41424631353501196, val_loss: 0.38991234976856365 \n",
      "round 3243, train_loss: 0.4142318858885879, val_loss: 0.389899740532862 \n",
      "round 3244, train_loss: 0.41421746589673336, val_loss: 0.3898871402753479 \n",
      "round 3245, train_loss: 0.4142030535535214, val_loss: 0.3898745489887651 \n",
      "round 3246, train_loss: 0.4141886488530311, val_loss: 0.3898619666658652 \n",
      "round 3247, train_loss: 0.4141742517893467, val_loss: 0.38984939329940566 \n",
      "round 3248, train_loss: 0.4141598623565596, val_loss: 0.3898368288821524 \n",
      "round 3249, train_loss: 0.41414548054876593, val_loss: 0.38982427340687864 \n",
      "round 3250, train_loss: 0.4141311063600681, val_loss: 0.38981172686636417 \n",
      "round 3251, train_loss: 0.4141167397845748, val_loss: 0.3897991892533972 \n",
      "round 3252, train_loss: 0.41410238081640016, val_loss: 0.38978666056077216 \n",
      "round 3253, train_loss: 0.4140880294496641, val_loss: 0.38977414078129163 \n",
      "round 3254, train_loss: 0.4140736856784926, val_loss: 0.38976162990776514 \n",
      "round 3255, train_loss: 0.4140593494970176, val_loss: 0.3897491279330092 \n",
      "round 3256, train_loss: 0.41404502089937667, val_loss: 0.3897366348498478 \n",
      "round 3257, train_loss: 0.41403069987971297, val_loss: 0.38972415065111216 \n",
      "round 3258, train_loss: 0.4140163864321759, val_loss: 0.38971167532964107 \n",
      "round 3259, train_loss: 0.41400208055092097, val_loss: 0.3896992088782805 \n",
      "round 3260, train_loss: 0.4139877822301084, val_loss: 0.38968675128988306 \n",
      "round 3261, train_loss: 0.4139734914639054, val_loss: 0.38967430255730906 \n",
      "round 3262, train_loss: 0.41395920824648436, val_loss: 0.38966186267342606 \n",
      "round 3263, train_loss: 0.41394493257202325, val_loss: 0.3896494316311085 \n",
      "round 3264, train_loss: 0.4139306644347066, val_loss: 0.38963700942323853 \n",
      "round 3265, train_loss: 0.4139164038287239, val_loss: 0.3896245960427048 \n",
      "round 3266, train_loss: 0.41390215074827114, val_loss: 0.38961219148240384 \n",
      "round 3267, train_loss: 0.41388790518754914, val_loss: 0.38959979573523906 \n",
      "round 3268, train_loss: 0.4138736671407657, val_loss: 0.38958740879412046 \n",
      "round 3269, train_loss: 0.4138594366021331, val_loss: 0.38957503065196636 \n",
      "round 3270, train_loss: 0.4138452135658705, val_loss: 0.3895626613017009 \n",
      "round 3271, train_loss: 0.41383099802620155, val_loss: 0.3895503007362567 \n",
      "round 3272, train_loss: 0.413816789977357, val_loss: 0.3895379489485724 \n",
      "round 3273, train_loss: 0.4138025894135723, val_loss: 0.38952560593159435 \n",
      "round 3274, train_loss: 0.41378839632908904, val_loss: 0.3895132716782757 \n",
      "round 3275, train_loss: 0.41377421071815457, val_loss: 0.389500946181577 \n",
      "round 3276, train_loss: 0.41376003257502153, val_loss: 0.38948862943446577 \n",
      "round 3277, train_loss: 0.4137458618939488, val_loss: 0.3894763214299163 \n",
      "round 3278, train_loss: 0.4137316986692004, val_loss: 0.3894640221609104 \n",
      "round 3279, train_loss: 0.4137175428950461, val_loss: 0.38945173162043684 \n",
      "round 3280, train_loss: 0.4137033945657621, val_loss: 0.38943944980149114 \n",
      "round 3281, train_loss: 0.41368925367562953, val_loss: 0.3894271766970761 \n",
      "round 3282, train_loss: 0.41367512021893504, val_loss: 0.3894149123002021 \n",
      "round 3283, train_loss: 0.41366099418997143, val_loss: 0.38940265660388523 \n",
      "round 3284, train_loss: 0.41364687558303687, val_loss: 0.3893904096011495 \n",
      "round 3285, train_loss: 0.41363276439243535, val_loss: 0.38937817128502605 \n",
      "round 3286, train_loss: 0.4136186606124764, val_loss: 0.3893659416485526 \n",
      "round 3287, train_loss: 0.41360456423747494, val_loss: 0.3893537206847742 \n",
      "round 3288, train_loss: 0.413590475261752, val_loss: 0.38934150838674264 \n",
      "round 3289, train_loss: 0.4135763936796336, val_loss: 0.38932930474751676 \n",
      "round 3290, train_loss: 0.41356231948545186, val_loss: 0.38931710976016226 \n",
      "round 3291, train_loss: 0.41354825267354445, val_loss: 0.3893049234177518 \n",
      "round 3292, train_loss: 0.41353419323825436, val_loss: 0.38929274571336536 \n",
      "round 3293, train_loss: 0.41352014117393004, val_loss: 0.3892805766400893 \n",
      "round 3294, train_loss: 0.41350609647492625, val_loss: 0.3892684161910175 \n",
      "round 3295, train_loss: 0.4134920591356027, val_loss: 0.3892562643592503 \n",
      "round 3296, train_loss: 0.4134780291503245, val_loss: 0.3892441211378954 \n",
      "round 3297, train_loss: 0.41346400651346327, val_loss: 0.38923198652006646 \n",
      "round 3298, train_loss: 0.4134499912193948, val_loss: 0.3892198604988857 \n",
      "round 3299, train_loss: 0.4134359832625016, val_loss: 0.3892077430674802 \n",
      "round 3300, train_loss: 0.4134219826371712, val_loss: 0.38919563421898573 \n",
      "round 3301, train_loss: 0.4134079893377966, val_loss: 0.38918353394654376 \n",
      "round 3302, train_loss: 0.4133940033587765, val_loss: 0.38917144224330336 \n",
      "round 3303, train_loss: 0.413380024694515, val_loss: 0.3891593591024197 \n",
      "round 3304, train_loss: 0.4133660533394218, val_loss: 0.38914728451705555 \n",
      "round 3305, train_loss: 0.41335208928791206, val_loss: 0.3891352184803803 \n",
      "round 3306, train_loss: 0.4133381325344065, val_loss: 0.3891231609855698 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 3307, train_loss: 0.4133241830733312, val_loss: 0.3891111120258069 \n",
      "round 3308, train_loss: 0.4133102408991177, val_loss: 0.38909907159428186 \n",
      "round 3309, train_loss: 0.4132963060062031, val_loss: 0.3890870396841904 \n",
      "round 3310, train_loss: 0.41328237838903015, val_loss: 0.38907501628873703 \n",
      "round 3311, train_loss: 0.41326845804204665, val_loss: 0.3890630014011312 \n",
      "round 3312, train_loss: 0.413254544959706, val_loss: 0.3890509950145898 \n",
      "round 3313, train_loss: 0.41324063913646747, val_loss: 0.3890389971223366 \n",
      "round 3314, train_loss: 0.4132267405667952, val_loss: 0.38902700771760235 \n",
      "round 3315, train_loss: 0.41321284924515905, val_loss: 0.38901502679362393 \n",
      "round 3316, train_loss: 0.41319896516603394, val_loss: 0.38900305434364574 \n",
      "round 3317, train_loss: 0.413185088323901, val_loss: 0.3889910903609182 \n",
      "round 3318, train_loss: 0.41317121871324586, val_loss: 0.38897913483869884 \n",
      "round 3319, train_loss: 0.4131573563285603, val_loss: 0.38896718777025185 \n",
      "round 3320, train_loss: 0.413143501164341, val_loss: 0.3889552491488476 \n",
      "round 3321, train_loss: 0.41312965321509015, val_loss: 0.3889433189677651 \n",
      "round 3322, train_loss: 0.4131158124753155, val_loss: 0.388931397220287 \n",
      "round 3323, train_loss: 0.41310197893953016, val_loss: 0.3889194838997055 \n",
      "round 3324, train_loss: 0.4130881526022526, val_loss: 0.3889075789993174 \n",
      "round 3325, train_loss: 0.4130743334580062, val_loss: 0.3888956825124279 \n",
      "round 3326, train_loss: 0.4130605215013202, val_loss: 0.3888837944323474 \n",
      "round 3327, train_loss: 0.41304671672672955, val_loss: 0.38887191475239374 \n",
      "round 3328, train_loss: 0.41303291912877366, val_loss: 0.3888600434658915 \n",
      "round 3329, train_loss: 0.4130191287019977, val_loss: 0.3888481805661714 \n",
      "round 3330, train_loss: 0.4130053454409525, val_loss: 0.3888363260465708 \n",
      "round 3331, train_loss: 0.4129915693401932, val_loss: 0.38882447990043445 \n",
      "round 3332, train_loss: 0.41297780039428206, val_loss: 0.38881264212111294 \n",
      "round 3333, train_loss: 0.4129640385977846, val_loss: 0.38880081270196404 \n",
      "round 3334, train_loss: 0.4129502839452728, val_loss: 0.3887889916363512 \n",
      "round 3335, train_loss: 0.4129365364313242, val_loss: 0.38877717891764557 \n",
      "round 3336, train_loss: 0.4129227960505209, val_loss: 0.3887653745392242 \n",
      "round 3337, train_loss: 0.4129090627974504, val_loss: 0.38875357849447106 \n",
      "round 3338, train_loss: 0.41289533666670625, val_loss: 0.3887417907767764 \n",
      "round 3339, train_loss: 0.412881617652886, val_loss: 0.3887300113795372 \n",
      "round 3340, train_loss: 0.41286790575059357, val_loss: 0.3887182402961571 \n",
      "round 3341, train_loss: 0.41285420095443776, val_loss: 0.388706477520046 \n",
      "round 3342, train_loss: 0.41284050325903243, val_loss: 0.38869472304462055 \n",
      "round 3343, train_loss: 0.4128268126589971, val_loss: 0.3886829768633038 \n",
      "round 3344, train_loss: 0.4128131291489559, val_loss: 0.38867123896952566 \n",
      "round 3345, train_loss: 0.41279945272353924, val_loss: 0.3886595093567221 \n",
      "round 3346, train_loss: 0.41278578337738175, val_loss: 0.38864778801833577 \n",
      "round 3347, train_loss: 0.4127721211051236, val_loss: 0.3886360749478158 \n",
      "round 3348, train_loss: 0.4127584659014105, val_loss: 0.3886243701386181 \n",
      "round 3349, train_loss: 0.4127448177608931, val_loss: 0.3886126735842048 \n",
      "round 3350, train_loss: 0.41273117667822734, val_loss: 0.3886009852780441 \n",
      "round 3351, train_loss: 0.41271754264807403, val_loss: 0.38858930521361135 \n",
      "round 3352, train_loss: 0.41270391566509956, val_loss: 0.3885776333843884 \n",
      "round 3353, train_loss: 0.41269029572397553, val_loss: 0.3885659697838628 \n",
      "round 3354, train_loss: 0.41267668281937875, val_loss: 0.3885543144055291 \n",
      "round 3355, train_loss: 0.41266307694599075, val_loss: 0.38854266724288844 \n",
      "round 3356, train_loss: 0.41264947809849883, val_loss: 0.3885310282894479 \n",
      "round 3357, train_loss: 0.4126358862715948, val_loss: 0.3885193975387211 \n",
      "round 3358, train_loss: 0.41262230145997664, val_loss: 0.38850777498422856 \n",
      "round 3359, train_loss: 0.41260872365834594, val_loss: 0.3884961606194963 \n",
      "round 3360, train_loss: 0.41259515286141135, val_loss: 0.3884845544380577 \n",
      "round 3361, train_loss: 0.4125815890638849, val_loss: 0.3884729564334521 \n",
      "round 3362, train_loss: 0.41256803226048483, val_loss: 0.3884613665992249 \n",
      "round 3363, train_loss: 0.41255448244593423, val_loss: 0.3884497849289285 \n",
      "round 3364, train_loss: 0.41254093961496113, val_loss: 0.38843821141612106 \n",
      "round 3365, train_loss: 0.41252740376229874, val_loss: 0.3884266460543678 \n",
      "round 3366, train_loss: 0.4125138748826858, val_loss: 0.38841508883723935 \n",
      "round 3367, train_loss: 0.4125003529708653, val_loss: 0.38840353975831376 \n",
      "round 3368, train_loss: 0.4124868380215862, val_loss: 0.3883919988111747 \n",
      "round 3369, train_loss: 0.41247333002960207, val_loss: 0.38838046598941217 \n",
      "round 3370, train_loss: 0.41245982898967176, val_loss: 0.38836894128662264 \n",
      "round 3371, train_loss: 0.41244633489655935, val_loss: 0.38835742469640944 \n",
      "round 3372, train_loss: 0.4124328477450332, val_loss: 0.388345916212381 \n",
      "round 3373, train_loss: 0.4124193675298677, val_loss: 0.3883344158281531 \n",
      "round 3374, train_loss: 0.41240589424584173, val_loss: 0.3883229235373475 \n",
      "round 3375, train_loss: 0.4123924278877396, val_loss: 0.3883114393335923 \n",
      "round 3376, train_loss: 0.4123789684503504, val_loss: 0.3882999632105211 \n",
      "round 3377, train_loss: 0.41236551592846826, val_loss: 0.3882884951617751 \n",
      "round 3378, train_loss: 0.4123520703168925, val_loss: 0.38827703518100104 \n",
      "round 3379, train_loss: 0.4123386316104275, val_loss: 0.38826558326185173 \n",
      "round 3380, train_loss: 0.41232519980388216, val_loss: 0.3882541393979863 \n",
      "round 3381, train_loss: 0.4123117748920713, val_loss: 0.38824270358307067 \n",
      "round 3382, train_loss: 0.4122983568698139, val_loss: 0.38823127581077654 \n",
      "round 3383, train_loss: 0.4122849457319344, val_loss: 0.38821985607478166 \n",
      "round 3384, train_loss: 0.41227154147326206, val_loss: 0.3882084443687701 \n",
      "round 3385, train_loss: 0.4122581440886315, val_loss: 0.3881970406864329 \n",
      "round 3386, train_loss: 0.4122447535728818, val_loss: 0.38818564502146596 \n",
      "round 3387, train_loss: 0.4122313699208574, val_loss: 0.38817425736757255 \n",
      "round 3388, train_loss: 0.4122179931274076, val_loss: 0.3881628777184614 \n",
      "round 3389, train_loss: 0.4122046231873865, val_loss: 0.3881515060678477 \n",
      "round 3390, train_loss: 0.4121912600956535, val_loss: 0.3881401424094528 \n",
      "round 3391, train_loss: 0.4121779038470725, val_loss: 0.3881287867370045 \n",
      "round 3392, train_loss: 0.41216455443651295, val_loss: 0.38811743904423585 \n",
      "round 3393, train_loss: 0.41215121185884857, val_loss: 0.3881060993248871 \n",
      "round 3394, train_loss: 0.41213787610895886, val_loss: 0.38809476757270384 \n",
      "round 3395, train_loss: 0.4121245471817279, val_loss: 0.3880834437814384 \n",
      "round 3396, train_loss: 0.4121112250720438, val_loss: 0.3880721279448492 \n",
      "round 3397, train_loss: 0.41209790977480104, val_loss: 0.3880608200566999 \n",
      "round 3398, train_loss: 0.4120846012848981, val_loss: 0.3880495201107615 \n",
      "round 3399, train_loss: 0.4120712995972387, val_loss: 0.3880382281008098 \n",
      "round 3400, train_loss: 0.41205800470673154, val_loss: 0.38802694402062865 \n",
      "round 3401, train_loss: 0.4120447166082899, val_loss: 0.3880156678640057 \n",
      "round 3402, train_loss: 0.4120314352968321, val_loss: 0.38800439962473615 \n",
      "round 3403, train_loss: 0.41201816076728137, val_loss: 0.3879931392966207 \n",
      "round 3404, train_loss: 0.4120048930145661, val_loss: 0.38798188687346674 \n",
      "round 3405, train_loss: 0.4119916320336192, val_loss: 0.38797064234908674 \n",
      "round 3406, train_loss: 0.4119783778193785, val_loss: 0.3879594057172997 \n",
      "round 3407, train_loss: 0.41196513036678656, val_loss: 0.38794817697193135 \n",
      "round 3408, train_loss: 0.4119518896707914, val_loss: 0.3879369561068123 \n",
      "round 3409, train_loss: 0.41193865572634486, val_loss: 0.3879257431157799 \n",
      "round 3410, train_loss: 0.4119254285284048, val_loss: 0.3879145379926774 \n",
      "round 3411, train_loss: 0.4119122080719335, val_loss: 0.3879033407313538 \n",
      "round 3412, train_loss: 0.41189899435189753, val_loss: 0.3878921513256644 \n",
      "round 3413, train_loss: 0.41188578736326875, val_loss: 0.3878809697694706 \n",
      "round 3414, train_loss: 0.4118725871010242, val_loss: 0.38786979605663957 \n",
      "round 3415, train_loss: 0.41185939356014506, val_loss: 0.38785863018104416 \n",
      "round 3416, train_loss: 0.4118462067356177, val_loss: 0.38784747213656406 \n",
      "round 3417, train_loss: 0.4118330266224328, val_loss: 0.38783632191708406 \n",
      "round 3418, train_loss: 0.41181985321558695, val_loss: 0.3878251795164956 \n",
      "round 3419, train_loss: 0.41180668651008034, val_loss: 0.38781404492869537 \n",
      "round 3420, train_loss: 0.41179352650091894, val_loss: 0.3878029181475869 \n",
      "round 3421, train_loss: 0.4117803731831127, val_loss: 0.38779179916707873 \n",
      "round 3422, train_loss: 0.4117672265516764, val_loss: 0.3877806879810861 \n",
      "round 3423, train_loss: 0.4117540866016307, val_loss: 0.38776958458353 \n",
      "round 3424, train_loss: 0.4117409533279994, val_loss: 0.38775848896833665 \n",
      "round 3425, train_loss: 0.41172782672581226, val_loss: 0.3877474011294393 \n",
      "round 3426, train_loss: 0.4117147067901034, val_loss: 0.38773632106077616 \n",
      "round 3427, train_loss: 0.41170159351591157, val_loss: 0.38772524875629183 \n",
      "round 3428, train_loss: 0.4116884868982805, val_loss: 0.3877141842099371 \n",
      "round 3429, train_loss: 0.4116753869322585, val_loss: 0.3877031274156679 \n",
      "round 3430, train_loss: 0.4116622936128989, val_loss: 0.38769207836744635 \n",
      "round 3431, train_loss: 0.41164920693525897, val_loss: 0.38768103705924073 \n",
      "round 3432, train_loss: 0.41163612689440193, val_loss: 0.38767000348502495 \n",
      "round 3433, train_loss: 0.41162305348539474, val_loss: 0.3876589776387787 \n",
      "round 3434, train_loss: 0.41160998670330945, val_loss: 0.3876479595144876 \n",
      "round 3435, train_loss: 0.41159692654322294, val_loss: 0.3876369491061431 \n",
      "round 3436, train_loss: 0.4115838730002159, val_loss: 0.38762594640774267 \n",
      "round 3437, train_loss: 0.4115708260693754, val_loss: 0.3876149514132897 \n",
      "round 3438, train_loss: 0.4115577857457915, val_loss: 0.3876039641167928 \n",
      "round 3439, train_loss: 0.4115447520245604, val_loss: 0.38759298451226676 \n",
      "round 3440, train_loss: 0.4115317249007817, val_loss: 0.3875820125937324 \n",
      "round 3441, train_loss: 0.41151870436956034, val_loss: 0.38757104835521605 \n",
      "round 3442, train_loss: 0.41150569042600577, val_loss: 0.3875600917907499 \n",
      "round 3443, train_loss: 0.4114926830652323, val_loss: 0.3875491428943721 \n",
      "round 3444, train_loss: 0.4114796822823587, val_loss: 0.38753820166012637 \n",
      "round 3445, train_loss: 0.4114666880725086, val_loss: 0.38752726808206234 \n",
      "round 3446, train_loss: 0.41145370043080987, val_loss: 0.38751634215423525 \n",
      "round 3447, train_loss: 0.4114407193523954, val_loss: 0.3875054238707064 \n",
      "round 3448, train_loss: 0.4114277448324029, val_loss: 0.38749451322554274 \n",
      "round 3449, train_loss: 0.411414776865974, val_loss: 0.38748361021281624 \n",
      "round 3450, train_loss: 0.4114018154482551, val_loss: 0.3874727148266062 \n",
      "round 3451, train_loss: 0.41138886057439844, val_loss: 0.38746182706099624 \n",
      "round 3452, train_loss: 0.4113759122395592, val_loss: 0.3874509469100762 \n",
      "round 3453, train_loss: 0.41136297043889797, val_loss: 0.3874400743679414 \n",
      "round 3454, train_loss: 0.4113500351675802, val_loss: 0.38742920942869374 \n",
      "round 3455, train_loss: 0.4113371064207752, val_loss: 0.3874183520864398 \n",
      "round 3456, train_loss: 0.41132418419365746, val_loss: 0.38740750233529225 \n",
      "round 3457, train_loss: 0.41131126848140603, val_loss: 0.38739666016936963 \n",
      "round 3458, train_loss: 0.411298359279204, val_loss: 0.38738582558279633 \n",
      "round 3459, train_loss: 0.41128545658223964, val_loss: 0.3873749985697016 \n",
      "round 3460, train_loss: 0.4112725603857059, val_loss: 0.3873641791242206 \n",
      "round 3461, train_loss: 0.4112596706847995, val_loss: 0.3873533672404953 \n",
      "round 3462, train_loss: 0.4112467874747226, val_loss: 0.38734256291267205 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 3463, train_loss: 0.4112339107506813, val_loss: 0.3873317661349032 \n",
      "round 3464, train_loss: 0.4112210405078863, val_loss: 0.3873209769013471 \n",
      "round 3465, train_loss: 0.4112081767415532, val_loss: 0.38731019520616694 \n",
      "round 3466, train_loss: 0.41119531944690196, val_loss: 0.3872994210435327 \n",
      "round 3467, train_loss: 0.411182468619157, val_loss: 0.387288654407619 \n",
      "round 3468, train_loss: 0.41116962425354736, val_loss: 0.3872778952926069 \n",
      "round 3469, train_loss: 0.4111567863453068, val_loss: 0.38726714369268184 \n",
      "round 3470, train_loss: 0.4111439548896731, val_loss: 0.3872563996020365 \n",
      "round 3471, train_loss: 0.41113112988188877, val_loss: 0.38724566301486785 \n",
      "round 3472, train_loss: 0.41111831131720106, val_loss: 0.38723493392537894 \n",
      "round 3473, train_loss: 0.4111054991908616, val_loss: 0.3872242123277787 \n",
      "round 3474, train_loss: 0.4110926934981266, val_loss: 0.3872134982162809 \n",
      "round 3475, train_loss: 0.4110798942342561, val_loss: 0.38720279158510573 \n",
      "round 3476, train_loss: 0.41106710139451574, val_loss: 0.38719209242847824 \n",
      "round 3477, train_loss: 0.4110543149741747, val_loss: 0.3871814007406295 \n",
      "round 3478, train_loss: 0.4110415349685073, val_loss: 0.3871707165157963 \n",
      "round 3479, train_loss: 0.41102876137279154, val_loss: 0.38716003974822 \n",
      "round 3480, train_loss: 0.4110159941823111, val_loss: 0.38714937043214875 \n",
      "round 3481, train_loss: 0.41100323339235306, val_loss: 0.38713870856183524 \n",
      "round 3482, train_loss: 0.41099047899820884, val_loss: 0.38712805413153867 \n",
      "round 3483, train_loss: 0.41097773099517565, val_loss: 0.38711740713552284 \n",
      "round 3484, train_loss: 0.4109649893785534, val_loss: 0.38710676756805734 \n",
      "round 3485, train_loss: 0.41095225414364783, val_loss: 0.3870961354234177 \n",
      "round 3486, train_loss: 0.4109395252857685, val_loss: 0.3870855106958843 \n",
      "round 3487, train_loss: 0.4109268028002295, val_loss: 0.38707489337974355 \n",
      "round 3488, train_loss: 0.4109140866823492, val_loss: 0.38706428346928706 \n",
      "round 3489, train_loss: 0.41090137692745066, val_loss: 0.3870536809588124 \n",
      "round 3490, train_loss: 0.4108886735308613, val_loss: 0.38704308584262137 \n",
      "round 3491, train_loss: 0.4108759764879126, val_loss: 0.38703249811502277 \n",
      "round 3492, train_loss: 0.41086328579394094, val_loss: 0.3870219177703303 \n",
      "round 3493, train_loss: 0.4108506014442868, val_loss: 0.3870113448028626 \n",
      "round 3494, train_loss: 0.4108379234342952, val_loss: 0.3870007792069442 \n",
      "round 3495, train_loss: 0.4108252517593152, val_loss: 0.38699022097690555 \n",
      "round 3496, train_loss: 0.4108125864147012, val_loss: 0.3869796701070816 \n",
      "round 3497, train_loss: 0.41079992739581034, val_loss: 0.3869691265918135 \n",
      "round 3498, train_loss: 0.4107872746980058, val_loss: 0.3869585904254473 \n",
      "round 3499, train_loss: 0.4107746283166543, val_loss: 0.3869480616023347 \n",
      "round 3500, train_loss: 0.41076198824712695, val_loss: 0.3869375401168328 \n",
      "round 3501, train_loss: 0.4107493544847992, val_loss: 0.38692702596330447 \n",
      "round 3502, train_loss: 0.4107367270250515, val_loss: 0.386916519136117 \n",
      "round 3503, train_loss: 0.4107241058632674, val_loss: 0.3869060196296442 \n",
      "round 3504, train_loss: 0.41071149099483606, val_loss: 0.38689552743826455 \n",
      "round 3505, train_loss: 0.41069888241514996, val_loss: 0.3868850425563622 \n",
      "round 3506, train_loss: 0.410686280119607, val_loss: 0.38687456497832656 \n",
      "round 3507, train_loss: 0.41067368410360827, val_loss: 0.38686409469855265 \n",
      "round 3508, train_loss: 0.41066109436256, val_loss: 0.3868536317114409 \n",
      "round 3509, train_loss: 0.41064851089187226, val_loss: 0.38684317601139584 \n",
      "round 3510, train_loss: 0.4106359336869597, val_loss: 0.38683272759282955 \n",
      "round 3511, train_loss: 0.41062336274324124, val_loss: 0.38682228645015787 \n",
      "round 3512, train_loss: 0.4106107980561399, val_loss: 0.3868118525778021 \n",
      "round 3513, train_loss: 0.41059823962108366, val_loss: 0.38680142597018946 \n",
      "round 3514, train_loss: 0.4105856874335036, val_loss: 0.3867910066217521 \n",
      "round 3515, train_loss: 0.41057314148883634, val_loss: 0.386780594526928 \n",
      "round 3516, train_loss: 0.41056060178252185, val_loss: 0.38677018968015947 \n",
      "round 3517, train_loss: 0.410548068310005, val_loss: 0.38675979207589495 \n",
      "round 3518, train_loss: 0.41053554106673473, val_loss: 0.38674940170858846 \n",
      "round 3519, train_loss: 0.410523020048164, val_loss: 0.3867390185726981 \n",
      "round 3520, train_loss: 0.41051050524975025, val_loss: 0.3867286426626881 \n",
      "round 3521, train_loss: 0.4104979966669554, val_loss: 0.3867182739730281 \n",
      "round 3522, train_loss: 0.4104854942952452, val_loss: 0.38670791249819253 \n",
      "round 3523, train_loss: 0.4104729981300901, val_loss: 0.3866975582326616 \n",
      "round 3524, train_loss: 0.4104605081669641, val_loss: 0.38668721117092014 \n",
      "round 3525, train_loss: 0.4104480244013462, val_loss: 0.38667687130745876 \n",
      "round 3526, train_loss: 0.4104355468287194, val_loss: 0.38666653863677325 \n",
      "round 3527, train_loss: 0.4104230754445708, val_loss: 0.3866562131533645 \n",
      "round 3528, train_loss: 0.41041061024439135, val_loss: 0.3866458948517391 \n",
      "round 3529, train_loss: 0.41039815122367734, val_loss: 0.38663558372640777 \n",
      "round 3530, train_loss: 0.4103856983779279, val_loss: 0.38662527977188743 \n",
      "round 3531, train_loss: 0.41037325170264755, val_loss: 0.38661498298270025 \n",
      "round 3532, train_loss: 0.4103608111933445, val_loss: 0.3866046933533732 \n",
      "round 3533, train_loss: 0.4103483768455306, val_loss: 0.38659441087843843 \n",
      "round 3534, train_loss: 0.41033594865472306, val_loss: 0.3865841355524337 \n",
      "round 3535, train_loss: 0.4103235266164425, val_loss: 0.38657386736990157 \n",
      "round 3536, train_loss: 0.4103111107262138, val_loss: 0.38656360632539005 \n",
      "round 3537, train_loss: 0.41029870097956633, val_loss: 0.38655335241345185 \n",
      "round 3538, train_loss: 0.4102862973720335, val_loss: 0.386543105628646 \n",
      "round 3539, train_loss: 0.4102738998991527, val_loss: 0.3865328659655353 \n",
      "round 3540, train_loss: 0.4102615085564655, val_loss: 0.3865226334186886 \n",
      "round 3541, train_loss: 0.41024912333951796, val_loss: 0.3865124079826799 \n",
      "round 3542, train_loss: 0.4102367442438599, val_loss: 0.386502189652088 \n",
      "round 3543, train_loss: 0.41022437126504585, val_loss: 0.38649197842149624 \n",
      "round 3544, train_loss: 0.4102120043986337, val_loss: 0.3864817742854952 \n",
      "round 3545, train_loss: 0.4101996436401863, val_loss: 0.3864715772386786 \n",
      "round 3546, train_loss: 0.41018728898526985, val_loss: 0.3864613872756457 \n",
      "round 3547, train_loss: 0.41017494042945535, val_loss: 0.38645120439100167 \n",
      "round 3548, train_loss: 0.41016259796831733, val_loss: 0.3864410285793555 \n",
      "round 3549, train_loss: 0.4101502615974353, val_loss: 0.38643085983532305 \n",
      "round 3550, train_loss: 0.41013793131239207, val_loss: 0.3864206981535237 \n",
      "round 3551, train_loss: 0.41012560710877466, val_loss: 0.3864105435285824 \n",
      "round 3552, train_loss: 0.4101132889821748, val_loss: 0.3864003959551299 \n",
      "round 3553, train_loss: 0.4101009769281878, val_loss: 0.3863902554278007 \n",
      "round 3554, train_loss: 0.410088670942413, val_loss: 0.386380121941236 \n",
      "round 3555, train_loss: 0.41007637102045413, val_loss: 0.3863699954900807 \n",
      "round 3556, train_loss: 0.4100640771579189, val_loss: 0.3863598760689854 \n",
      "round 3557, train_loss: 0.41005178935041914, val_loss: 0.38634976367260576 \n",
      "round 3558, train_loss: 0.4100395075935709, val_loss: 0.3863396582956024 \n",
      "round 3559, train_loss: 0.4100272318829936, val_loss: 0.386329559932641 \n",
      "round 3560, train_loss: 0.4100149622143121, val_loss: 0.3863194685783922 \n",
      "round 3561, train_loss: 0.41000269858315397, val_loss: 0.38630938422753197 \n",
      "round 3562, train_loss: 0.4099904409851515, val_loss: 0.3862993068747411 \n",
      "round 3563, train_loss: 0.4099781894159407, val_loss: 0.38628923651470526 \n",
      "round 3564, train_loss: 0.40996594387116214, val_loss: 0.38627917314211596 \n",
      "round 3565, train_loss: 0.40995370434646, val_loss: 0.38626911675166825 \n",
      "round 3566, train_loss: 0.40994147083748284, val_loss: 0.38625906733806364 \n",
      "round 3567, train_loss: 0.4099292433398828, val_loss: 0.3862490248960077 \n",
      "round 3568, train_loss: 0.4099170218493167, val_loss: 0.3862389894202116 \n",
      "round 3569, train_loss: 0.40990480636144466, val_loss: 0.38622896090539127 \n",
      "round 3570, train_loss: 0.4098925968719312, val_loss: 0.3862189393462679 \n",
      "round 3571, train_loss: 0.4098803933764451, val_loss: 0.3862089247375665 \n",
      "round 3572, train_loss: 0.4098681958706587, val_loss: 0.38619891707401915 \n",
      "round 3573, train_loss: 0.40985600435024877, val_loss: 0.3861889163503609 \n",
      "round 3574, train_loss: 0.4098438188108958, val_loss: 0.38617892256133274 \n",
      "round 3575, train_loss: 0.40983163924828403, val_loss: 0.3861689357016808 \n",
      "round 3576, train_loss: 0.4098194656581026, val_loss: 0.38615895576615533 \n",
      "round 3577, train_loss: 0.40980729803604354, val_loss: 0.3861489827495125 \n",
      "round 3578, train_loss: 0.40979513637780396, val_loss: 0.3861390166465129 \n",
      "round 3579, train_loss: 0.4097829806790836, val_loss: 0.38612905745192166 \n",
      "round 3580, train_loss: 0.40977083093558775, val_loss: 0.38611910516051 \n",
      "round 3581, train_loss: 0.4097586871430247, val_loss: 0.38610915976705296 \n",
      "round 3582, train_loss: 0.4097465492971066, val_loss: 0.3860992212663311 \n",
      "round 3583, train_loss: 0.4097344173935504, val_loss: 0.38608928965312944 \n",
      "round 3584, train_loss: 0.4097222914280761, val_loss: 0.38607936492223865 \n",
      "round 3585, train_loss: 0.409710171396408, val_loss: 0.38606944706845353 \n",
      "round 3586, train_loss: 0.4096980572942748, val_loss: 0.3860595360865745 \n",
      "round 3587, train_loss: 0.4096859491174081, val_loss: 0.3860496319714057 \n",
      "round 3588, train_loss: 0.40967384686154495, val_loss: 0.3860397347177577 \n",
      "round 3589, train_loss: 0.409661750522425, val_loss: 0.38602984432044485 \n",
      "round 3590, train_loss: 0.4096496600957924, val_loss: 0.3860199607742868 \n",
      "round 3591, train_loss: 0.4096375755773949, val_loss: 0.38601008407410786 \n",
      "round 3592, train_loss: 0.4096254969629848, val_loss: 0.38600021421473774 \n",
      "round 3593, train_loss: 0.40961342424831804, val_loss: 0.38599035119101016 \n",
      "round 3594, train_loss: 0.40960135742915377, val_loss: 0.38598049499776454 \n",
      "round 3595, train_loss: 0.4095892965012564, val_loss: 0.3859706456298446 \n",
      "round 3596, train_loss: 0.40957724146039326, val_loss: 0.3859608030820988 \n",
      "round 3597, train_loss: 0.4095651923023357, val_loss: 0.385950967349381 \n",
      "round 3598, train_loss: 0.4095531490228594, val_loss: 0.3859411384265497 \n",
      "round 3599, train_loss: 0.40954111161774326, val_loss: 0.3859313163084678 \n",
      "round 3600, train_loss: 0.4095290800827709, val_loss: 0.3859215009900036 \n",
      "round 3601, train_loss: 0.40951705441372893, val_loss: 0.38591169246602997 \n",
      "round 3602, train_loss: 0.40950503460640886, val_loss: 0.3859018907314244 \n",
      "round 3603, train_loss: 0.4094930206566049, val_loss: 0.3858920957810696 \n",
      "round 3604, train_loss: 0.4094810125601164, val_loss: 0.3858823076098526 \n",
      "round 3605, train_loss: 0.40946901031274546, val_loss: 0.3858725262126658 \n",
      "round 3606, train_loss: 0.4094570139102986, val_loss: 0.38586275158440586 \n",
      "round 3607, train_loss: 0.40944502334858646, val_loss: 0.38585298371997456 \n",
      "round 3608, train_loss: 0.40943303862342284, val_loss: 0.3858432226142783 \n",
      "round 3609, train_loss: 0.4094210597306257, val_loss: 0.3858334682622282 \n",
      "round 3610, train_loss: 0.4094090866660172, val_loss: 0.38582372065874027 \n",
      "round 3611, train_loss: 0.40939711942542295, val_loss: 0.38581397979873533 \n",
      "round 3612, train_loss: 0.4093851580046724, val_loss: 0.3858042456771386 \n",
      "round 3613, train_loss: 0.40937320239959885, val_loss: 0.385794518288881 \n",
      "round 3614, train_loss: 0.4093612526060398, val_loss: 0.3857847976288966 \n",
      "round 3615, train_loss: 0.40934930861983576, val_loss: 0.385775083692126 \n",
      "round 3616, train_loss: 0.40933737043683177, val_loss: 0.38576537647351306 \n",
      "round 3617, train_loss: 0.40932543805287713, val_loss: 0.38575567596800747 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 3618, train_loss: 0.4093135114638236, val_loss: 0.38574598217056266 \n",
      "round 3619, train_loss: 0.4093015906655277, val_loss: 0.38573629507613755 \n",
      "round 3620, train_loss: 0.4092896756538493, val_loss: 0.38572661467969577 \n",
      "round 3621, train_loss: 0.4092777664246527, val_loss: 0.38571694097620457 \n",
      "round 3622, train_loss: 0.40926586297380535, val_loss: 0.3857072739606377 \n",
      "round 3623, train_loss: 0.4092539652971787, val_loss: 0.38569761362797184 \n",
      "round 3624, train_loss: 0.40924207339064816, val_loss: 0.3856879599731896 \n",
      "round 3625, train_loss: 0.40923018725009264, val_loss: 0.3856783129912777 \n",
      "round 3626, train_loss: 0.40921830687139515, val_loss: 0.3856686726772276 \n",
      "round 3627, train_loss: 0.40920643225044206, val_loss: 0.38565903902603565 \n",
      "round 3628, train_loss: 0.4091945633831238, val_loss: 0.38564941203270253 \n",
      "round 3629, train_loss: 0.4091827002653345, val_loss: 0.38563979169223384 \n",
      "round 3630, train_loss: 0.4091708428929722, val_loss: 0.38563017799963994 \n",
      "round 3631, train_loss: 0.40915899126193833, val_loss: 0.3856205709499357 \n",
      "round 3632, train_loss: 0.40914714536813845, val_loss: 0.3856109705381402 \n",
      "round 3633, train_loss: 0.4091353052074817, val_loss: 0.3856013767592781 \n",
      "round 3634, train_loss: 0.40912347077588096, val_loss: 0.38559178960837803 \n",
      "round 3635, train_loss: 0.40911164206925293, val_loss: 0.38558220908047336 \n",
      "round 3636, train_loss: 0.40909981908351783, val_loss: 0.385572635170602 \n",
      "round 3637, train_loss: 0.4090880018146, val_loss: 0.3855630678738069 \n",
      "round 3638, train_loss: 0.40907619025842723, val_loss: 0.38555350718513537 \n",
      "round 3639, train_loss: 0.4090643844109306, val_loss: 0.38554395309963896 \n",
      "round 3640, train_loss: 0.40905258426804625, val_loss: 0.38553440561237456 \n",
      "round 3641, train_loss: 0.40904078982571235, val_loss: 0.38552486471840286 \n",
      "round 3642, train_loss: 0.40902900107987206, val_loss: 0.38551533041279007 \n",
      "round 3643, train_loss: 0.4090172180264718, val_loss: 0.3855058026906062 \n",
      "round 3644, train_loss: 0.4090054406614617, val_loss: 0.3854962815469259 \n",
      "round 3645, train_loss: 0.40899366898079503, val_loss: 0.38548676697682915 \n",
      "round 3646, train_loss: 0.40898190298043036, val_loss: 0.38547725897539975 \n",
      "round 3647, train_loss: 0.40897014265632764, val_loss: 0.38546775753772666 \n",
      "round 3648, train_loss: 0.4089583880044528, val_loss: 0.38545826265890265 \n",
      "round 3649, train_loss: 0.40894663902077355, val_loss: 0.3854487743340256 \n",
      "round 3650, train_loss: 0.40893489570126274, val_loss: 0.3854392925581975 \n",
      "round 3651, train_loss: 0.40892315804189616, val_loss: 0.3854298173265256 \n",
      "round 3652, train_loss: 0.40891142603865327, val_loss: 0.3854203486341214 \n",
      "round 3653, train_loss: 0.4088996996875174, val_loss: 0.38541088647610067 \n",
      "round 3654, train_loss: 0.4088879789844753, val_loss: 0.3854014308475835 \n",
      "round 3655, train_loss: 0.4088762639255181, val_loss: 0.3853919817436952 \n",
      "round 3656, train_loss: 0.40886455450663955, val_loss: 0.3853825391595656 \n",
      "round 3657, train_loss: 0.4088528507238374, val_loss: 0.38537310309032846 \n",
      "round 3658, train_loss: 0.4088411525731132, val_loss: 0.3853636735311221 \n",
      "round 3659, train_loss: 0.4088294600504725, val_loss: 0.38535425047709004 \n",
      "round 3660, train_loss: 0.4088177731519238, val_loss: 0.38534483392337976 \n",
      "round 3661, train_loss: 0.4088060918734796, val_loss: 0.3853354238651428 \n",
      "round 3662, train_loss: 0.408794416211156, val_loss: 0.3853260202975366 \n",
      "round 3663, train_loss: 0.4087827461609726, val_loss: 0.3853166232157215 \n",
      "round 3664, train_loss: 0.4087710817189526, val_loss: 0.38530723261486344 \n",
      "round 3665, train_loss: 0.40875942288112327, val_loss: 0.38529784849013216 \n",
      "round 3666, train_loss: 0.4087477696435146, val_loss: 0.38528847083670237 \n",
      "round 3667, train_loss: 0.4087361220021614, val_loss: 0.3852790996497531 \n",
      "round 3668, train_loss: 0.4087244799531008, val_loss: 0.3852697349244674 \n",
      "round 3669, train_loss: 0.40871284349237474, val_loss: 0.38526037665603374 \n",
      "round 3670, train_loss: 0.4087012126160275, val_loss: 0.3852510248396435 \n",
      "round 3671, train_loss: 0.4086895873201082, val_loss: 0.3852416794704946 \n",
      "round 3672, train_loss: 0.40867796760066855, val_loss: 0.38523234054378747 \n",
      "round 3673, train_loss: 0.40866635345376445, val_loss: 0.3852230080547278 \n",
      "round 3674, train_loss: 0.4086547448754552, val_loss: 0.3852136819985263 \n",
      "round 3675, train_loss: 0.4086431418618035, val_loss: 0.3852043623703971 \n",
      "round 3676, train_loss: 0.40863154440887606, val_loss: 0.3851950491655589 \n",
      "round 3677, train_loss: 0.4086199525127427, val_loss: 0.3851857423792355 \n",
      "round 3678, train_loss: 0.40860836616947693, val_loss: 0.38517644200665463 \n",
      "round 3679, train_loss: 0.4085967853751561, val_loss: 0.3851671480430482 \n",
      "round 3680, train_loss: 0.4085852101258604, val_loss: 0.3851578604836532 \n",
      "round 3681, train_loss: 0.40857364041767474, val_loss: 0.3851485793237101 \n",
      "round 3682, train_loss: 0.4085620762466864, val_loss: 0.3851393045584648 \n",
      "round 3683, train_loss: 0.40855051760898703, val_loss: 0.3851300361831666 \n",
      "round 3684, train_loss: 0.4085389645006715, val_loss: 0.3851207741930701 \n",
      "round 3685, train_loss: 0.4085274169178377, val_loss: 0.38511151858343357 \n",
      "round 3686, train_loss: 0.40851587485658836, val_loss: 0.38510226934952 \n",
      "round 3687, train_loss: 0.40850433831302846, val_loss: 0.3850930264865967 \n",
      "round 3688, train_loss: 0.40849280728326703, val_loss: 0.3850837899899354 \n",
      "round 3689, train_loss: 0.4084812817634167, val_loss: 0.385074559854812 \n",
      "round 3690, train_loss: 0.4084697617495933, val_loss: 0.3850653360765067 \n",
      "round 3691, train_loss: 0.4084582472379168, val_loss: 0.3850561186503045 \n",
      "round 3692, train_loss: 0.4084467382245099, val_loss: 0.38504690757149435 \n",
      "round 3693, train_loss: 0.40843523470549925, val_loss: 0.3850377028353695 \n",
      "round 3694, train_loss: 0.40842373667701465, val_loss: 0.3850285044372277 \n",
      "round 3695, train_loss: 0.40841224413518995, val_loss: 0.3850193123723711 \n",
      "round 3696, train_loss: 0.40840075707616247, val_loss: 0.38501012663610606 \n",
      "round 3697, train_loss: 0.40838927549607246, val_loss: 0.38500094722374334 \n",
      "round 3698, train_loss: 0.4083777993910636, val_loss: 0.38499177413059804 \n",
      "round 3699, train_loss: 0.408366328757284, val_loss: 0.384982607351989 \n",
      "round 3700, train_loss: 0.4083548635908842, val_loss: 0.3849734468832406 \n",
      "round 3701, train_loss: 0.4083434038880191, val_loss: 0.3849642927196802 \n",
      "round 3702, train_loss: 0.4083319496448462, val_loss: 0.38495514485664006 \n",
      "round 3703, train_loss: 0.4083205008575274, val_loss: 0.384946003289457 \n",
      "round 3704, train_loss: 0.40830905752222707, val_loss: 0.38493686801347154 \n",
      "round 3705, train_loss: 0.40829761963511374, val_loss: 0.38492773902402894 \n",
      "round 3706, train_loss: 0.4082861871923592, val_loss: 0.3849186163164786 \n",
      "round 3707, train_loss: 0.4082747601901387, val_loss: 0.38490949988617384 \n",
      "round 3708, train_loss: 0.40826333862463093, val_loss: 0.38490038972847296 \n",
      "round 3709, train_loss: 0.4082519224920177, val_loss: 0.38489128583873783 \n",
      "round 3710, train_loss: 0.4082405117884853, val_loss: 0.3848821882123353 \n",
      "round 3711, train_loss: 0.4082291065102219, val_loss: 0.3848730968446354 \n",
      "round 3712, train_loss: 0.40821770665342044, val_loss: 0.3848640117310134 \n",
      "round 3713, train_loss: 0.4082063122142766, val_loss: 0.3848549328668486 \n",
      "round 3714, train_loss: 0.4081949231889897, val_loss: 0.38484586024752426 \n",
      "round 3715, train_loss: 0.40818353957376247, val_loss: 0.38483679386842806 \n",
      "round 3716, train_loss: 0.40817216136480117, val_loss: 0.3848277337249515 \n",
      "round 3717, train_loss: 0.4081607885583148, val_loss: 0.3848186798124914 \n",
      "round 3718, train_loss: 0.40814942115051694, val_loss: 0.38480963212644753 \n",
      "round 3719, train_loss: 0.40813805913762385, val_loss: 0.3848005906622245 \n",
      "round 3720, train_loss: 0.4081267025158548, val_loss: 0.3847915554152311 \n",
      "round 3721, train_loss: 0.4081153512814335, val_loss: 0.38478252638088023 \n",
      "round 3722, train_loss: 0.40810400543058617, val_loss: 0.3847735035545891 \n",
      "round 3723, train_loss: 0.40809266495954294, val_loss: 0.3847644869317791 \n",
      "round 3724, train_loss: 0.4080813298645369, val_loss: 0.38475547650787567 \n",
      "round 3725, train_loss: 0.4080700001418051, val_loss: 0.3847464722783085 \n",
      "round 3726, train_loss: 0.408058675787587, val_loss: 0.3847374742385115 \n",
      "round 3727, train_loss: 0.408047356798127, val_loss: 0.38472848238392265 \n",
      "round 3728, train_loss: 0.4080360431696712, val_loss: 0.38471949670998457 \n",
      "round 3729, train_loss: 0.40802473489846997, val_loss: 0.3847105172121433 \n",
      "round 3730, train_loss: 0.4080134319807769, val_loss: 0.3847015438858495 \n",
      "round 3731, train_loss: 0.40800213441284905, val_loss: 0.38469257672655793 \n",
      "round 3732, train_loss: 0.4079908421909465, val_loss: 0.3846836157297276 \n",
      "round 3733, train_loss: 0.40797955531133323, val_loss: 0.3846746608908212 \n",
      "round 3734, train_loss: 0.40796827377027584, val_loss: 0.38466571220530643 \n",
      "round 3735, train_loss: 0.4079569975640449, val_loss: 0.3846567696686543 \n",
      "round 3736, train_loss: 0.40794572668891427, val_loss: 0.38464783327634045 \n",
      "round 3737, train_loss: 0.4079344611411604, val_loss: 0.38463890302384424 \n",
      "round 3738, train_loss: 0.407923200917064, val_loss: 0.38462997890664924 \n",
      "round 3739, train_loss: 0.40791194601290875, val_loss: 0.38462106092024384 \n",
      "round 3740, train_loss: 0.40790069642498167, val_loss: 0.3846121490601196 \n",
      "round 3741, train_loss: 0.40788945214957306, val_loss: 0.38460324332177287 \n",
      "round 3742, train_loss: 0.4078782131829768, val_loss: 0.38459434370070344 \n",
      "round 3743, train_loss: 0.4078669795214893, val_loss: 0.3845854501924159 \n",
      "round 3744, train_loss: 0.4078557511614116, val_loss: 0.3845765627924185 \n",
      "round 3745, train_loss: 0.4078445280990467, val_loss: 0.3845676814962237 \n",
      "round 3746, train_loss: 0.4078333103307018, val_loss: 0.38455880629934824 \n",
      "round 3747, train_loss: 0.40782209785268714, val_loss: 0.38454993719731273 \n",
      "round 3748, train_loss: 0.40781089066131593, val_loss: 0.3845410741856416 \n",
      "round 3749, train_loss: 0.4077996887529052, val_loss: 0.3845322172598642 \n",
      "round 3750, train_loss: 0.4077884921237749, val_loss: 0.3845233664155127 \n",
      "round 3751, train_loss: 0.40777730077024843, val_loss: 0.38451452164812483 \n",
      "round 3752, train_loss: 0.407766114688653, val_loss: 0.3845056829532409 \n",
      "round 3753, train_loss: 0.4077549338753177, val_loss: 0.3844968503264063 \n",
      "round 3754, train_loss: 0.4077437583265762, val_loss: 0.38448802376317015 \n",
      "round 3755, train_loss: 0.40773258803876516, val_loss: 0.3844792032590856 \n",
      "round 3756, train_loss: 0.4077214230082239, val_loss: 0.38447038880970996 \n",
      "round 3757, train_loss: 0.4077102632312957, val_loss: 0.3844615804106044 \n",
      "round 3758, train_loss: 0.40769910870432696, val_loss: 0.3844527780573342 \n",
      "round 3759, train_loss: 0.4076879594236671, val_loss: 0.3844439817454686 \n",
      "round 3760, train_loss: 0.4076768153856689, val_loss: 0.3844351914705811 \n",
      "round 3761, train_loss: 0.40766567658668873, val_loss: 0.38442640722824895 \n",
      "round 3762, train_loss: 0.40765454302308557, val_loss: 0.38441762901405363 \n",
      "round 3763, train_loss: 0.4076434146912218, val_loss: 0.38440885682358056 \n",
      "round 3764, train_loss: 0.40763229158746367, val_loss: 0.384400090652419 \n",
      "round 3765, train_loss: 0.40762117370817996, val_loss: 0.38439133049616253 \n",
      "round 3766, train_loss: 0.40761006104974296, val_loss: 0.38438257635040846 \n",
      "round 3767, train_loss: 0.40759895360852855, val_loss: 0.3843738282107582 \n",
      "round 3768, train_loss: 0.40758785138091486, val_loss: 0.38436508607281733 \n",
      "round 3769, train_loss: 0.40757675436328406, val_loss: 0.3843563499321949 \n",
      "round 3770, train_loss: 0.40756566255202165, val_loss: 0.38434761978450466 \n",
      "round 3771, train_loss: 0.4075545759435154, val_loss: 0.3843388956253638 \n",
      "round 3772, train_loss: 0.4075434945341576, val_loss: 0.38433017745039333 \n",
      "round 3773, train_loss: 0.4075324183203426, val_loss: 0.3843214652552191 \n",
      "round 3774, train_loss: 0.40752134729846856, val_loss: 0.38431275903547 \n",
      "round 3775, train_loss: 0.40751028146493684, val_loss: 0.3843040587867793 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 3776, train_loss: 0.4074992208161514, val_loss: 0.38429536450478413 \n",
      "round 3777, train_loss: 0.4074881653485202, val_loss: 0.3842866761851258 \n",
      "round 3778, train_loss: 0.40747711505845446, val_loss: 0.3842779938234494 \n",
      "round 3779, train_loss: 0.40746606994236734, val_loss: 0.38426931741540377 \n",
      "round 3780, train_loss: 0.4074550299966766, val_loss: 0.38426064695664197 \n",
      "round 3781, train_loss: 0.40744399521780233, val_loss: 0.38425198244282055 \n",
      "round 3782, train_loss: 0.4074329656021683, val_loss: 0.3842433238696009 \n",
      "round 3783, train_loss: 0.4074219411462013, val_loss: 0.38423467123264743 \n",
      "round 3784, train_loss: 0.40741092184633065, val_loss: 0.38422602452762905 \n",
      "round 3785, train_loss: 0.40739990769898987, val_loss: 0.3842173837502178 \n",
      "round 3786, train_loss: 0.40738889870061523, val_loss: 0.3842087488960905 \n",
      "round 3787, train_loss: 0.40737789484764597, val_loss: 0.38420011996092773 \n",
      "round 3788, train_loss: 0.4073668961365246, val_loss: 0.38419149694041366 \n",
      "round 3789, train_loss: 0.4073559025636969, val_loss: 0.3841828798302367 \n",
      "round 3790, train_loss: 0.4073449141256117, val_loss: 0.38417426862608844 \n",
      "round 3791, train_loss: 0.40733393081872094, val_loss: 0.3841656633236651 \n",
      "round 3792, train_loss: 0.4073229526394798, val_loss: 0.3841570639186668 \n",
      "round 3793, train_loss: 0.4073119795843466, val_loss: 0.38414847040679684 \n",
      "round 3794, train_loss: 0.4073010116497828, val_loss: 0.38413988278376343 \n",
      "round 3795, train_loss: 0.40729004883225267, val_loss: 0.3841313010452777 \n",
      "round 3796, train_loss: 0.4072790911282241, val_loss: 0.38412272518705515 \n",
      "round 3797, train_loss: 0.407268138534168, val_loss: 0.3841141552048149 \n",
      "round 3798, train_loss: 0.40725719104655833, val_loss: 0.3841055910942804 \n",
      "round 3799, train_loss: 0.40724624866187176, val_loss: 0.3840970328511779 \n",
      "round 3800, train_loss: 0.40723531137658875, val_loss: 0.384088480471239 \n",
      "round 3801, train_loss: 0.4072243791871926, val_loss: 0.3840799339501981 \n",
      "round 3802, train_loss: 0.4072134520901696, val_loss: 0.38407139328379364 \n",
      "round 3803, train_loss: 0.4072025300820093, val_loss: 0.3840628584677683 \n",
      "round 3804, train_loss: 0.4071916131592041, val_loss: 0.38405432949786755 \n",
      "round 3805, train_loss: 0.4071807013182498, val_loss: 0.3840458063698421 \n",
      "round 3806, train_loss: 0.4071697945556458, val_loss: 0.38403728907944534 \n",
      "round 3807, train_loss: 0.40715889286789303, val_loss: 0.3840287776224353 \n",
      "round 3808, train_loss: 0.4071479962514971, val_loss: 0.38402027199457317 \n",
      "round 3809, train_loss: 0.40713710470296577, val_loss: 0.3840117721916245 \n",
      "round 3810, train_loss: 0.4071262182188104, val_loss: 0.3840032782093583 \n",
      "round 3811, train_loss: 0.40711533679554507, val_loss: 0.3839947900435474 \n",
      "round 3812, train_loss: 0.40710446042968723, val_loss: 0.3839863076899689 \n",
      "round 3813, train_loss: 0.407093589117757, val_loss: 0.3839778311444026 \n",
      "round 3814, train_loss: 0.407082722856278, val_loss: 0.3839693604026335 \n",
      "round 3815, train_loss: 0.40707186164177694, val_loss: 0.38396089546044954 \n",
      "round 3816, train_loss: 0.4070610054707829, val_loss: 0.38395243631364223 \n",
      "round 3817, train_loss: 0.40705015433982905, val_loss: 0.38394398295800797 \n",
      "round 3818, train_loss: 0.4070393082454509, val_loss: 0.38393553538934544 \n",
      "round 3819, train_loss: 0.40702846718418706, val_loss: 0.38392709360345845 \n",
      "round 3820, train_loss: 0.4070176311525794, val_loss: 0.3839186575961534 \n",
      "round 3821, train_loss: 0.4070068001471727, val_loss: 0.3839102273632417 \n",
      "round 3822, train_loss: 0.40699597416451516, val_loss: 0.3839018029005376 \n",
      "round 3823, train_loss: 0.4069851532011574, val_loss: 0.3838933842038591 \n",
      "round 3824, train_loss: 0.40697433725365356, val_loss: 0.38388497126902876 \n",
      "round 3825, train_loss: 0.4069635263185603, val_loss: 0.38387656409187176 \n",
      "round 3826, train_loss: 0.40695272039243807, val_loss: 0.38386816266821794 \n",
      "round 3827, train_loss: 0.4069419194718498, val_loss: 0.3838597669939008 \n",
      "round 3828, train_loss: 0.40693112355336136, val_loss: 0.3838513770647568 \n",
      "round 3829, train_loss: 0.40692033263354205, val_loss: 0.38384299287662715 \n",
      "round 3830, train_loss: 0.40690954670896395, val_loss: 0.3838346144253561 \n",
      "round 3831, train_loss: 0.4068987657762024, val_loss: 0.38382624170679175 \n",
      "round 3832, train_loss: 0.4068879898318353, val_loss: 0.383817874716786 \n",
      "round 3833, train_loss: 0.4068772188724437, val_loss: 0.38380951345119496 \n",
      "round 3834, train_loss: 0.40686645289461176, val_loss: 0.3838011579058771 \n",
      "round 3835, train_loss: 0.40685569189492704, val_loss: 0.383792808076696 \n",
      "round 3836, train_loss: 0.4068449358699793, val_loss: 0.3837844639595185 \n",
      "round 3837, train_loss: 0.4068341848163617, val_loss: 0.38377612555021495 \n",
      "round 3838, train_loss: 0.40682343873067056, val_loss: 0.38376779284465895 \n",
      "round 3839, train_loss: 0.40681269760950495, val_loss: 0.3837594658387291 \n",
      "round 3840, train_loss: 0.40680196144946695, val_loss: 0.3837511445283065 \n",
      "round 3841, train_loss: 0.4067912302471615, val_loss: 0.38374282890927636 \n",
      "round 3842, train_loss: 0.40678050399919696, val_loss: 0.38373451897752775 \n",
      "round 3843, train_loss: 0.4067697827021844, val_loss: 0.38372621472895285 \n",
      "round 3844, train_loss: 0.4067590663527374, val_loss: 0.38371791615944845 \n",
      "round 3845, train_loss: 0.4067483549474731, val_loss: 0.38370962326491376 \n",
      "round 3846, train_loss: 0.4067376484830121, val_loss: 0.38370133604125317 \n",
      "round 3847, train_loss: 0.40672694695597617, val_loss: 0.3836930544843732 \n",
      "round 3848, train_loss: 0.4067162503629922, val_loss: 0.38368477859018485 \n",
      "round 3849, train_loss: 0.40670555870068853, val_loss: 0.3836765083546029 \n",
      "round 3850, train_loss: 0.4066948719656968, val_loss: 0.3836682437735452 \n",
      "round 3851, train_loss: 0.4066841901546524, val_loss: 0.38365998484293395 \n",
      "round 3852, train_loss: 0.4066735132641924, val_loss: 0.38365173155869425 \n",
      "round 3853, train_loss: 0.40666284129095753, val_loss: 0.3836434839167553 \n",
      "round 3854, train_loss: 0.4066521742315914, val_loss: 0.3836352419130498 \n",
      "round 3855, train_loss: 0.40664151208274074, val_loss: 0.38362700554351437 \n",
      "round 3856, train_loss: 0.4066308548410544, val_loss: 0.3836187748040884 \n",
      "round 3857, train_loss: 0.4066202025031854, val_loss: 0.3836105496907161 \n",
      "round 3858, train_loss: 0.4066095550657889, val_loss: 0.38360233019934414 \n",
      "round 3859, train_loss: 0.4065989125255227, val_loss: 0.38359411632592394 \n",
      "round 3860, train_loss: 0.4065882748790486, val_loss: 0.3835859080664094 \n",
      "round 3861, train_loss: 0.4065776421230297, val_loss: 0.38357770541675884 \n",
      "round 3862, train_loss: 0.40656701425413405, val_loss: 0.38356950837293396 \n",
      "round 3863, train_loss: 0.4065563912690306, val_loss: 0.3835613169308995 \n",
      "round 3864, train_loss: 0.40654577316439283, val_loss: 0.38355313108662487 \n",
      "round 3865, train_loss: 0.4065351599368961, val_loss: 0.38354495083608225 \n",
      "round 3866, train_loss: 0.40652455158321893, val_loss: 0.38353677617524745 \n",
      "round 3867, train_loss: 0.40651394810004315, val_loss: 0.3835286071001003 \n",
      "round 3868, train_loss: 0.4065033494840528, val_loss: 0.38352044360662374 \n",
      "round 3869, train_loss: 0.4064927557319355, val_loss: 0.3835122856908048 \n",
      "round 3870, train_loss: 0.40648216684038113, val_loss: 0.38350413334863376 \n",
      "round 3871, train_loss: 0.4064715828060829, val_loss: 0.383495986576104 \n",
      "round 3872, train_loss: 0.40646100362573684, val_loss: 0.3834878453692134 \n",
      "round 3873, train_loss: 0.40645042929604175, val_loss: 0.3834797097239629 \n",
      "round 3874, train_loss: 0.4064398598136992, val_loss: 0.38347157963635664 \n",
      "round 3875, train_loss: 0.4064292951754139, val_loss: 0.3834634551024033 \n",
      "round 3876, train_loss: 0.4064187353778932, val_loss: 0.3834553361181141 \n",
      "round 3877, train_loss: 0.40640818041784743, val_loss: 0.3834472226795042 \n",
      "round 3878, train_loss: 0.4063976302919899, val_loss: 0.3834391147825926 \n",
      "round 3879, train_loss: 0.40638708499703646, val_loss: 0.3834310124234012 \n",
      "round 3880, train_loss: 0.40637654452970634, val_loss: 0.3834229155979562 \n",
      "round 3881, train_loss: 0.40636600888672114, val_loss: 0.3834148243022866 \n",
      "round 3882, train_loss: 0.40635547806480554, val_loss: 0.38340673853242524 \n",
      "round 3883, train_loss: 0.40634495206068694, val_loss: 0.38339865828440856 \n",
      "round 3884, train_loss: 0.4063344308710954, val_loss: 0.38339058355427635 \n",
      "round 3885, train_loss: 0.40632391449276456, val_loss: 0.38338251433807213 \n",
      "round 3886, train_loss: 0.4063134029224301, val_loss: 0.38337445063184233 \n",
      "round 3887, train_loss: 0.4063028961568311, val_loss: 0.3833663924316378 \n",
      "round 3888, train_loss: 0.4062923941927089, val_loss: 0.3833583397335124 \n",
      "round 3889, train_loss: 0.40628189702680834, val_loss: 0.3833502925335234 \n",
      "round 3890, train_loss: 0.40627140465587674, val_loss: 0.38334225082773155 \n",
      "round 3891, train_loss: 0.40626091707666395, val_loss: 0.38333421461220146 \n",
      "round 3892, train_loss: 0.40625043428592345, val_loss: 0.3833261838830006 \n",
      "round 3893, train_loss: 0.40623995628041043, val_loss: 0.38331815863620095 \n",
      "round 3894, train_loss: 0.4062294830568841, val_loss: 0.3833101388678766 \n",
      "round 3895, train_loss: 0.40621901461210586, val_loss: 0.38330212457410623 \n",
      "round 3896, train_loss: 0.40620855094283936, val_loss: 0.3832941157509717 \n",
      "round 3897, train_loss: 0.40619809204585217, val_loss: 0.38328611239455795 \n",
      "round 3898, train_loss: 0.40618763791791407, val_loss: 0.3832781145009535 \n",
      "round 3899, train_loss: 0.40617718855579765, val_loss: 0.3832701220662512 \n",
      "round 3900, train_loss: 0.40616674395627855, val_loss: 0.3832621350865459 \n",
      "round 3901, train_loss: 0.40615630411613485, val_loss: 0.3832541535579371 \n",
      "round 3902, train_loss: 0.4061458690321476, val_loss: 0.383246177476527 \n",
      "round 3903, train_loss: 0.40613543870110075, val_loss: 0.3832382068384218 \n",
      "round 3904, train_loss: 0.4061250131197809, val_loss: 0.3832302416397305 \n",
      "round 3905, train_loss: 0.40611459228497737, val_loss: 0.38322228187656626 \n",
      "round 3906, train_loss: 0.4061041761934825, val_loss: 0.38321432754504536 \n",
      "round 3907, train_loss: 0.4060937648420912, val_loss: 0.38320637864128754 \n",
      "round 3908, train_loss: 0.4060833582276014, val_loss: 0.3831984351614156 \n",
      "round 3909, train_loss: 0.40607295634681323, val_loss: 0.38319049710155584 \n",
      "round 3910, train_loss: 0.4060625591965304, val_loss: 0.38318256445783905 \n",
      "round 3911, train_loss: 0.4060521667735584, val_loss: 0.38317463722639755 \n",
      "round 3912, train_loss: 0.4060417790747067, val_loss: 0.3831667154033693 \n",
      "round 3913, train_loss: 0.4060313960967868, val_loss: 0.38315879898489347 \n",
      "round 3914, train_loss: 0.4060210178366126, val_loss: 0.3831508879671141 \n",
      "round 3915, train_loss: 0.4060106442910015, val_loss: 0.38314298234617805 \n",
      "round 3916, train_loss: 0.4060002754567734, val_loss: 0.38313508211823566 \n",
      "round 3917, train_loss: 0.40598991133075074, val_loss: 0.38312718727944095 \n",
      "round 3918, train_loss: 0.4059795519097589, val_loss: 0.3831192978259508 \n",
      "round 3919, train_loss: 0.40596919719062613, val_loss: 0.3831114137539257 \n",
      "round 3920, train_loss: 0.40595884717018293, val_loss: 0.3831035350595299 \n",
      "round 3921, train_loss: 0.4059485018452633, val_loss: 0.38309566173893045 \n",
      "round 3922, train_loss: 0.40593816121270315, val_loss: 0.3830877937882982 \n",
      "round 3923, train_loss: 0.4059278252693418, val_loss: 0.3830799312038073 \n",
      "round 3924, train_loss: 0.4059174940120209, val_loss: 0.38307207398163473 \n",
      "round 3925, train_loss: 0.40590716743758465, val_loss: 0.3830642221179616 \n",
      "round 3926, train_loss: 0.4058968455428806, val_loss: 0.38305637560897193 \n",
      "round 3927, train_loss: 0.40588652832475886, val_loss: 0.38304853445085324 \n",
      "round 3928, train_loss: 0.40587621578007166, val_loss: 0.38304069863979673 \n",
      "round 3929, train_loss: 0.4058659079056746, val_loss: 0.3830328681719957 \n",
      "round 3930, train_loss: 0.40585560469842574, val_loss: 0.3830250430436487 \n",
      "round 3931, train_loss: 0.40584530615518544, val_loss: 0.38301722325095605 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 3932, train_loss: 0.405835012272818, val_loss: 0.38300940879012224 \n",
      "round 3933, train_loss: 0.405824723048189, val_loss: 0.38300159965735436 \n",
      "round 3934, train_loss: 0.4058144384781672, val_loss: 0.38299379584886406 \n",
      "round 3935, train_loss: 0.40580415855962504, val_loss: 0.38298599736086497 \n",
      "round 3936, train_loss: 0.405793883289436, val_loss: 0.382978204189575 \n",
      "round 3937, train_loss: 0.40578361266447716, val_loss: 0.3829704163312146 \n",
      "round 3938, train_loss: 0.40577334668162857, val_loss: 0.3829626337820081 \n",
      "round 3939, train_loss: 0.40576308533777233, val_loss: 0.3829548565381833 \n",
      "round 3940, train_loss: 0.4057528286297933, val_loss: 0.38294708459597077 \n",
      "round 3941, train_loss: 0.4057425765545794, val_loss: 0.38293931795160474 \n",
      "round 3942, train_loss: 0.40573232910902113, val_loss: 0.38293155660132244 \n",
      "round 3943, train_loss: 0.40572208629001116, val_loss: 0.3829238005413646 \n",
      "round 3944, train_loss: 0.4057118480944457, val_loss: 0.38291604976797544 \n",
      "round 3945, train_loss: 0.40570161451922276, val_loss: 0.3829083042774022 \n",
      "round 3946, train_loss: 0.40569138556124384, val_loss: 0.3829005640658951 \n",
      "round 3947, train_loss: 0.4056811612174122, val_loss: 0.3828928291297085 \n",
      "round 3948, train_loss: 0.40567094148463456, val_loss: 0.3828850994650994 \n",
      "round 3949, train_loss: 0.40566072635981965, val_loss: 0.38287737506832825 \n",
      "round 3950, train_loss: 0.40565051583987966, val_loss: 0.3828696559356587 \n",
      "round 3951, train_loss: 0.4056403099217285, val_loss: 0.3828619420633577 \n",
      "round 3952, train_loss: 0.40563010860228343, val_loss: 0.38285423344769576 \n",
      "round 3953, train_loss: 0.4056199118784642, val_loss: 0.382846530084946 \n",
      "round 3954, train_loss: 0.40560971974719284, val_loss: 0.38283883197138563 \n",
      "round 3955, train_loss: 0.40559953220539435, val_loss: 0.38283113910329425 \n",
      "round 3956, train_loss: 0.40558934924999623, val_loss: 0.3828234514769554 \n",
      "round 3957, train_loss: 0.40557917087792894, val_loss: 0.3828157690886559 \n",
      "round 3958, train_loss: 0.4055689970861252, val_loss: 0.38280809193468496 \n",
      "round 3959, train_loss: 0.4055588278715206, val_loss: 0.3828004200113361 \n",
      "round 3960, train_loss: 0.405548663231053, val_loss: 0.3827927533149052 \n",
      "round 3961, train_loss: 0.4055385031616633, val_loss: 0.3827850918416917 \n",
      "round 3962, train_loss: 0.405528347660295, val_loss: 0.38277743558799904 \n",
      "round 3963, train_loss: 0.40551819672389355, val_loss: 0.38276978455013244 \n",
      "round 3964, train_loss: 0.40550805034940807, val_loss: 0.38276213872440173 \n",
      "round 3965, train_loss: 0.4054979085337895, val_loss: 0.3827544981071187 \n",
      "round 3966, train_loss: 0.4054877712739916, val_loss: 0.38274686269459934 \n",
      "round 3967, train_loss: 0.40547763856697094, val_loss: 0.3827392324831626 \n",
      "round 3968, train_loss: 0.40546751040968654, val_loss: 0.38273160746913004 \n",
      "round 3969, train_loss: 0.4054573867990999, val_loss: 0.3827239876488275 \n",
      "round 3970, train_loss: 0.40544726773217526, val_loss: 0.38271637301858347 \n",
      "round 3971, train_loss: 0.40543715320587964, val_loss: 0.38270876357472916 \n",
      "round 3972, train_loss: 0.40542704321718237, val_loss: 0.38270115931359994 \n",
      "round 3973, train_loss: 0.40541693776305515, val_loss: 0.38269356023153356 \n",
      "round 3974, train_loss: 0.40540683684047285, val_loss: 0.38268596632487134 \n",
      "round 3975, train_loss: 0.40539674044641305, val_loss: 0.3826783775899579 \n",
      "round 3976, train_loss: 0.4053866485778545, val_loss: 0.382670794023141 \n",
      "round 3977, train_loss: 0.4053765612317805, val_loss: 0.38266321562077105 \n",
      "round 3978, train_loss: 0.40536647840517565, val_loss: 0.3826556423792023 \n",
      "round 3979, train_loss: 0.40535640009502716, val_loss: 0.38264807429479214 \n",
      "round 3980, train_loss: 0.4053463262983255, val_loss: 0.3826405113639006 \n",
      "round 3981, train_loss: 0.4053362570120631, val_loss: 0.3826329535828913 \n",
      "round 3982, train_loss: 0.40532619223323524, val_loss: 0.38262540094813097 \n",
      "round 3983, train_loss: 0.4053161319588397, val_loss: 0.3826178534559894 \n",
      "round 3984, train_loss: 0.40530607618587683, val_loss: 0.38261031110283966 \n",
      "round 3985, train_loss: 0.4052960249113494, val_loss: 0.3826027738850578 \n",
      "round 3986, train_loss: 0.4052859781322629, val_loss: 0.38259524179902343 \n",
      "round 3987, train_loss: 0.4052759358456255, val_loss: 0.38258771484111886 \n",
      "round 3988, train_loss: 0.4052658980484478, val_loss: 0.3825801930077293 \n",
      "round 3989, train_loss: 0.4052558647377425, val_loss: 0.38257267629524433 \n",
      "round 3990, train_loss: 0.40524583591052543, val_loss: 0.38256516470005536 \n",
      "round 3991, train_loss: 0.405235811563815, val_loss: 0.38255765821855714 \n",
      "round 3992, train_loss: 0.4052257916946318, val_loss: 0.3825501568471484 \n",
      "round 3993, train_loss: 0.405215776299999, val_loss: 0.38254266058223024 \n",
      "round 3994, train_loss: 0.40520576537694253, val_loss: 0.3825351694202068 \n",
      "round 3995, train_loss: 0.4051957589224907, val_loss: 0.3825276833574861 \n",
      "round 3996, train_loss: 0.40518575693367465, val_loss: 0.38252020239047835 \n"
     ]
    }
   ],
   "source": [
    "model = mylogit(tol=1e-5, max_iter=10000, intercept=False,dropout_rate=1,early_stopping=50,verbose=True,validation_set=(X_test,y_test))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847457627118644"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "poly_features = PolynomialFeatures(degree = 20) #To ensure no intercept is added\n",
    "X_train=poly_features.fit_transform(X_train)\n",
    "X_test = poly_features.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout : 0.0, test accuracy: 0.8475, convergence: True, rounds : 3920\n",
      "Dropout : 0.05, test accuracy: 0.8475, convergence: True, rounds : 7872\n",
      "Dropout : 0.1, test accuracy: 0.8475, convergence: True, rounds : 8444\n",
      "Dropout : 0.15, test accuracy: 0.8475, convergence: True, rounds : 8576\n",
      "Dropout : 0.2, test accuracy: 0.8475, convergence: True, rounds : 8586\n",
      "Dropout : 0.25, test accuracy: 0.8475, convergence: True, rounds : 8534\n",
      "Dropout : 0.3, test accuracy: 0.8305, convergence: True, rounds : 8421\n",
      "Dropout : 0.35, test accuracy: 0.8305, convergence: True, rounds : 9786\n",
      "Dropout : 0.4, test accuracy: 0.8136, convergence: True, rounds : 9946\n",
      "Dropout : 0.45, test accuracy: 0.8305, convergence: True, rounds : 10352\n",
      "Dropout : 0.5, test accuracy: 0.8305, convergence: True, rounds : 10235\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = np.arange(0.00,0.55,0.05)\n",
    "acc = []\n",
    "for c in dropout_rates:\n",
    "    model = mylogit(tol=1e-5, max_iter=20000,dropout_rate=c,last_n_losses=5, intercept=False,early_stopping=5,validation_set=(X_test,y_test))\n",
    "    model.fit(X_train, y_train)\n",
    "    acc.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "    print(f'Dropout : {round(c,2)}, test accuracy: {round(acc[-1],4)}, convergence: {model.converged}, rounds : {model.iterations}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout : 0.0, test accuracy: 0.8475, convergence: True, rounds : 3920\n",
      "Dropout : 0.05, test accuracy: 0.8475, convergence: True, rounds : 4047\n",
      "Dropout : 0.1, test accuracy: 0.8644, convergence: True, rounds : 4306\n",
      "Dropout : 0.15, test accuracy: 0.8644, convergence: True, rounds : 4329\n",
      "Dropout : 0.2, test accuracy: 0.8644, convergence: True, rounds : 4337\n",
      "Dropout : 0.25, test accuracy: 0.8475, convergence: True, rounds : 4341\n",
      "Dropout : 0.3, test accuracy: 0.8644, convergence: True, rounds : 4414\n",
      "Dropout : 0.35, test accuracy: 0.7966, convergence: True, rounds : 5039\n",
      "Dropout : 0.4, test accuracy: 0.8136, convergence: True, rounds : 5119\n",
      "Dropout : 0.45, test accuracy: 0.8305, convergence: True, rounds : 4608\n",
      "Dropout : 0.5, test accuracy: 0.8475, convergence: True, rounds : 4407\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = np.arange(0.00,0.55,0.05)\n",
    "acc = []\n",
    "for c in dropout_rates:\n",
    "    model = mylogit(tol=1e-5, max_iter=20000,dropout_rate=c,last_n_losses=1, intercept=False,early_stopping=5,validation_set=(X_test,y_test))\n",
    "    model.fit(X_train, y_train)\n",
    "    acc.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "    print(f'Dropout : {round(c,2)}, test accuracy: {round(acc[-1],4)}, convergence: {model.converged}, rounds : {model.iterations}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7288135593220338"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, model.predict(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847457627118644"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mylogit(tol=1e-5, max_iter=10000, intercept=False,dropout_rate=0)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
